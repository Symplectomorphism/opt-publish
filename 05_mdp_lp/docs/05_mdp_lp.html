<!DOCTYPE html>
<html lang="en"><head>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/tabby.min.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.2.313">

  <meta name="author" content="Aykut C. Satici">
  <title>Optimization Theory and Practice</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="site_libs/revealjs/dist/theme/quarto.css" id="theme">
  <link rel="stylesheet" href="styles.css">
  <link href="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-pointer/pointer.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">


<section id="optimization-theory-and-practice" class="slide level2 center smaller">
<h2>Optimization Theory and Practice</h2>
<!-- ###################################################################### -->
<hr>
<h3 id="markov-decision-processes-and-linear-programming">Markov Decision Processes and Linear Programming</h3>
<p><br></p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 52.2%;justify-content: center;">
<p><strong>Instructor</strong>: Aykut Satici, Ph.D.&nbsp;<br> <br> Mechanical and Biomedical Engineering <br> Electrical and Computer Engineering <br> Boise State University, Boise, ID, USA</p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 47.8%;justify-content: center;">
<p><strong>Topics</strong>: <br><br> Markov Decision Processes <br> Policies and Value Functions <br> Bellman Optimality and Linear Programming <br></p>
</div>
</div>
</div>
</section>
<section>
<section id="markov-decision-processes-mdp" class="title-slide slide level1 center">
<h1>Markov Decision Processes (MDP)</h1>

</section>
<section id="introduction" class="slide level2">
<h2>Introduction</h2>
<ul>
<li>MDPs are a classical formalization of sequential decision making.
<ul>
<li>Actions influence not just immediate rewards, but also subsequent states, and through those, future rewards.</li>
<li>They are meant to be a straightforward framing of the problem of learning from interaction to achieve a goal.</li>
</ul></li>
<li>MDPs involve delayed reward and the need to trade off immediate and delayed reward.</li>
<li>We will estimate the value <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mo>*</mo></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">q_\ast(s, a)</annotation></semantics></math> of each action <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math> in each state <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>,
<ul>
<li>or we estimate the value <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mo>*</mo></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">v_\ast(s)</annotation></semantics></math> of each state given optimal action selections.</li>
</ul></li>
<li>These state-dependent quantities are essential to accurately assigning credit for long-term consequences to individual action selections.</li>
</ul>
</section>
<section id="the-agent-environment-interface" class="slide level2 smaller">
<h2>The Agent – Environment Interface</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div class="callout callout-warning no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<ul>
<li>The decision maker is called the <em>agent</em> or <em>controller</em>.</li>
<li>The thing it interacts with, everything outside the agent, is called the <em>environment</em> or <em>plant</em>.</li>
<li>These interact continually, the agent selecting <em>actions</em> (or <em>control signal</em>) and the environment responding to these control signals and presenting new situations to the agent.</li>
<li>The environment also gives rise to <em>rewards</em>, special numerical values that the agent seeks to maximize over time through its choice of actions.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-warning no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<ul>
<li>The agent and environment interact at each of a sequence of discrete time steps, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi>…</mi></mrow><annotation encoding="application/x-tex">t = 0, 1, 2, \ldots</annotation></semantics></math>.
<ul>
<li>At each time step <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>, the agent receives some respresentation of the environment’s <em>state</em>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>t</mi></msub><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle></mrow><annotation encoding="application/x-tex">S_t \in \mathcal{S}</annotation></semantics></math>, and on that basis selects an action <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi>t</mi></msub><mo>∈</mo><mstyle mathvariant="script"><mi>𝒜</mi></mstyle><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">A_t \in \mathcal{A}(s)</annotation></semantics></math>.</li>
<li>One time step later, in part as a consequence of its actions, the agent receives a numerical reward, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>∈</mo><mstyle mathvariant="script"><mi>ℛ</mi></mstyle><mo>∈</mo><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle></mrow><annotation encoding="application/x-tex">R_{t+1} \in \mathcal{R} \in \mathbb{R}</annotation></semantics></math> and finds itself in a new state, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>S</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">S_{t+1}</annotation></semantics></math>.</li>
</ul></li>
<li>The MDP and agent together give rise to a trajectory that begins like this: <span id="eq-traj"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mn>0</mn></msub><mo>,</mo><msub><mi>A</mi><mn>0</mn></msub><mo>,</mo><msub><mi>S</mi><mn>1</mn></msub><mo>,</mo><msub><mi>R</mi><mn>1</mn></msub><mo>,</mo><msub><mi>A</mi><mn>2</mn></msub><mo>,</mo><msub><mi>R</mi><mn>2</mn></msub><mo>,</mo><msub><mi>S</mi><mn>2</mn></msub><mo>,</mo><msub><mi>A</mi><mn>2</mn></msub><mo>,</mo><msub><mi>R</mi><mn>3</mn></msub><mo>,</mo><mi>…</mi><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> S_0, A_0, S_1, R_1, A_2, R_2, S_2, A_2, R_3, \ldots  \qquad(1)</annotation></semantics></math></span></li>
</ul>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<center>
<img src="contents/assets/agent_environment.png" width="95%" img="">
</center>
<div class="callout callout-important no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<ul>
<li>In a <em>finite</em> MDP, the sets of states, actions, and rewards<br>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo>,</mo><mstyle mathvariant="script"><mi>𝒜</mi></mstyle><mo>,</mo><mstyle mathvariant="script"><mi>ℛ</mi></mstyle><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(\mathcal{S}, \mathcal{A}, \mathcal{R})</annotation></semantics></math> all have a finite number of elements.
<ul>
<li>In this case, the random variables <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>R</mi><mi>t</mi></msub><annotation encoding="application/x-tex">R_t</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>S</mi><mi>t</mi></msub><annotation encoding="application/x-tex">S_t</annotation></semantics></math> have well defined discrete probability distributions dependent on the preceding state and action.</li>
</ul></li>
</ul>
<p><span id="eq-dyn"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi><mo>∣</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≜</mo><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">{</mo><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi><mi>′</mi><mo>,</mo><msub><mi>R</mi><mi>t</mi></msub><mo>=</mo><mi>r</mi><mo>∣</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>s</mi><mo>,</mo><msub><mi>A</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>a</mi><mo stretchy="false" form="postfix">}</mo><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>2</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> p(s', r \mid s, a) \triangleq \mathbb{P}\{S_t = s', R_t = r \mid S_{t-1} = s,
A_{t-1} = a\}  \qquad(2)</annotation></semantics></math></span></p>
<ul>
<li>This function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math> defines the <em>dynamics</em> of the MDP.
<ul>
<li>It specifies a probability distribution for each choice of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math>, i.e.,</li>
</ul></li>
</ul>
<p><span id="eq-pprob"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo>∑</mo><mrow><mi>s</mi><mi>′</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle></mrow></munder><munder><mo>∑</mo><mrow><mi>r</mi><mo>∈</mo><mstyle mathvariant="script"><mi>ℛ</mi></mstyle></mrow></munder><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi><mo>∣</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>1</mn><mo>,</mo><mspace width="1.0em"></mspace><mo>∀</mo><mi>s</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo>,</mo><mspace width="0.278em"></mspace><mi>a</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒜</mi></mstyle><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>3</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> \sum_{s' \in \mathcal{S}} \sum_{r \in \mathcal{R}} p(s', r \mid s, a) = 1,
\quad \forall s \in \mathcal{S}, \; a \in \mathcal{A}(s).  \qquad(3)</annotation></semantics></math></span></p>
<ul>
<li>This is called the <em>Markov property</em>.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="the-agent-environment-interface-1" class="slide level2 smaller">
<h2>The Agent – Environment Interface</h2>
<ul>
<li>From the four-argument dynamics function, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>, one can compute anything else one might want to know about the environment
<ul>
<li>the <em>state-transition probabilities</em> <span id="eq-st-trans"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo>∣</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≜</mo><mstyle mathvariant="double-struck"><mi>ℙ</mi></mstyle><mo stretchy="false" form="prefix">{</mo><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi><mi>′</mi><mo>∣</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>a</mi><mo>,</mo><msub><mi>A</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>a</mi><mo stretchy="false" form="postfix">}</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>r</mi><mo>∈</mo><mstyle mathvariant="script"><mi>ℛ</mi></mstyle></mrow></munder><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi><mo>∣</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>4</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> p(s' \mid s, a) \triangleq \mathbb{P}\{S_t = s' \mid S_{t-1} = a, A_{t-1} =
a\} = \sum_{r \in \mathcal{R}} p(s', r \mid s, a).  \qquad(4)</annotation></semantics></math></span></li>
<li>the expected rewards for state-action pairs as a two-argument function <span id="eq-exp-rew-sa"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≜</mo><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>R</mi><mi>t</mi></msub><mo>∣</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>s</mi><mo>,</mo><msub><mi>A</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>a</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><munder><mo>∑</mo><mrow><mi>r</mi><mo>∈</mo><mstyle mathvariant="script"><mi>ℛ</mi></mstyle></mrow></munder><mi>r</mi><munder><mo>∑</mo><mrow><mi>s</mi><mi>′</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle></mrow></munder><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi><mo>∣</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>5</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> r(s, a) \triangleq \mathbb{E}[R_t \mid S_{t-1} = s, A_{t-1} = a] = \sum_{r
\in \mathcal{R}} r \sum_{s' \in \mathcal{S}} p(s', r \mid s, a),  \qquad(5)</annotation></semantics></math></span></li>
<li>the expected rewards for state-action-next-state triples as a three argument function <span id="eq-exp-rew-sas"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo>,</mo><mi>s</mi><mi>′</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≜</mo><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>R</mi><mi>t</mi></msub><mo>∣</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>s</mi><mo>,</mo><msub><mi>A</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>a</mi><mo>,</mo><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi><mi>′</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><munder><mo>∑</mo><mrow><mi>r</mi><mo>∈</mo><mstyle mathvariant="script"><mi>ℛ</mi></mstyle></mrow></munder><mi>r</mi><mspace width="0.278em"></mspace><mfrac><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi><mo>∣</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo>∣</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mi>.</mi><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>6</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> r(s, a, s') \triangleq \mathbb{E}[R_t \mid S_{t-1} = s, A_{t-1} = a, S_t =
s'] = \sum_{r \in \mathcal{R}} r \; \frac{p(s', r \mid s, a)}{p(s' \mid s, a)}.
 \qquad(6)</annotation></semantics></math></span></li>
</ul></li>
</ul>
<div class="column-tip" data-appearance="minimal">
<ul>
<li>The time steps can refer to arbitrary successive stages of decision making.</li>
<li>The actions can be low-level controls (e.g.&nbsp;voltages), or high-level decisions (e.g.&nbsp;have lunch, go to grad school).</li>
<li>They can be determined by low-level sensing (e.g.&nbsp;sensor readings) or they can be more high-level and abstract (e.g.&nbsp;symbolic descriptions of objects in a room).</li>
<li>States can be anything we can know that might be useful in making the decisions.</li>
</ul>
</div>
</section>
<section id="the-agent-environment-interface-2" class="slide level2 smaller">
<h2>The Agent – Environment Interface</h2>
<div class="callout callout-tip no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Rule of thumb</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Anything that cannot be changed arbitrarily by the agent is considered to be outside of it and thus part of its environment.</li>
</ul>
</div>
</div>
</div>
<ul>
<li>Not everything in the environment is unknown to the agent.
<ul>
<li>For example, the agent often knows how its rewards are computed as a function of its actions and the states.</li>
<li>Reward computation is external to the agent because it defines the task facing the agent and thus is beyond its ability to change arbitrarily.</li>
</ul></li>
<li>In fact, some agents know <em>everything</em> about how its environment.</li>
</ul>
<div class="callout callout-tip no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>MDP framework</strong></p>
</div>
<div class="callout-content">
<p>Whatever the details of the sensory, memory, and control apparatus, and whatever objective one is trying to achieve, any problem of learning goal-directed behavior can be reduced to three signals passing back and forth between an agent and its environment:</p>
<ol type="1">
<li>one signal to represent the choices made by the agent (the actions),</li>
<li>one signal to represent the basis on which the choices are made (the states),</li>
<li>one signal to define the agent’s goal (the rewards).</li>
</ol>
</div>
</div>
</div>
</section>
<section id="examples" class="slide level2 smaller">
<h2>Examples</h2>
<div class="callout callout-tip no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Example 1 – Bioreactor</strong></p>
</div>
<div class="callout-content">
<p>Suppose we want to determine moment-by-moment temperatures and stirring rates for a bioreactor.</p>
<ul>
<li>The actions might be target temperatures and target stirring rates that are passed to the lower-level control system,
<ul>
<li>The control system, in turn, will activate heating elements and motors to attain the targets.</li>
</ul></li>
<li>The states could be the outputs of a thermocouple and other sensory readings</li>
<li>The rewards might be moment-by-moment measures of the rate at which the useful chemical is being produced by the bioreactor.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-tip no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Example 2 – Pick-and-Place Robot</strong></p>
</div>
<div class="callout-content">
<p>Suppose we want to control the motion of a robot arm in a repetitive pick-and-place task.</p>
<ul>
<li>The actions might be the voltages applied to each motor at each joint.</li>
<li>The states might be the latest readings of joint angles and velocities.</li>
<li>The reward might be <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">+1</annotation></semantics></math> for each object successfully picked up and placed.
<ul>
<li>To encourage smooth movements, at each time step, a small, negative reward could be given as a function of the moment-to-moment jerkiness of the motion.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-warning no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Homework</strong></p>
</div>
<div class="callout-content">
<p>Devise three example tasks of your own that fit into the MDP framework, identifying for each states, actions, and rewards.</p>
</div>
</div>
</div>
</section>
<section id="example-recycling-robot" class="slide level2 smaller">
<h2>Example — Recycling Robot</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div class="r-stack">
<div class="fragment fade-out" data-fragment-index="1">
<ul>
<li>A mobile robot has the job of collecting empty soda cans in an office environment.</li>
<li>It has sensors for detecting cans, and an arm and gripper that can pick them up and place them in an onboard bin; it runs on a rechargable battery.</li>
<li>The robot’s control system has components for
<ul>
<li>interpreting sensory information,</li>
<li>for navigating,</li>
<li>and for controlling the arm and gripper.</li>
</ul></li>
<li>High-level decisions about how to search for cans are to be made by the agent on the current charge level of the battery.
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo>=</mo><mo stretchy="false" form="prefix">{</mo><mtext mathvariant="monospace">𝚑𝚒𝚐𝚑</mtext><mo>,</mo><mtext mathvariant="monospace">𝚕𝚘𝚠</mtext><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\mathcal{S} = \{\texttt{high}, \texttt{low}\}</annotation></semantics></math>.</li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>𝒜</mi></mstyle><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="monospace">𝚑𝚒𝚐𝚑</mtext><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mo stretchy="false" form="prefix">{</mo><mtext mathvariant="monospace">𝚜𝚎𝚊𝚛𝚌𝚑</mtext><mo>,</mo><mtext mathvariant="monospace">𝚠𝚊𝚒𝚝</mtext><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\mathcal{A}(\texttt{high}) = \{\texttt{search}, \texttt{wait}\}</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>𝒜</mi></mstyle><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="monospace">𝚕𝚘𝚠</mtext><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mo stretchy="false" form="prefix">{</mo><mtext mathvariant="monospace">𝚜𝚎𝚊𝚛𝚌𝚑</mtext><mo>,</mo><mtext mathvariant="monospace">𝚠𝚊𝚒𝚝</mtext><mo>,</mo><mtext mathvariant="monospace">𝚛𝚎𝚌𝚑𝚊𝚛𝚐𝚎</mtext><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\mathcal{A}(\texttt{low}) = \{\texttt{search}, \texttt{wait}, \texttt{recharge}\}</annotation></semantics></math>.</li>
</ul></li>
</ul>
</div>
<div class="fragment fade-in-then-out" data-fragment-index="2">
<ul>
<li>The rewards are zero most of the time, but become positive when the robot secures an empty can, or large and negative if the battery runs all the down.</li>
<li>Best way to find cans is to actively search for them, but this runs down the robot’s battery.
<ul>
<li>If the battery is depleted, the robot must be rescued (producing a low reward).</li>
</ul></li>
<li>If the energy is <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext mathvariant="monospace">𝚑𝚒𝚐𝚑</mtext><annotation encoding="application/x-tex">\texttt{high}</annotation></semantics></math> then a period active search can always be completed w/o risk of depleting the battery.</li>
<li>A period of searching that begins with a <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext mathvariant="monospace">𝚑𝚒𝚐𝚑</mtext><annotation encoding="application/x-tex">\texttt{high}</annotation></semantics></math> energy level leaves the energy level <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext mathvariant="monospace">𝚑𝚒𝚐𝚑</mtext><annotation encoding="application/x-tex">\texttt{high}</annotation></semantics></math> with probability <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math> and reduces it to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext mathvariant="monospace">𝚕𝚘𝚠</mtext><annotation encoding="application/x-tex">\texttt{low}</annotation></semantics></math> with probability <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mi>α</mi></mrow><annotation encoding="application/x-tex">1-\alpha</annotation></semantics></math>.</li>
<li>A period of searching undertaken when the energy level is <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext mathvariant="monospace">𝚕𝚘𝚠</mtext><annotation encoding="application/x-tex">\texttt{low}</annotation></semantics></math> leaves it <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext mathvariant="monospace">𝚕𝚘𝚠</mtext><annotation encoding="application/x-tex">\texttt{low}</annotation></semantics></math> with probability <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation></semantics></math> and depletes the battery with probability <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">1-\beta</annotation></semantics></math>.
<ul>
<li>Robot must be rescued and the battery is then recharged back to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext mathvariant="monospace">𝚑𝚒𝚐𝚑</mtext><annotation encoding="application/x-tex">\texttt{high}</annotation></semantics></math>.</li>
</ul></li>
</ul>
</div>
<div class="fragment" data-fragment-index="3">
<ul>
<li>Each can collected by the robot counts as a unit reward, whereas a reward of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">-3</annotation></semantics></math> results whenever the robot has to be rescued.</li>
<li>Let <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>r</mi><mtext mathvariant="normal">search</mtext></msub><annotation encoding="application/x-tex">r_{\text{search}}</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>r</mi><mtext mathvariant="normal">wait</mtext></msub><annotation encoding="application/x-tex">r_{\text{wait}}</annotation></semantics></math> with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mtext mathvariant="normal">search</mtext></msub><mo>&gt;</mo><msub><mi>r</mi><mtext mathvariant="normal">wait</mtext></msub></mrow><annotation encoding="application/x-tex">r_{\text{search}} &gt; r_{\text{wait}}</annotation></semantics></math> denote the expected number of cans the robot will collect.</li>
<li>Finally, suppose that no cans can be collected during a run home for recharging, and that no cans can be collected on a step in which the battery is depleted.</li>
</ul>
<div class="callout callout-important no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Exercise</strong></p>
</div>
<div class="callout-content">
<p>Give a table analogous to the one on the right but for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(s', r | s, a)</annotation></semantics></math>. It should have columns for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>,</mo><mi>a</mi><mo>,</mo><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi></mrow><annotation encoding="application/x-tex">s, a, s', r</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(s', r|s,a)</annotation></semantics></math> and a row every <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>4</mn><annotation encoding="application/x-tex">4</annotation></semantics></math>-tuple for which <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">p(s', r| s, a) &gt; 0</annotation></semantics></math>.</p>
</div>
</div>
</div>
</div>
</div>
</div><div class="column" style="width:40%;">
<center>
<p><img src="contents/assets/recycling1.png" width="95%" img=""></p>
<img src="contents/assets/recycling2.png" width="95%" img="">
</center>
<div class="callout callout-tip no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Transition graph</strong></p>
</div>
<div class="callout-content">
<p><em>states</em>: open circle | <em>actions</em>: solid circle</p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="goals-and-rewards" class="slide level2 smaller">
<h2>Goals and Rewards</h2>
<ul>
<li>The agent’s goal is to <em>maximize</em> the total amount of reward it receives; <em>not</em> the immediate reward, but the cumulative reward in the long run.</li>
</ul>
<div class="callout callout-important no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Reward Hypothesis</strong></p>
</div>
<div class="callout-content">
<p>All of what we mean by goal and purposes can be well thought as the maximization of the expected value of the cumulative sum of a received scalar signal (called reward).</p>
</div>
</div>
</div>
<ul>
<li>Formulating goals in terms of reward signals has proved to be flexible and widely applicable.</li>
</ul>
<div class="callout callout-note no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Examples</strong></p>
</div>
<div class="callout-content">
<table>
<colgroup>
<col style="width: 42%">
<col style="width: 57%">
</colgroup>
<thead>
<tr class="header">
<th>Task</th>
<th>Reward</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Robot walking</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mo>+</mo><annotation encoding="application/x-tex">+</annotation></semantics></math>ve reward on each time step proportional to robot’s forward motion</td>
</tr>
<tr class="even">
<td>Escape from a maze</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math> reward for every time step that passes prior to escape</td>
</tr>
<tr class="odd">
<td>Playing chess</td>
<td><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">+1</annotation></semantics></math> for winning, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math> for losing, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0</mn><annotation encoding="application/x-tex">0</annotation></semantics></math> for drawing</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<ul>
<li>The reward signal is no the place to impart to the agent prior knowledge about <em>how</em> to achieve what we want it to do (better places: initial policy, iniial value function).
<ul>
<li>Otherwise the agent might find a way to achieve <em>subgoals</em> without achieving the real goal!</li>
</ul></li>
</ul>
</section>
<section id="returns-and-episodes" class="slide level2 smaller">
<h2>Returns and Episodes</h2>
<ul>
<li>In general, we seek to maximize the <em>expected return</em>, where the return, denoted <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>G</mi><mi>t</mi></msub><annotation encoding="application/x-tex">G_t</annotation></semantics></math>, is defined as some specific function of the reward sequence.
<ul>
<li>Simplest (bit naïve) case: <span id="eq-rew-episode"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mi>t</mi></msub><mo>≜</mo><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>2</mn></mrow></msub><mo>+</mo><mi>⋯</mi><mo>+</mo><msub><mi>R</mi><mi>T</mi></msub><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>T</mi></munderover><msub><mi>R</mi><mi>k</mi></msub><mo>,</mo><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>7</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> G_t \triangleq R_{t+1} + R_{t+2} + \cdots + R_T = \sum_{k=t+1}^T R_k,   \qquad(7)</annotation></semantics></math></span></li>
<li><em>Discounted return</em>: <span id="eq-rew-discounted"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mi>t</mi></msub><mo>≜</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mo accent="false">∞</mo></munderover><msup><mi>γ</mi><mi>k</mi></msup><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>T</mi></munderover><msup><mi>γ</mi><mrow><mi>k</mi><mo>−</mo><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msup><msub><mi>R</mi><mi>k</mi></msub><mo>,</mo><mspace width="1.0em"></mspace><mn>0</mn><mo>≤</mo><mi>γ</mi><mo>≤</mo><mn>1</mn><mi>.</mi><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>8</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> G_t \triangleq \sum_{k=0}^\infty \gamma^kR_{t+k+1} =
\sum_{k=t+1}^T \gamma^{k-t-1}R_k, \quad 0 \leq \gamma \leq 1.  \qquad(8)</annotation></semantics></math></span></li>
</ul></li>
<li>The naïve approach makes sense in applications in which there is a natural notion of a final time step (<em>episodes</em>).
<ul>
<li>Each episodes ends in a state called the <em>terminal state</em>.</li>
<li>In <em>episodic tasks</em> we sometimes need to distinguish the set of all nonterminal states, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><annotation encoding="application/x-tex">\mathcal{S}</annotation></semantics></math> from the set of all states plus the terminal state, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo>+</mo></msup><annotation encoding="application/x-tex">\mathcal{S}^+</annotation></semantics></math>.</li>
</ul></li>
<li>If the task has no final time, or terminal state, then <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mi>∞</mi></mrow><annotation encoding="application/x-tex">T=\infty</annotation></semantics></math>.
<ul>
<li>The naïve return may easily become infinite. Hence we use the discounted return. <span id="eq-ret-rec"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mi>t</mi></msub><mo>=</mo><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>2</mn></mrow></msub><mo>+</mo><mi>γ</mi><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>3</mn></mrow></msub><mo>+</mo><msup><mi>γ</mi><mn>2</mn></msup><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>4</mn></mrow></msub><mo>+</mo><mi>⋯</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>γ</mi><msub><mi>G</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mi>.</mi><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>9</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> G_t = R_{t+1} + \gamma(R_{t+2} + \gamma R_{t+3} + \gamma^2 R_{t+4} + \cdots)
= R_{t+1} + \gamma G_{t+1}.  \qquad(9)</annotation></semantics></math></span></li>
</ul></li>
</ul>
</section>
<section id="example-pole-balancing" class="slide level2 smaller">
<h2>Example — Pole-Balancing</h2>
<div class="columns">
<div class="column" style="width:60%;">
<ul>
<li>A failure is said to occur if the pole falls past a given angle from vertical or if the cart runs off the track.
<ul>
<li>The pole is reset to vertical after each failure.</li>
</ul></li>
<li>This task could be treated as <em>episodic</em>, where the natural episodes are the repeated atempts to balance the pole.
<ul>
<li>The reward in this case would be <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">+1</annotation></semantics></math> for every time step on which failure did not occur.</li>
<li>The return at each time would be the number of steps until failure.</li>
<li>Successful balancing forever would mean a return of infinity.</li>
</ul></li>
</ul>
</div><div class="column" style="width:40%;">
<center>
<img src="contents/assets/cartpole.png" width="85%" img="">
</center>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>Objective: Apply forces to a cart moving along a track so as to keep a pole hinged to the cart from falling over.</p>
</div>
</div>
</div>
</div>
</div>
<ul>
<li>Alternatively, we could treat pole-balancing as a continuing task, using discounting.
<ul>
<li>In his case the reward would be <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math> on each failur and zero all other times.</li>
<li>The return at each time would the be related to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><msup><mi>γ</mi><mrow><mi>K</mi><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">-\gamma^{K-1}</annotation></semantics></math>, where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math> is the number of time steps before failure.</li>
</ul></li>
<li>In either case, the return is maximized by keeping the pole balanced for as long as possible.</li>
</ul>
</section></section>
<section>
<section id="policies-and-value-functions" class="title-slide slide level1 center">
<h1>Policies and Value Functions</h1>

</section>
<section id="how-good-are-a-state-and-an-action" class="slide level2 smaller">
<h2>How good are a state and an action?</h2>
<ul>
<li>The rewards the agent can expect to receive in the future depend on what actions it will take.</li>
<li>Value functions are defined with respect to paricular ways of acting, called <em>policies</em>.</li>
</ul>
<div class="columns">
<div class="column" style="width:50%;">
<div class="callout callout-tip no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Definition</strong></p>
</div>
<div class="callout-content">
<p>A <em>policy</em> is a mapping from states o probabilities of selecting each possible action.</p>
<ul>
<li>If the agent is following policy <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>π</mi><annotation encoding="application/x-tex">\pi</annotation></semantics></math> at time <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>, then <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi(a|s)</annotation></semantics></math> is the probability that <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi>t</mi></msub><mo>=</mo><mi>a</mi></mrow><annotation encoding="application/x-tex">A_t = a</annotation></semantics></math> given that <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi></mrow><annotation encoding="application/x-tex">S_t = s</annotation></semantics></math>.</li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi(a|s)</annotation></semantics></math> defines a probability distribution over <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒜</mi></mstyle><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">a \in \mathcal{A}(s)</annotation></semantics></math> for each <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle></mrow><annotation encoding="application/x-tex">s \in \mathcal{S}</annotation></semantics></math>.</li>
</ul>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="callout callout-tip no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Definition (State-Value Function for Policy <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>π</mi><annotation encoding="application/x-tex">\pi</annotation></semantics></math>)</strong></p>
</div>
<div class="callout-content">
<p>The <em>value function</em> of a state <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math> under a policy <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>π</mi><annotation encoding="application/x-tex">\pi</annotation></semantics></math>, denoted <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">v_\pi(s)</annotation></semantics></math>, is the expected return when starting in <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math> and following <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>π</mi><annotation encoding="application/x-tex">\pi</annotation></semantics></math> thereafter.</p>
<p><span id="eq-val-fcn"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtable><mtr><mtd columnalign="right"><msub><mi>v</mi><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left"><mo>≜</mo><msub><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>G</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi><mo stretchy="true" form="postfix">]</mo></mrow></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>=</mo><msub><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">[</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mo accent="false">∞</mo></munderover><msup><mi>γ</mi><mi>k</mi></msup><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>,</mo><mspace width="0.278em"></mspace><mspace width="0.278em"></mspace><mo>∀</mo><mi>s</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mi>.</mi></mtd></mtr></mtable><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>10</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> 
\begin{align}
v_\pi(s) &amp;\triangleq \mathbb{E}_\pi[G_t | S_t = s] \\ 
&amp;= \mathbb{E}_\pi\left[\sum_{k=0}^\infty \gamma^k R_{t+k+1} | S_t = s \right],
\;\; \forall s \in \mathcal{S}.
\end{align}
 \qquad(10)</annotation></semantics></math></span></p>
<ul>
<li>The value of the terminal state, if any, is always zero.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-tip no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Definition (Action-Value Function for Policy <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>π</mi><annotation encoding="application/x-tex">\pi</annotation></semantics></math>)</strong></p>
</div>
<div class="callout-content">
<p>We define the value of taking action <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math> in state <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math> under a policy <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>π</mi><annotation encoding="application/x-tex">\pi</annotation></semantics></math>, denoted <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">q_\pi(s, a)</annotation></semantics></math>, as the expected return starting from <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>, taking the action <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math>, and thereafter following policy <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>π</mi><annotation encoding="application/x-tex">\pi</annotation></semantics></math>:</p>
<p><span id="eq-act-val-fcn"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtable><mtr><mtd columnalign="right"><msub><mi>q</mi><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left"><mo>≜</mo><msub><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>G</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi><mo>,</mo><msub><mi>A</mi><mi>t</mi></msub><mo>=</mo><mi>a</mi><mo stretchy="true" form="postfix">]</mo></mrow></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>=</mo><msub><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">[</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mo accent="false">∞</mo></munderover><mrow><msup><mi>γ</mi><mi>k</mi></msup><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="true" form="postfix">|</mo></mrow><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi><mo>,</mo><msub><mi>A</mi><mi>t</mi></msub><mo>=</mo><mi>a</mi><mo stretchy="true" form="postfix">]</mo></mrow><mi>.</mi></mtd></mtr></mtable><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>11</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> 
\begin{align}
q_\pi(s, a) &amp;\triangleq \mathbb{E}_\pi[G_t | S_t=s, A_t=a] \\
&amp;= \mathbb{E}_\pi\left[\sum_{k=0}^\infty \left. \gamma^k R_{t+k+1}\right| S_t=s, 
A_t=a \right].
\end{align}
 \qquad(11)</annotation></semantics></math></span></p>
</div>
</div>
</div>
</section>
<section id="bellman-equation" class="slide level2 smaller">
<h2>Bellman Equation</h2>
<div class="callout callout-important no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Fundamental property of Value Functions</strong></p>
</div>
<div class="callout-content">
<p>Value functions saisfy recursive relationships similar that which we established for the return <a href="#/eq-ret-rec">Equation&nbsp;9</a>.</p>
<p>For any policy <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>π</mi><annotation encoding="application/x-tex">\pi</annotation></semantics></math> and any state <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>, the following consistency condition holds between he value of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math> and he value of its possible successor states:</p>
<p><span id="eq-bellman"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtable><mtr><mtd columnalign="right"><msub><mi>v</mi><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≜</mo></mtd><mtd columnalign="left"><mo>=</mo><msub><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>G</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><msub><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>γ</mi><msub><mi>G</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>,</mo><mspace width="1.0em"></mspace><mtext mathvariant="normal">by (9)</mtext></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>=</mo><munder><mo>∑</mo><mrow><mi>a</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒜</mi></mstyle><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></munder><mi>π</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><munder><mo>∑</mo><mrow><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi></mrow></munder><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">[</mo><mi>r</mi><mo>+</mo><mi>γ</mi><msub><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>G</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>s</mi><mi>′</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo stretchy="true" form="postfix">]</mo></mrow></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>=</mo><munder><mo>∑</mo><mrow><mi>a</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒜</mi></mstyle><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></munder><mi>π</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><munder><mo>∑</mo><mrow><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi></mrow></munder><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">[</mo><mi>r</mi><mo>+</mo><mi>γ</mi><msub><mi>v</mi><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">]</mo></mrow><mo>,</mo><mspace width="1.0em"></mspace><mo>∀</mo><mi>s</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mi>.</mi></mtd></mtr></mtable><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>12</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\begin{align}
v_\pi(s) \triangleq &amp;= \mathbb{E}_\pi[G_t|S_t=s] = \mathbb{E}_\pi[R_{t+1} +
\gamma G_{t+1}|S_t = s], \quad {\text{by (9)} }\\
&amp;= \sum_{a \in \mathcal{A}(s)} \pi(a|s)\sum_{s',r}p(s',r|s,a)\left[r + \gamma
\mathbb{E}_\pi[G_{t+1}|S_{t+1}=s']\right] \\
&amp;= \sum_{a \in \mathcal{A}(s)} \pi(a|s) \sum_{s', r}p(s',r|s,a)\left[r + \gamma
v_\pi(s')\right],
\quad \forall s \in \mathcal{S}.
\end{align}
 \qquad(12)</annotation></semantics></math></span></p>
</div>
</div>
</div>
<div class="columns">
<div class="column" style="width:78%;">
<ul>
<li>Each open circle represents a state and each solid circle represents a state-action pair.</li>
<li>Starting from state <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math>, the root node at the top, the agent could take any of some set of actions — three are shown — based on its policy <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>π</mi><annotation encoding="application/x-tex">\pi</annotation></semantics></math>.</li>
</ul>
</div><div class="column" style="width:22%;">
<center>
<img src="contents/assets/backup.png" width="95%" img="">
</center>
</div>
</div>
<ul>
<li>From each of these, the environment could respond with one of several next states, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>′</mi></mrow><annotation encoding="application/x-tex">s'</annotation></semantics></math> (two are shown), along with a reward, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>r</mi><annotation encoding="application/x-tex">r</annotation></semantics></math>, depending on its dynamics, given by the function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>.</li>
<li>Bellman equation averages over all the possibilites, weighing each by its probability of occuring: the value of the start state must equal the (discounted) value of the expected next state, plus the reward expected along the way.</li>
</ul>
</section>
<section id="example-gridworld" class="slide level2 smaller">
<h2>Example — Gridworld</h2>
<div class="columns">
<div class="column" style="width:80%;">
<div class="r-stack">
<div class="fragment fade-out" data-fragment-index="1">
<ul>
<li>Gridworld is a finite Markov Decision Process.
<ul>
<li>The cells of the grid correspond to the states.</li>
<li>At each cell, four actions are possible: <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext mathvariant="monospace">𝚗𝚘𝚛𝚝𝚑</mtext><annotation encoding="application/x-tex">\texttt{north}</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext mathvariant="monospace">𝚜𝚘𝚞𝚝𝚑</mtext><annotation encoding="application/x-tex">\texttt{south}</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext mathvariant="monospace">𝚎𝚊𝚜𝚝</mtext><annotation encoding="application/x-tex">\texttt{east}</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext mathvariant="monospace">𝚠𝚎𝚜𝚝</mtext><annotation encoding="application/x-tex">\texttt{west}</annotation></semantics></math></li>
<li>These actions <em>deterministically</em> cause the agent to move one cell in the respective direction of the grid.</li>
</ul></li>
<li>Actions that would take the agent off the grid leave its location unchanged, but also incur a reward of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math>.</li>
<li>Other actions reward <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0</mn><annotation encoding="application/x-tex">0</annotation></semantics></math>, except those that move the agent out of the special states <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>.
<ul>
<li>From state <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>, all four actions yield a reward of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">+10</annotation></semantics></math> and take the agent to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>′</mi></mrow><annotation encoding="application/x-tex">A'</annotation></semantics></math>.</li>
<li>From state <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>, all actions yield a reward of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">+5</annotation></semantics></math> and take the agent to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>′</mi></mrow><annotation encoding="application/x-tex">B'</annotation></semantics></math>.</li>
</ul></li>
</ul>
<div class="callout callout-note no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Exercise</strong></p>
</div>
<div class="callout-content">
<p>The Bellman <a href="#/eq-bellman">Equation&nbsp;12</a> must hold for each state for the value function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>v</mi><mi>π</mi></msub><annotation encoding="application/x-tex">v_\pi</annotation></semantics></math>. Show numerically that this equation holds for the center state, valued at <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mn>0.7</mn></mrow><annotation encoding="application/x-tex">+0.7</annotation></semantics></math>, w.r.t. its four neighboring states, valued at <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mn>2.3</mn></mrow><annotation encoding="application/x-tex">+2.3</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mn>0.4</mn></mrow><annotation encoding="application/x-tex">+0.4</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>0.4</mn></mrow><annotation encoding="application/x-tex">-0.4</annotation></semantics></math>, and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mn>0.7</mn></mrow><annotation encoding="application/x-tex">+0.7</annotation></semantics></math> (accurate to one decimal place).</p>
</div>
</div>
</div>
</div>
<div class="fragment" data-fragment-index="2">
<ul>
<li>The agent selects all four actions with equal probability in all states.</li>
<li>Figure at the bottom shows the value function, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>v</mi><mi>π</mi></msub><annotation encoding="application/x-tex">v_\pi</annotation></semantics></math>, for this policy, for the discounted reward case with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi><mo>=</mo><mfrac><mn>9</mn><mn>10</mn></mfrac></mrow><annotation encoding="application/x-tex">\gamma = \frac{9}{10}</annotation></semantics></math>.</li>
<li>Notice the negative values near the lower edge.
<ul>
<li>these are the results of the high probability of hitting the edge of the grid under the random policy.</li>
</ul></li>
<li>State <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math> is the best state to be in under this policy.
<ul>
<li>Note: <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math>’s expected return is <em>less</em> than its immediate reward of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>10</mn><annotation encoding="application/x-tex">10</annotation></semantics></math> because from <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math> the agent is taken to state <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>′</mi></mrow><annotation encoding="application/x-tex">A'</annotation></semantics></math> from which it is likely to run into the edge of the grid.</li>
</ul></li>
<li>State <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>, on the other hand, is valued <em>more</em> than its immediate reward of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>5</mn><annotation encoding="application/x-tex">5</annotation></semantics></math>, because from <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math> the agent is taken to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>′</mi></mrow><annotation encoding="application/x-tex">B'</annotation></semantics></math> which has a positive value.
<ul>
<li>From <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>′</mi></mrow><annotation encoding="application/x-tex">B'</annotation></semantics></math> the expected penalty (negative reward) for possibly running into an edge is more than compensated for by the expected gain for possibly stumbling onto <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math> or <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>.</li>
</ul></li>
</ul>
</div>
</div>
</div><div class="column" style="width:20%;">
<center>
<p><img src="contents/assets/gridworld1.png" width="85%" img=""></p>
<p><img src="contents/assets/gridworld2.png" width="40%" img=""></p>
<img src="contents/assets/gridworld3.png" width="85%" img="">
</center>
</div>
</div>
</section>
<section id="optimal-policies-and-optimal-value-functions" class="slide level2 smaller">
<h2><span style="font-size:99%"> Optimal Policies and Optimal Value Functions </span></h2>
<ul>
<li><p>We want to find a policy that achieves a lot of reward over the long run.</p></li>
<li><p>Value functions define a partial ordering over policies: a policy <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>π</mi><annotation encoding="application/x-tex">\pi</annotation></semantics></math> is defined to be better than or equal to a policy <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mi>′</mi></mrow><annotation encoding="application/x-tex">\pi'</annotation></semantics></math> if its expected return is greater than or equal to that of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mi>′</mi></mrow><annotation encoding="application/x-tex">\pi'</annotation></semantics></math> for all states. <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo>≥</mo><mi>π</mi><mi>′</mi><mo>⇔</mo><msub><mi>v</mi><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≥</mo><msub><mi>v</mi><mrow><mi>π</mi><mi>′</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><mspace width="1.0em"></mspace><mo>∀</mo><mi>s</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mi>.</mi></mrow><annotation encoding="application/x-tex"> \pi \geq \pi' \Longleftrightarrow v_{\pi}(s) \geq v_{\pi'}(s), \quad
\forall s \in \mathcal{S}. </annotation></semantics></math></p></li>
<li><p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mo>∃</mo><annotation encoding="application/x-tex">\exists</annotation></semantics></math> always at least one policy that is better than or equal to all other policies: an <em>optimal policy</em>.</p>
<ul>
<li><p>Although there may be more than one, let us denot all the optimal policies by <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>π</mi><mo>*</mo></msub><annotation encoding="application/x-tex">\pi_\ast</annotation></semantics></math>.</p></li>
<li><p>They share the same state-value function, called the <em>optimal state-value function</em>:</p>
<p><span id="eq-optimal-st-val"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mo>*</mo></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≜</mo><munder><mo>max</mo><mi>π</mi></munder><msub><mi>v</mi><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><mspace width="1.0em"></mspace><mo>∀</mo><mi>s</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mi>.</mi><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>13</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> v_\ast(s) \triangleq \operatorname{max}_\pi v_{\pi}(s), \quad
\forall s \in \mathcal{S}.  \qquad(13)</annotation></semantics></math></span></p></li>
</ul></li>
<li><p>Optimal policies also share the same <em>optimal action-value function</em>:</p>
<p><span id="eq-optimal-act-val"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mo>*</mo></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≜</mo><munder><mo>max</mo><mi>π</mi></munder><msub><mi>q</mi><mi>π</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><mspace width="1.0em"></mspace><mo>∀</mo><mi>s</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo>,</mo><mspace width="0.278em"></mspace><mi>a</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒜</mi></mstyle><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>14</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> q_\ast(s, a) \triangleq \operatorname{max}_\pi q_{\pi}(s, a), \quad
  \forall s \in \mathcal{S}, \; a \in \mathcal{A}(s).  \qquad(14)</annotation></semantics></math></span></p></li>
<li><p>For the state-action pair <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(s,a)</annotation></semantics></math>, this function gives the expected return for taking action <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation encoding="application/x-tex">a</annotation></semantics></math> in state <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>s</mi><annotation encoding="application/x-tex">s</annotation></semantics></math> and thereafter following an optimal policy.</p>
<ul>
<li>Thus, we can write <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>q</mi><mo>*</mo></msub><annotation encoding="application/x-tex">q_\ast</annotation></semantics></math> in terms of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>v</mi><mo>*</mo></msub><annotation encoding="application/x-tex">v_\ast</annotation></semantics></math> as follows: <span id="eq-q-w-v"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mo>*</mo></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>γ</mi><msub><mi>v</mi><mo>*</mo></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>∣</mo><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi><mo>,</mo><msub><mi>A</mi><mi>t</mi></msub><mo>=</mo><mi>a</mi><mo stretchy="true" form="postfix">]</mo></mrow><mi>.</mi><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>15</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> q_\ast (s, a) = \mathbb{E}[R_{t+1} + \gamma v_\ast(S_{t+1}) \mid S_t = s, A_t =
a].  \qquad(15)</annotation></semantics></math></span></li>
</ul></li>
</ul>
</section>
<section id="bellman-optimality-equation" class="slide level2 smaller">
<h2>Bellman Optimality Equation</h2>
<ul>
<li>Because <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>v</mi><mo>*</mo></msub><annotation encoding="application/x-tex">v_\ast</annotation></semantics></math> is the value function for a policy, it must satisfy the self-consistency condition given by the Bellman equation for state values <a href="#/eq-bellman">Equation&nbsp;12</a>.</li>
<li>But it is also the optimal value function so <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>v</mi><mo>*</mo></msub><annotation encoding="application/x-tex">v_\ast</annotation></semantics></math>’s consistency condition can be written in a special form w/o reference to any specific policy!</li>
</ul>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>The Bellman optimality equation expresses the fact that the value of a state under an optimal policy must equal the expected return for the best action from that state.</p>
</div>
</div>
</div>
<p><span id="eq-bellman-optimality-v"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtable><mtr><mtd columnalign="right"><msub><mi>v</mi><mo>*</mo></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left"><mo>=</mo><munder><mo>max</mo><mrow><mi>a</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒜</mi></mstyle><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></munder><msub><mi>q</mi><msub><mi>π</mi><mo>*</mo></msub></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munder><mo>max</mo><mi>a</mi></munder><msub><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><msub><mi>π</mi><mo>*</mo></msub></msub><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>G</mi><mi>t</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi><mo>,</mo><msub><mi>A</mi><mi>t</mi></msub><mo>=</mo><mi>a</mi><mo stretchy="true" form="postfix">]</mo></mrow></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>=</mo><munder><mo>max</mo><mi>a</mi></munder><msub><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><msub><mi>π</mi><mo>*</mo></msub></msub><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>γ</mi><msub><mi>G</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi><mo>,</mo><msub><mi>A</mi><mi>t</mi></msub><mo>=</mo><mi>a</mi><mo stretchy="true" form="postfix">]</mo></mrow></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>=</mo><munder><mo>max</mo><mi>a</mi></munder><msub><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><msub><mi>π</mi><mo>*</mo></msub></msub><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>γ</mi><msub><mi>v</mi><mo>*</mo></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="false" form="prefix">|</mo><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi><mo>,</mo><msub><mi>A</mi><mi>t</mi></msub><mo>=</mo><mi>a</mi><mo stretchy="true" form="postfix">]</mo></mrow></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mo>=</mo><munder><mo>max</mo><mi>a</mi></munder><munder><mo>∑</mo><mrow><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi></mrow></munder><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">[</mo><mi>r</mi><mo>+</mo><mi>γ</mi><msub><mi>v</mi><mo>*</mo></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">]</mo></mrow><mi>.</mi></mtd></mtr></mtable><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>16</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\begin{align}
v_\ast(s) &amp;= \operatorname{max}_{a \in \mathcal{A}(s)} q_{\pi_\ast}(s, a) =
\operatorname{max}_{a} \mathbb{E}_{\pi_\ast}[G_t | S_t =s, A_t = a] \\
&amp;= \operatorname{max}_a \mathbb{E}_{\pi_\ast}[R_{t+1} + \gamma G_{t+1} | S_t =
s, A_t = a] \\
&amp;= \operatorname{max}_a \mathbb{E}_{\pi_\ast}[R_{t+1} + \gamma v_\ast(S_{t+1}) | S_t =
s, A_t = a] \\
&amp;= \operatorname{max}_a \sum_{s', r} p(s', r|s, a)[r + \gamma v_\ast(s')].
\end{align}
 \qquad(16)</annotation></semantics></math></span></p>
<ul>
<li>The Bellman optimality equation for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>q</mi><mo>*</mo></msub><annotation encoding="application/x-tex">q_\ast</annotation></semantics></math> is</li>
</ul>
<p><span id="eq-bellman-optimality-q"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mo>*</mo></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>R</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>γ</mi><munder><mo>max</mo><mrow><mi>a</mi><mi>′</mi></mrow></munder><msub><mi>q</mi><mo>*</mo></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>∣</mo><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi><mo>,</mo><msub><mi>A</mi><mi>t</mi></msub><mo>=</mo><mi>a</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><munder><mo>∑</mo><mrow><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi></mrow></munder><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo>,</mo><mi>r</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">[</mo><mi>r</mi><mo>+</mo><mi>γ</mi><munder><mo>max</mo><mrow><mi>a</mi><mi>′</mi></mrow></munder><msub><mi>q</mi><mo>*</mo></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo>,</mo><mi>a</mi><mi>′</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">]</mo></mrow><mi>.</mi><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>17</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
q_\ast(s, a) = \mathbb{E}\left[R_{t+1} + \gamma \operatorname{max}_{a'}
q_\ast(S_{t+1}, a) \mid S_t = s, A_t = a\right] = \sum_{s', r} p(s', r|s, a) 
\left[ r+ \gamma \operatorname{max}_{a'} q_\ast (s', a') \right].
 \qquad(17)</annotation></semantics></math></span></p>
</section></section>
<section>
<section id="bellman-optimality-and-linear-programming" class="title-slide slide level1 center">
<h1>Bellman Optimality and Linear Programming</h1>

</section>
<section id="linear-programming-methods" class="slide level2 smaller">
<h2>Linear Programming Methods</h2>
<div class="columns">
<div class="column" style="width:43%;">
<div class="callout callout-note no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Short-hand notation</strong></p>
</div>
<div class="callout-content">
<p>For any function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>:</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo>→</mo><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle></mrow><annotation encoding="application/x-tex">J: \mathcal{S} \rightarrow \mathbb{R}</annotation></semantics></math>, define the functional <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>J</mi></mrow><annotation encoding="application/x-tex">TJ</annotation></semantics></math> by</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right"><mrow><mo stretchy="true" form="prefix">(</mo><mi>T</mi><mi>J</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munder><mo>max</mo><mrow><mi>a</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒜</mi></mstyle><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></munder></mtd><mtd columnalign="left"><mi>r</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mstyle mathvariant="double-struck"><mi>𝔼</mi></mstyle><mrow><mo stretchy="true" form="prefix">[</mo><mi>γ</mi><mi>J</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>S</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>∣</mo></mrow></mtd></mtr><mtr><mtd columnalign="right"></mtd><mtd columnalign="left"><mrow><msub><mi>S</mi><mi>t</mi></msub><mo>=</mo><mi>s</mi><mo>,</mo><msub><mi>A</mi><mi>t</mi></msub><mo>=</mo><mi>a</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>,</mo><mspace width="1.0em"></mspace><mi>s</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex"> 
\begin{align}
(TJ)(s) = \operatorname{max}_{a \in \mathcal{A}(s)} &amp;r(s,a) + \mathbb{E}\left[ 
    \gamma J(S_{t+1}) \mid \right. \\
    &amp;\left. S_t = s, A_t = a\right], \quad s \in \mathcal{S}.
\end{align}
</annotation></semantics></math></p>
</div>
</div>
</div>
</div><div class="column" style="width:57%;">
<div class="callout callout-tip no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Monotonicity Lemma</strong></p>
</div>
<div class="callout-content">
<p>For any <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>:</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo>→</mo><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle></mrow><annotation encoding="application/x-tex">J: \mathcal{S} \rightarrow \mathbb{R}</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mi>′</mi><mo>:</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo>→</mo><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle></mrow><annotation encoding="application/x-tex">J': \mathcal{S} \rightarrow \mathbb{R}</annotation></semantics></math>, such that for all <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle></mrow><annotation encoding="application/x-tex">s \in \mathcal{S}</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≥</mo><mi>J</mi><mi>′</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">J(s) \geq J'(s)</annotation></semantics></math>, and any stationary policy <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo>:</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo>→</mo><mstyle mathvariant="script"><mi>𝒜</mi></mstyle></mrow><annotation encoding="application/x-tex">\pi: \mathcal{S} \rightarrow \mathcal{A}</annotation></semantics></math>, we have <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>T</mi><mi>k</mi></msup><mi>J</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≥</mo><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>T</mi><mi>k</mi></msup><mi>J</mi><mi>′</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><mspace width="1.0em"></mspace><mi>s</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo>,</mo><mspace width="0.278em"></mspace><mspace width="0.278em"></mspace><mi>k</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi>…</mi><mi>.</mi></mrow><annotation encoding="application/x-tex"> (T^kJ)(s) \geq (T^kJ')(s), \quad s \in \mathcal{S}, \;\; k = 1, 2, \ldots . </annotation></semantics></math> In particular, if <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>:</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo>→</mo><mstyle mathvariant="script"><mi>ℛ</mi></mstyle></mrow><annotation encoding="application/x-tex">J: \mathcal{S} \rightarrow \mathcal{R}</annotation></semantics></math> is such that for all <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle></mrow><annotation encoding="application/x-tex">s \in \mathcal{S}</annotation></semantics></math>, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≥</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>T</mi><mi>J</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">J(s) \geq (TJ)(s)</annotation></semantics></math>, <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>T</mi><mi>k</mi></msup><mi>J</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≥</mo><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>T</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msup><mi>J</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><mspace width="1.0em"></mspace><mi>s</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo>,</mo><mspace width="0.278em"></mspace><mspace width="0.278em"></mspace><mi>k</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi>…</mi><mi>.</mi></mrow><annotation encoding="application/x-tex"> (T^kJ)(s) \geq (T^{k+1}J)(s), \quad s \in \mathcal{S}, \;\; k = 1, 2, \ldots .</annotation></semantics></math></p>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-important no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Main idea</strong></p>
</div>
<div class="callout-content">
<p>Since <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math> is monotone, if <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>≥</mo><mi>T</mi><mi>J</mi></mrow><annotation encoding="application/x-tex">J \geq TJ</annotation></semantics></math> for some <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>J</mi><annotation encoding="application/x-tex">J</annotation></semantics></math>, we also have <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>≥</mo><msup><mi>T</mi><mi>k</mi></msup><mi>J</mi></mrow><annotation encoding="application/x-tex">J \geq T^kJ</annotation></semantics></math> for all <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math> and since<sup>1</sup> <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo>lim</mo><mrow><mi>k</mi><mo>→</mo><mi>∞</mi></mrow></msub><msup><mi>T</mi><mi>k</mi></msup><mi>J</mi><mo>=</mo><msup><mi>J</mi><mo>*</mo></msup></mrow><annotation encoding="application/x-tex">\lim_{k\rightarrow \infty} T^kJ = J^\ast</annotation></semantics></math>, it follows that <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>≥</mo><mi>T</mi><mi>J</mi><mspace width="1.0em"></mspace><mo>⇒</mo><mspace width="1.0em"></mspace><mi>J</mi><mo>≥</mo><msup><mi>J</mi><mo>*</mo></msup><mo>=</mo><mi>T</mi><msup><mi>J</mi><mo>*</mo></msup><mi>.</mi></mrow><annotation encoding="application/x-tex"> J \geq TJ \quad \Rightarrow \quad J \geq J^\ast = TJ^\ast. </annotation></semantics></math></p>
<ul>
<li>Thus, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>J</mi><mo>*</mo></msup><annotation encoding="application/x-tex">J^\ast</annotation></semantics></math> is the “smallest” <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>J</mi><annotation encoding="application/x-tex">J</annotation></semantics></math> that satisfies the constraint <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>≥</mo><mi>T</mi><mi>J</mi></mrow><annotation encoding="application/x-tex">J \geq TJ</annotation></semantics></math>.</li>
<li>This constraint can be written as a finite system of linear inequalities, yielding an LP to find the optimal value function.</li>
</ul>
</div>
</div>
</div>
<p><span id="eq-mdp-lp"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtable><mtr><mtd columnalign="right"><mo>minimize</mo></mtd><mtd columnalign="left"><munder><mo>∑</mo><mi>s</mi></munder><mi>J</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="right"><mtext mathvariant="normal">subject to</mtext></mtd><mtd columnalign="left"><mi>J</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≥</mo><mi>r</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>γ</mi><munder><mo>∑</mo><mrow><mi>s</mi><mi>′</mi></mrow></munder><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>J</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><mspace width="1.0em"></mspace><mi>s</mi><mo>,</mo><mi>s</mi><mi>′</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo>,</mo><mspace width="0.278em"></mspace><mspace width="0.278em"></mspace><mi>a</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒜</mi></mstyle><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mtd></mtr></mtable><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>18</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\begin{align}
\operatorname{minimize} &amp; \sum_{s} J(s) \\
\text{subject to} &amp; J(s) \geq r(s,a) + \gamma \sum_{s'} p(s'|s,a) J(s'), \quad
s, s' \in \mathcal{S}, \;\; a \in \mathcal{A}(s).
\end{align}
 \qquad(18)</annotation></semantics></math></span></p>
<aside><ol class="aside-footnotes"><li id="fn1"><p>D. Bertsekas, <em>Dynamic Programming and Optimal Control</em> Vol. 2, Athena Scientific, 2018</p></li></ol></aside></section>
<section id="cost-approximation-based-on-lp" class="slide level2 smaller">
<h2>Cost Approximation-Based on LP</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li>When the number of states is very large or infinite, we may consdier finding an approximation to the optimal value fuinction.
<ul>
<li>This can be used, in turn, to obtain a (suboptimal) policy by maximization in Bellman’s equation.</li>
</ul></li>
</ul>
</div><div class="column" style="width:50%;">
<div class="callout callout-important no-icon callout-captioned callout-style-default">
<div class="callout-body">
<div class="callout-caption">
<p><strong>Linear form approximation</strong></p>
</div>
<div class="callout-content">
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>J</mi><mo accent="true">̃</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>;</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>s</mi></munderover><msub><mi>θ</mi><mi>k</mi></msub><msub><mi>ϕ</mi><mi>k</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex"> \tilde{J}(s; \theta) = \sum_{k=1}^s \theta_k \phi_k(s), </annotation></semantics></math></p>
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>θ</mi><mn>1</mn></msub><mo>,</mo><msub><mi>θ</mi><mn>2</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>θ</mi><mi>s</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\theta = (\theta_1, \theta_2, \ldots, \theta_s)</annotation></semantics></math> is a vector of parameters.</li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϕ</mi><mi>k</mi></msub><mo>:</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo>→</mo><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle></mrow><annotation encoding="application/x-tex">\phi_k: \mathcal{S} \rightarrow \mathbb{R}</annotation></semantics></math> are some fixed known functions &amp;ndash, called the <em>basis</em> functions.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<ul>
<li>It is then possible to determine <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>θ</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math> by using <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>J</mi><mo accent="true">̃</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>;</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\tilde{J}(s; \theta)</annotation></semantics></math> in place of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>J</mi><mo>*</mo></msup><annotation encoding="application/x-tex">J^\ast</annotation></semantics></math> in the LP approach.
<ul>
<li>In particular, we optimize over <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>θ</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math> the following program</li>
</ul></li>
</ul>
<p><span id="eq-mdp-lp-approx"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtable><mtr><mtd columnalign="right"><mo>minimize</mo></mtd><mtd columnalign="left"><munder><mo>∑</mo><mrow><mi>s</mi><mo>∈</mo><mover><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo accent="true">̃</mo></mover></mrow></munder><mover><mi>J</mi><mo accent="true">̃</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>;</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="right"><mtext mathvariant="normal">subject to</mtext></mtd><mtd columnalign="left"><mover><mi>J</mi><mo accent="true">̃</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>;</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≥</mo><mi>r</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>γ</mi><munder><mo>∑</mo><mrow><mi>s</mi><mi>′</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle></mrow></munder><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo stretchy="false" form="prefix">|</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow><mover><mi>J</mi><mo accent="true">̃</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mi>′</mi><mo>;</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><mspace width="1.0em"></mspace><mi>s</mi><mo>∈</mo><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo>,</mo><mspace width="0.278em"></mspace><mspace width="0.278em"></mspace><mi>a</mi><mo>∈</mo><mover><mstyle mathvariant="script"><mi>𝒜</mi></mstyle><mo accent="true">̃</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mtd></mtr></mtable><mspace width="2.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>19</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\begin{align}
\operatorname{minimize} &amp; \sum_{s \in \tilde{\mathcal{S}}} \tilde{J}(s; \theta) \\
\text{subject to} &amp; \tilde{J}(s; \theta) \geq r(s, a) + \gamma \sum_{s' \in
\mathcal{S}} p(s' | s, a) \tilde{J}(s'; \theta), \quad s \in \mathcal{S}, \;\; a
\in \tilde{\mathcal{A}}(s),
\end{align}
 \qquad(19)</annotation></semantics></math></span></p>
<ul>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><mo accent="true">̃</mo></mover><annotation encoding="application/x-tex">\tilde{\mathcal{S}}</annotation></semantics></math> is either the state-space <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><annotation encoding="application/x-tex">\mathcal{S}</annotation></semantics></math> or a suitably chosen finite subset of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="script"><mi>𝒮</mi></mstyle><annotation encoding="application/x-tex">\mathcal{S}</annotation></semantics></math>,</li>
<li><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mstyle mathvariant="script"><mi>𝒜</mi></mstyle><mo accent="true">̃</mo></mover><annotation encoding="application/x-tex">\tilde{\mathcal{A}}</annotation></semantics></math> is either the action-space <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="script"><mi>𝒜</mi></mstyle><annotation encoding="application/x-tex">\mathcal{A}</annotation></semantics></math> or a suitably chosen finite subset of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mstyle mathvariant="script"><mi>𝒜</mi></mstyle><annotation encoding="application/x-tex">\mathcal{A}</annotation></semantics></math>.</li>
</ul>

<div class="footer footer-default">
<p>Optimization Theory and Practice • Aykut C. Satici</p>
</div>
</section></section>

    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-pointer/pointer.js"></script>
  <script src="site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="site_libs/revealjs/plugin/search/search.js"></script>
  <script src="site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': true,
'smaller': false,
'pdfSeparateFragments': true,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":false},
'pointer': {"key":"q","color":"#32cd32","pointerSize":18,"alwaysVisible":false},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, RevealPointer, QuartoSupport,

          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>