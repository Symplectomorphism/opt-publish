[
  {
    "objectID": "08_constrained.html#optimization-theory-and-practice",
    "href": "08_constrained.html#optimization-theory-and-practice",
    "title": "08_constrained",
    "section": "Optimization Theory and Practice",
    "text": "Optimization Theory and Practice\n\n\nConstrained Optimization Conditions\n\n\n\n\nInstructor: Aykut Satici, Ph.D.Â   Mechanical and Biomedical Engineering  Electrical and Computer Engineering  Boise State University, Boise, ID, USA\n\n\nTopics:  Constraints and Tangent Plane  First-Order Necessary Conditions (Equality)  Equality Constrained Examples  Second Order Conditions (Equality)  Inequality Constraints"
  },
  {
    "objectID": "08_constrained.html#constraints",
    "href": "08_constrained.html#constraints",
    "title": "08_constrained",
    "section": "Constraints",
    "text": "Constraints\nGeneral nonlinear programming problems are of the form\n\n\nminimizef(ğ±)subject toğ¡(ğ±)=ğŸ,ğ (ğ±)â‰¥ğŸ,ğ±âˆˆÎ©.\n\\begin{align}\n\\operatorname{minimize} & f(\\bm{x}) \\\\\n\\text{subject to} & \\bm{h}(\\bm{x}) = \\bm{0}, \\;\\; \\bm{g}(\\bm{x}) \\geq \\bm{0}, \\\\ \n& \\bm{x} \\in \\Omega.\n\\end{align}\n\n\nAn inequality constraint is said to be active at ğ±\\bm{x} if gi(ğ±)=0g_i(\\bm{x}) = 0.\nIt is said to be inactive if gi(ğ±)&gt;0g_i(\\bm{x}) &gt; 0.\nAny equality constraint hi(ğ±)=0h_i(\\bm{x}) = 0 is active.\nIn the figure, g1g_1 is active, g2g_2 and g3g_3 are not.\nIf it were known a priori which constraints were active at an optimal solution then it would be a local minimum point of the problem defined by ignoring the inactive constraints.\n\n\n\nğ¡=(h1,h2,â€¦,hm)\\bm{h} = (h_1, h_2, \\ldots, h_m), ğ =(g1,g2,â€¦,gp)\\;\\;\\bm{g} = (g_1, g_2, \\ldots, g_p) are functional constraints.\nğ±âˆˆÎ©\\bm{x} \\in \\Omega: set constraint.\n\n\n\n\n\n\n\nWe will therefore start by ignoring the inequality constraints and come back to them later."
  },
  {
    "objectID": "08_constrained.html#tangent-plane",
    "href": "08_constrained.html#tangent-plane",
    "title": "08_constrained",
    "section": "Tangent Plane",
    "text": "Tangent Plane\n\nThe equality constraints define a (hyper)surface S={ğ±:h1(ğ±)=h2(ğ±)=â‹¯=hm(ğ±)=0}S = \\{\\bm{x}: h_1(\\bm{x}) = h_2(\\bm{x}) = \\cdots = h_m(\\bm{x}) = 0\\} of â„n\\mathbb{R}^n.\n\nThis hypersurface is of dimension nâˆ’mn-m (subject to a regularity assumption).\nIf the functions hih_i are continuously differentiable, the surface is said to be smooth.\n\nAssociated with a point on a smooth surface is the tangent plane at that point.\n\nA curve on a surface SS is a familty of points ğ±(t)âˆˆS\\bm{x}(t) \\in S, aâ‰¤tâ‰¤ba \\leq t \\leq b.\nThe curve is differentiable if ğ±Ì‡(t)=ddtğ±(t)\\dot{\\bm{x}}(t) = \\frac{d}{d t}\\bm{x}(t) exists, and is twice differentiable if ğ±Ìˆ(t)\\ddot{\\bm{x}}(t) exists.\nA curve ğ±(t)\\bm{x}(t) is said to pass through the point ğ±*\\bm{x}^\\ast if ğ±*=ğ±(t*)\\bm{x}^\\ast = \\bm{x}(t^\\ast) for some aâ‰¤t*â‰¤ba \\leq t^\\ast \\leq b.\n\n\n\n\n\nTangent Plane\n\n\nConsider all differentiable curves on SS passing through a point ğ±*\\bm{x}^\\ast. The tangent plane Tx*ST_{x^\\ast}S at ğ±*\\bm{x}^\\ast of SS is defined as the collection of hte derivatives at ğ±*\\bm{x}^\\ast of all these differentiable curves.\nIf ğ±*\\bm{x}^\\ast is a regular point (to be defined) then we can make the following identification:\nTğ±*S=Mâ‰œ{ğ:âˆ‡ğ¡(ğ±*)ğ=ğŸ}. T_{\\bm{x}^\\ast}S = M \\triangleq \\{\\bm{d}: \\nabla \\bm{h}(\\bm{x}^\\ast)\\bm{d} =\n\\bm{0} \\}."
  },
  {
    "objectID": "08_constrained.html#tangent-plane-2",
    "href": "08_constrained.html#tangent-plane-2",
    "title": "08_constrained",
    "section": "Tangent Plane",
    "text": "Tangent Plane\n\n\n\n\n\nDefinition (Regular Point)\n\n\nA point ğ±*\\bm{x}^\\ast satisfying the constraint ğ¡(ğ±*)=ğŸ\\bm{h}(\\bm{x}^\\ast) = \\bm{0} is said to be a regular point of the constraint if the gradient vectors âˆ‡h1(ğ±*),âˆ‡h2(ğ±*),â€¦,âˆ‡hm(ğ±*)\\nabla h_1(\\bm{x}^\\ast), \\nabla h_2(\\bm{x}^\\ast), \\ldots, \\nabla h_m(\\bm{x}^\\ast) are linearly independent."
  },
  {
    "objectID": "08_constrained.html#first-order-necessary-conditions-1",
    "href": "08_constrained.html#first-order-necessary-conditions-1",
    "title": "08_constrained",
    "section": "First-Order Necessary Conditions",
    "text": "First-Order Necessary Conditions\n\n\n\n\n\nLemma\n\n\nLet ğ±*\\bm{x}^\\ast be a regular point of the constraints ğ¡(ğ±)=ğŸ\\bm{h}(\\bm{x}) = \\bm{0} and a local extremum point of ff subject to these constraints. Then for all ğâˆˆâ„n\\bm{d} \\in \\mathbb{R}^n, we have âˆ‡ğ¡(ğ±*)ğ=ğŸâ‡’âˆ‡f(ğ±*)ğ=0. \\nabla \\bm{h}(\\bm{x}^\\ast) \\bm{d} = \\bm{0} \\;\\; \\Rightarrow \\;\\; \\nabla\nf(\\bm{x}^\\ast)\\bm{d} = 0. \n\n\n\n\n\n\nProof\n\n\nLet ğâˆˆTğ±*S\\bm{d} \\in T_{\\bm{x}^\\ast}S and let ğ±(t)âˆˆS\\bm{x}(t) \\in S such that ğ±(0)=ğ±*\\bm{x}(0) = \\bm{x}^\\ast and ğ±Ì‡(0)=ğ\\dot{\\bm{x}}(0) = \\bm{d} for âˆ’aâ‰¤tâ‰¤a-a \\leq t \\leq a for some a&gt;0a &gt; 0.\nSince ğ±*\\bm{x}^\\ast is a constrained local minimum point of ff, we have\nddtf(ğ±(t))|t=0=âˆ‡f(ğ±*)ğ=0. \\frac{d}{dt}f(\\bm{x}(t))\\Bigg\\rvert_{t=0} = \\nabla f(\\bm{x}^\\ast) \\bm{d} = 0.\n\n\n\n\n\n\n\nThis lemma says that âˆ‡f(ğ±*)âŠ¥Tğ±*S\\quad \\nabla f(\\bm{x}^\\ast) \\perp T_{\\bm{x}^\\ast}S.\n\n\n\n\n\n\n\nTheorem (FONC)\n\n\nLet ğ±*\\bm{x}^\\ast be a regular local minimum point of ff subject to the constraint ğ¡(ğ±)=ğŸ\\bm{h}(\\bm{x}) = \\bm{0}. Then there is a ğ›Œâˆˆâ„m\\bm{\\lambda} \\in \\mathbb{R}^m such that\nâˆ‡f(ğ±*)âˆ’ğ›ŒâŠ¤âˆ‡ğ¡(ğ±*)=ğŸ.(1) \\nabla f(\\bm{x}^\\ast) - \\bm{\\lambda}^\\top \\nabla \\bm{h}(\\bm{x}^\\ast) =\n\\bm{0}.  \\qquad(1)\n\n\n\n\n\n\nProof\n\n\nFrom the lemma, we may conclude that the linear system\nâˆ‡f(ğ±*)ğâ‰ 0,andâˆ‡ğ¡(ğ±*)ğ=ğŸ \\nabla f(\\bm{x}^\\ast) \\bm{d} \\neq 0, \\;\\; \\text{and} \\;\\; \\nabla\n\\bm{h}(\\bm{x}^\\ast)\\bm{d} = \\bm{0} \nHas no feasible solution ğ\\bm{d}. Then, by Farkasâ€™s lemma, its alternative system must have a solution. Specifically, there is a ğ›Œâˆˆâ„m\\bm{\\lambda} \\in \\mathbb{R}^m such that âˆ‡f(ğ±*)âˆ’ğ›ŒâŠ¤âˆ‡ğ¡(ğ±*)=ğŸ\\nabla f(\\bm{x}^\\ast) - \\bm{\\lambda}^\\top \\nabla \\bm{h}(\\bm{x}^\\ast) = \\bm{0}.\n\n\n\n\n\n\nThe FONC EquationÂ 1 together with the constraints ğ¡(ğ±*)=ğŸ\\bm{h}(\\bm{x}^\\ast) = \\bm{0} give a total of n+mn+m equations in the n+mn+m variables comprising ğ±*,ğ›Œ\\bm{x}^\\ast, \\bm{\\lambda}."
  },
  {
    "objectID": "08_constrained.html#lagrangian",
    "href": "08_constrained.html#lagrangian",
    "title": "08_constrained",
    "section": "Lagrangian",
    "text": "Lagrangian\n\nIntroduce the Lagrangian associated with the constrained problem, defined as\n\nâ„“(ğ±,ğ›Œ)=f(ğ±)âˆ’ğ›ŒâŠ¤ğ¡(ğ±).(2) \\ell(\\bm{x}, \\bm{\\lambda}) = f(\\bm{x}) - \\bm{\\lambda}^\\top \\bm{h}(\\bm{x}).  \\qquad(2)\n\nThe FONC can then be expressed as the Lagrangian derivatives\n\nâˆ‡ğ±â„“(ğ±,ğ›Œ)=ğŸ,âˆ‡ğ›Œâ„“(ğ±,ğ›Œ)=ğŸ.(3)\n\\nabla_{\\bm{x}} \\ell(\\bm{x}, \\bm{\\lambda}) = \\bm{0}, \\qquad\n\\nabla_{\\bm{\\lambda}} \\ell(\\bm{x}, \\bm{\\lambda}) = \\bm{0}.\n \\qquad(3)\n\nThe Lagrangian can be viewed as a combined objective function with a penalized term on the cosntraint violations.\n\nEach Î»i\\lambda_i is the penalty weight on equality constraint hi(ğ±)=0h_i(\\bm{x}) = 0.\nWith appropriate Î»i\\lambda_iâ€™s, a constrained problem could then be solved as an unconstrained optimization problem.\nIf ff is convex and ğ¡(ğ±)\\bm{h}(\\bm{x}) is affine ğ€ğ±âˆ’ğ›\\bm{Ax} - \\bm{b}, then â„“(â‹…)\\ell(\\cdot) is convex in ğ±\\bm{x} for every fixed ğ›Œ\\bm{\\lambda}.\n\n\n\n\n\nTheorem\n\n\nThe first-order necessary conditions are sufficient if ff is convex and ğ¡\\bm{h} is affine."
  },
  {
    "objectID": "08_constrained.html#sensitivity",
    "href": "08_constrained.html#sensitivity",
    "title": "08_constrained",
    "section": "Sensitivity",
    "text": "Sensitivity\n\nThe Lagrange multipliers associated with a constrained minimization problem have an interpretation as prices, similar to the prices in LP.\nLet a minimal solution ğ±*\\bm{x}^\\ast be a regular point and ğ›Œ*\\bm{\\lambda}^\\ast be the corresponding Lagrange multiplier vector. Consider the family of problems\n\nz(ğ›)=minimizef(ğ±)1234subject toğ¡(ğ±)=ğ›,ğ›âˆˆâ„m.(4)\n\\begin{align}\nz(\\bm{b}) = &\\operatorname{minimize} &f(\\bm{x}) \\phantom{1234} & \\\\\n& \\text{subject to} & \\bm{h}(\\bm{x}) = \\bm{b}, & \\bm{b} \\in \\mathbb{R}^m.\n\\end{align}\n \\qquad(4)\n\nFor sufficiently small |ğ›||\\bm{b}|, the problem will have a solution point ğ±(ğ›)\\bm{x}(\\bm{b}) near ğ±(ğŸ)=ğ±*\\bm{x}(\\bm{0}) = \\bm{x}^\\ast.\n\nFor each of these solutions, there is a corresponding minimum value z(ğ›)=f(ğ±(ğ›))z(\\bm{b}) = f(\\bm{x}(\\bm{b})).\nThe components of the gradient of this function can be regarded as the incremental rate of change in value per unit change in the constraint requirement.\n\n\n\n\n\nSensitivity Theorem\n\n\nConsider the family of problems EquationÂ 4. Suppose that for every ğ›âˆˆâ„m\\bm{b} \\in \\mathbb{R}^m in a region containing ğŸ\\bm{0}, its minimizer ğ±(ğ›)\\bm{x}(\\bm{b}) is continuously differentiable depending on ğ›\\bm{b}. Let ğ±*=ğ±(ğŸ)\\bm{x}^\\ast = \\bm{x}(\\bm{0}) with the corresponding Lagrange multiplier ğ›Œ*\\bm{\\lambda}^\\ast. Then\nâˆ‡z(ğŸ)=âˆ‡ğ›f(ğ±(ğ›))|ğ›=ğŸ=(ğ›Œ*)âŠ¤. \\nabla z(\\bm{0}) = \\nabla_\\bm{b} f(\\bm{x}(\\bm{b}))\n\\Bigg\\rvert_{\\bm{b}=\\bm{0}} = \\left(\\bm{\\lambda}^\\ast\\right)^\\top."
  },
  {
    "objectID": "08_constrained.html#sensitivity-1",
    "href": "08_constrained.html#sensitivity-1",
    "title": "08_constrained",
    "section": "Sensitivity",
    "text": "Sensitivity\n\n\n\nSensitivity Theorem\n\n\nConsider the family of problems EquationÂ 4. Suppose that for every ğ›âˆˆâ„m\\bm{b} \\in \\mathbb{R}^m in a region containing ğŸ\\bm{0}, its minimizer ğ±(ğ›)\\bm{x}(\\bm{b}) is continuously differentiable depending on ğ›\\bm{b}. Let ğ±*=ğ±(ğŸ)\\bm{x}^\\ast = \\bm{x}(\\bm{0}) with the corresponding Lagrange multiplier ğ›Œ*\\bm{\\lambda}^\\ast. Then\nâˆ‡z(ğŸ)=âˆ‡ğ›f(ğ±(ğ›))|ğ›=ğŸ=(ğ›Œ*)âŠ¤. \\nabla z(\\bm{0}) = \\nabla_\\bm{b} f(\\bm{x}(\\bm{b}))\n\\Bigg\\rvert_{\\bm{b}=\\bm{0}} = \\left(\\bm{\\lambda}^\\ast\\right)^\\top. \n\n\n\n\n\n\nProof\n\n\nUsing the chain rule and taking derivatives with respect to ğ›\\bm{b} on both sides of\nğ›=ğ¡(ğ±(ğ›)) \\bm{b} = \\bm{h}(\\bm{x}(\\bm{b})) \nat ğ›=ğŸ\\bm{b} = \\bm{0}, we have\nğˆ=âˆ‡ğ›ğ¡(ğ±(ğ›))|ğ›=ğŸ=âˆ‡ğ±ğ¡(ğ±(ğŸ))âˆ‡ğ›ğ±(ğŸ)=âˆ‡ğ±ğ¡(ğ±*)âˆ‡ğ›ğ±(ğŸ). \\bm{I} = \\nabla_\\bm{b} \\bm{h}(\\bm{x}(\\bm{b})) \\Bigg\\rvert_{\\bm{b}=\\bm{0}} =\n\\nabla_\\bm{x} \\bm{h}(\\bm{x}(\\bm{0}))\\nabla_\\bm{b}\\bm{x}(\\bm{0}) =\n\\nabla_\\bm{x}\\bm{h}(\\bm{x}^\\ast)\\nabla_\\bm{b}\\bm{x}(\\bm{0}). \nOn the other hand, using the chain rule and the first-order condition for ğ±*\\bm{x}^\\ast and the above matrix equality\nâˆ‡ğ›f(ğ±(ğ›))|ğ›=ğŸ=âˆ‡f(ğ±(ğŸ))âˆ‡ğ›ğ±(ğŸ)=âˆ‡f(ğ±*)âˆ‡ğ›ğ±(ğŸ)=(ğ›Œ*)âŠ¤âˆ‡ğ±ğ¡(ğ±*)âˆ‡ğ›ğ±(ğŸ)=(ğ›Œ*)âŠ¤. \\nabla_\\bm{b} f(\\bm{x}(\\bm{b})) \\Bigg\\rvert_{\\bm{b}=\\bm{0}} = \\nabla\nf(\\bm{x}(\\bm{0})) \\nabla_{\\bm{b}}\\bm{x}(\\bm{0}) = \\nabla f(\\bm{x}^\\ast)\n\\nabla_{\\bm{b}}\\bm{x}(\\bm{0}) = \\left(\\bm{\\lambda}^\\ast\\right)^\\top \\nabla_\\bm{x}\n\\bm{h}(\\bm{x}^\\ast) \\nabla_\\bm{b} \\bm{x}(\\bm{0}) =\n\\left(\\bm{\\lambda}^\\ast\\right)^\\top."
  },
  {
    "objectID": "08_constrained.html#example-1-geometric-prog.-max-volume",
    "href": "08_constrained.html#example-1-geometric-prog.-max-volume",
    "title": "08_constrained",
    "section": "Example 1 â€“ Geometric Prog.: Max Volume",
    "text": "Example 1 â€“ Geometric Prog.: Max Volume\n\n\n\nWe seek to construct a cardboard box of maximum volume, given a fixed area of the cardboard.\n\n\n\n\n\n\n\n\n\nmaximizexyzsubject to(xy+yz+xz)=c2,c&gt;0(area).\n\\begin{align}\n\\operatorname{maximize} & xyz \\\\\n\\text{subject to} & (xy + yz + xz) = \\frac{c}{2}, \\quad c &gt; 0 \\,(\\text{area}).\n\\end{align}\n\n\n\n\n\n\n\nFirst-Order Necessary Conditions\n\n\nyzâˆ’Î»(y+z)=0,xzâˆ’Î»(x+z)=0,xyâˆ’Î»(x+y)=0.\n\\begin{align}\nyz - \\lambda (y+z) &= 0, \\\\\nxz - \\lambda (x+z) &= 0, \\\\\nxy - \\lambda (x+y) &= 0.\n\\end{align}\n\n\n\n\n\n\n\nSince no variables can be zero, we have x=y=z=c6andÎ»=6c12.x = y = z = \\sqrt{\\frac{c}{6}} \\quad \\text{and} \\quad \\lambda =\n\\frac{\\sqrt{6c}}{12}. \n\n\n\n\n\nSumming the FONC gives (xy+yz+xz)âˆ’2Î»(x+y+z)=0(xy + yz + xz) - 2\\lambda(x+y+z) = 0.\nUsing the constraint with this implies c2âˆ’2Î»(x+y+z)=0. \\frac{c}{2} - 2\\lambda(x+y+z) = 0. \n\nFrom this it is clear that Î»â‰ 0\\lambda \\neq 0.\n\nNext, we see that none of xx, yy, and zz are zero.\n\nThis is because if, say, x=0x=0, then zz becomes zero (second eq.), which implies y=0y=0 from the first equation.\n\nMultiply the first by xx, second by yy and subtract to obtain Î»(xâˆ’y)z=0. \\lambda(x-y)z = 0. \nSimilarly operate on second and third to obtain Î»(yâˆ’z)x=0\\lambda (y-z)x = 0."
  },
  {
    "objectID": "08_constrained.html#example-2-hanging-chain",
    "href": "08_constrained.html#example-2-hanging-chain",
    "title": "08_constrained",
    "section": "Example 2 â€“ Hanging Chain",
    "text": "Example 2 â€“ Hanging Chain"
  },
  {
    "objectID": "08_constrained.html#example-3-compressed-sensing",
    "href": "08_constrained.html#example-3-compressed-sensing",
    "title": "08_constrained",
    "section": "Example 3 â€“ Compressed Sensing",
    "text": "Example 3 â€“ Compressed Sensing"
  },
  {
    "objectID": "08_constrained.html#second-order-conditions-1",
    "href": "08_constrained.html#second-order-conditions-1",
    "title": "08_constrained",
    "section": "Second-Order Conditions",
    "text": "Second-Order Conditions\n\n\n\n\n\nTheorem (SONC)\n\n\nSuppose that ğ±*\\bm{x}^\\ast is a regular local minimum of ff subject to ğ¡(ğ±)=ğŸ\\bm{h}(\\bm{x}) = \\bm{0}. Then there is a ğ›Œâˆˆâ„m\\bm{\\lambda} \\in \\mathbb{R}^m such that âˆ‡f(ğ±*)âˆ’ğ›ŒâŠ¤âˆ‡ğ¡(ğ±*)=ğŸ.(5) \\nabla f(\\bm{x}^\\ast) - \\bm{\\lambda}^\\top \\nabla \\bm{h}(\\bm{x}^\\ast) =\n\\bm{0}.  \\qquad(5) If we denote by MM, the tangent plane, then the matrix ğ‹(ğ±*)=ğ…(ğ±*)âˆ’ğ›ŒâŠ¤ğ‡(ğ±*)â‰½ğŸ(6) \\bm{L}(\\bm{x}^\\ast) = \\bm{F}(\\bm{x}^\\ast) - \\bm{\\lambda}^\\top\n\\bm{H}(\\bm{x}^\\ast) \\succeq \\bm{0}  \\qquad(6) on MM, that is, ğâŠ¤ğ‹(ğ±*)ğâ‰¥ğŸ\\bm{d}^\\top \\bm{L}(\\bm{x}^\\ast) \\bm{d} \\geq \\bm{0}, âˆ€ğâˆˆM\\forall \\bm{d} \\in M.\n\n\n\n\n\n\nProof\n\n\nFrom elementary calculus for every twice differentiable curve ğ±(t)âˆˆS\\bm{x}(t) \\in S through ğ±*\\bm{x}^\\ast we have 0â‰¤d2dt2f(ğ±(t))|t=0=ğ±Ì‡(0)âŠ¤ğ…(ğ±*)ğ±Ì‡(0)+âˆ‡f(ğ±*)ğ±Ìˆ(0). 0 \\leq \\frac{d^2}{dt^2}f(\\bm{x}(t))\n\\Bigg\\rvert_{t=0} = \\dot{\\bm{x}}(0)^\\top \\bm{F}(\\bm{x}^\\ast) \\dot{\\bm{x}}(0) +\n\\nabla f(\\bm{x}^\\ast) \\ddot{\\bm{x}}(0).  Furthermore, differentiating the relation ğ›ŒâŠ¤ğ¡(ğ±(t))=0\\bm{\\lambda}^\\top \\bm{h}(\\bm{x}(t)) = 0 twice, we obtain ğ±Ì‡(0)âŠ¤ğ›ŒâŠ¤ğ‡(ğ±*)ğ±Ì‡(0)âˆ’ğ›ŒâŠ¤âˆ‡ğ¡(ğ±*)ğ±Ìˆ(0)=0.\n\\dot{\\bm{x}}(0)^\\top \\bm{\\lambda}^\\top \\bm{H}(\\bm{x}^\\ast)\\dot{\\bm{x}}(0) -\n\\bm{\\lambda}^\\top \\nabla \\bm{h}(\\bm{x}^\\ast) \\ddot{\\bm{x}}(0) = 0.  Additing these two equations yields the result d2dt2f(ğ±(t))|t=0=ğ±Ì‡(0)âŠ¤ğ‹(ğ±*)ğ±Ì‡(0)â‰¥0. \\frac{d^2}{dt^2}f(\\bm{x}(t)) \\Bigg\\rvert_{t=0} = \\dot{\\bm{x}}(0)^\\top\n\\bm{L}(\\bm{x}^\\ast) \\dot{\\bm{x}}(0) \\geq 0.  Since ğ±Ì‡(0)\\dot{\\bm{x}}(0) is arbitrary in MM, we have the stated conclusion.\n\n\n\n\n\n\n\nTheorem (SOSC)\n\n\nSuppose there is a point ğ±*\\bm{x}^\\ast satisfying ğ¡(ğ±*)=ğŸ\\bm{h}(\\bm{x}^\\ast) = \\bm{0}, and a ğ›Œ\\bm{\\lambda} such that EquationÂ 5 holds. Suppose also that the matrix ğ‹(ğ±*)â‰»ğŸ\\bm{L}(\\bm{x}^\\ast) \\succ \\bm{0} on MM. Then ğ±*\\bm{x}^\\ast is a strict local minimum of ff subject to ğ¡(ğ±)=ğŸ\\bm{h}(\\bm{x}) = \\bm{0}.\n\n\n\n\n\n\nProof\n\n\nIf ğ±*\\bm{x}^\\ast is not a strict relative minimum point, âˆƒ\\exists a sequence of feasible points {ğ²k}\\{\\bm{y}_k\\} converging to ğ±*\\bm{x}^\\ast s.t. for each kk, f(ğ²k)â‰¤f(ğ±*)f(\\bm{y}_k) \\leq f(\\bm{x}^\\ast). Write ğ²k=ğ±*+Î´kğ¬k\\bm{y}_k = \\bm{x}^\\ast + \\delta_k \\bm{s}_k, where |ğ¬k|=1|\\bm{s}_k| = 1 and Î´k&gt;0\\delta_k &gt; 0, âˆ€k\\forall k. By Bolzano-Weierstrass some subsequence of {ğ¬k}\\{\\bm{s}_k\\} converges. WLOG assume ğ¬kâ†’ğ¬*\\bm{s}_k \\rightarrow \\bm{s}^\\ast. We also have ğ¡(ğ²k)âˆ’ğ¡(ğ±*)=ğŸ\\bm{h}(\\bm{y}_k) - \\bm{h}(\\bm{x}^\\ast) = \\bm{0} which implies âˆ‡ğ¡(ğ±*)ğ¬*=ğŸ\\nabla \\bm{h}(\\bm{x}^\\ast)\\bm{s}^\\ast = \\bm{0}. We have\n0=hi(ğ²k)=hi(ğ±*)+Î´kâˆ‡hi(ğ±*)ğ¬k+Î´k22ğ¬kâŠ¤âˆ‡2hi(ğ›ˆi)ğ¬k(7) 0 = h_i(\\bm{y}_k) = h_i(\\bm{x}^\\ast) + \\delta_k \\nabla\nh_i(\\bm{x}^\\ast)\\bm{s}_k + \\frac{\\delta_k^2}{2}\\bm{s}_k^\\top \\nabla^2\nh_i(\\bm{\\eta}_i) \\bm{s}_k  \\qquad(7) 0â‰¥f(ğ²k)âˆ’f(ğ±*)=Î´kâˆ‡f(ğ±*)ğ¬k+Î´k22ğ¬kâŠ¤âˆ‡2f(ğ›ˆ0)ğ¬k(8) 0 \\geq f(\\bm{y}_k) - f(\\bm{x}^\\ast) =  \\delta_k \\nabla\nf(\\bm{x}^\\ast)\\bm{s}_k + \\frac{\\delta_k^2}{2}\\bm{s}_k^\\top \\nabla^2\nf(\\bm{\\eta}_0) \\bm{s}_k  \\qquad(8)\nMultiply EquationÂ 7 by âˆ’Î»i-\\lambda_i and add to EquationÂ 8 to obtain\n0â‰¥Î´k22ğ¬kâŠ¤{âˆ‡2f(ğ›ˆ0)âˆ’âˆ‘i=1mÎ»iâˆ‡2hi(ğ›ˆi)}ğ¬k,â‡’â‡askâ†’âˆ. 0 \\geq \\frac{\\delta_k^2}{2}\\bm{s}_k^\\top \\left\\{ \\nabla^2 f(\\bm{\\eta}_0) -\n\\sum_{i=1}^m \\lambda_i \\nabla^2 h_i(\\bm{\\eta}_i) \\right\\}\\bm{s}_k, \\quad\n\\Rightarrow\\!\\Leftarrow \\;\\; \\text{as} \\;\\; k \\rightarrow \\infty."
  },
  {
    "objectID": "08_constrained.html#example",
    "href": "08_constrained.html#example",
    "title": "08_constrained",
    "section": "Example",
    "text": "Example\n\n\nConsider the problem\nmaximize(x1âˆ’1)2+(x2âˆ’1)2subject tox12+x22âˆ’1=0.\n\\begin{align}\n\\operatorname{maximize} & (x_1 - 1)^2 + (x_2 - 1)^2 \\\\\n\\text{subject to} & x_1^2 + x_2^2 - 1 = 0.\n\\end{align}\n\nThe Lagrangian and subsection FONC would be\nâ„“(x1,x2,Î»)=(x1âˆ’1)2+(x2âˆ’1)2âˆ’Î»(x12+x22âˆ’1),âˆ‡ğ±â„“(x1,x2,Î»)=(2x1(1âˆ’Î»)âˆ’22x2(1âˆ’Î»)âˆ’2)=ğŸ.\n\\begin{align}\n\\ell(x_1, x_2, \\lambda) &= (x_1 - 1)^2 + (x_2 - 1)^2 - \\lambda(x_1^2 + x_2^2 -\n1), \\\\\n\\nabla_{\\bm{x}}\\ell(x_1, x_2, \\lambda) &= \\begin{pmatrix} 2x_1(1-\\lambda) - 2 \\\\\n2x_2(1-\\lambda) - 2 \\end{pmatrix} = \\bm{0}.\n\\end{align}\n\nFrom the two equations we conclude x1=x2x_1 = x_2, together with x12+x22âˆ’1=0x_1^2 + x_2^2 - 1= 0.\nWe have the two first-order stationary solutions x1=x2=12,Î»=1âˆ’2x1=x2=âˆ’12,Î»=1+2. \n\\begin{align}\nx_1 &= x_2 = \\frac{1}{\\sqrt{2}}, \\quad \\lambda = 1-\\sqrt{2} \\\\\nx_1 &= x_2 = -\\frac{1}{\\sqrt{2}}, \\quad \\lambda = 1+\\sqrt{2}. \n\\end{align}\n\n\n\n\n\nThe Lagrangian Hessian matrix ğ…âˆ’ğ›ŒâŠ¤ğ‡\\bm{F}-\\bm{\\lambda}^\\top \\bm{H} at these Î»\\lambdas becomes\n[2(1âˆ’Î»)002(1âˆ’Î»)]|Î»=1âˆ’2=[220022][2(1âˆ’Î»)002(1âˆ’Î»)]|Î»=1+2=[âˆ’2200âˆ’22]\n\\begin{align}\n\\left. \\begin{bmatrix}\n2(1-\\lambda) & 0 \\\\ 0 & 2(1-\\lambda)\n\\end{bmatrix}\\right\\rvert_{\\lambda = 1-\\sqrt{2}} &= \n\\begin{bmatrix}\n2\\sqrt{2} & 0 \\\\ 0 & 2\\sqrt{2}\n\\end{bmatrix} \\\\\n\\left. \\begin{bmatrix}\n2(1-\\lambda) & 0 \\\\ 0 & 2(1-\\lambda)\n\\end{bmatrix}\\right\\rvert_{\\lambda = 1+\\sqrt{2}} &= \n\\begin{bmatrix}\n-2\\sqrt{2} & 0 \\\\ 0 & -2\\sqrt{2}\n\\end{bmatrix}\n\\end{align}\n\n\n\n\nSo which is minimum, which is maximum?"
  },
  {
    "objectID": "08_constrained.html#eigenvalues-in-the-tangent-subspace",
    "href": "08_constrained.html#eigenvalues-in-the-tangent-subspace",
    "title": "08_constrained",
    "section": "Eigenvalues in the Tangent Subspace",
    "text": "Eigenvalues in the Tangent Subspace\n\n\n\nGiven any vector ğâˆˆM\\bm{d} \\in M, the vector ğ‹ğâˆˆâ„n\\bm{Ld} \\in \\mathbb{R}^n, but not necessarily in MM.\nWe project ğ‹ğ\\bm{Ld} orthogonally back onto MM as in figure.\n\nThis is the restriction of ğ‹\\bm{L} to MM operating on ğ\\bm{d}.\nIn this way, we obtain a linear transformation ğ‹M:Mâ†’M\\bm{L}_M: M \\rightarrow M.\n\nA vector ğ²âˆˆM\\bm{y} \\in M is an eigenvector of ğ‹M\\bm{L}_M if âˆƒÎ»\\exists \\lambda s.t. ğ‹Mğ²=Î»ğ²\\bm{L}_M\\bm{y} = \\lambda \\bm{y} (Î»\\lambda: eigenvalue of ğ‹M\\bm{L}_M).\n\nIn terms of ğ‹\\bm{L}, we see that ğ²\\bm{y} is an eigenvector of ğ‹M\\bm{L}_M if ğ‹ğ²\\bm{Ly} can be written as a sum of Î»ğ²\\lambda \\bm{y} and a vector orthogonal to MM.\n\nIntroduce an orthonormal basis {ğ1,â€¦,ğnâˆ’m}\\{\\bm{e}_1, \\ldots, \\bm{e}_{n-m}\\} of MM.\n\nDefine ğ„â‰œ[ğ1ğ2â‹¯ğnâˆ’m]\\bm{E} \\triangleq \\begin{bmatrix} \\bm{e}_1 & \\bm{e}_2 & \\cdots \\bm{e}_{n-m} \\end{bmatrix}.\nAny vector ğ²âˆˆM\\bm{y} \\in M can be written as ğ²=ğ„ğ³\\bm{y} = \\bm{Ez} for some ğ³âˆˆâ„nâˆ’m\\bm{z} \\in \\mathbb{R}^{n-m}.\nğ‹ğ„ğ³\\bm{LEz} represents the action of LL on such a vector.\n\n\n\n\n\n\n\n\n\n\n\nTo project the result back to MM and express the result back in terms of the basis {ğ1,ğ2,â€¦,ğnâˆ’m}\\{\\bm{e}_1, \\bm{e}_2, \\ldots, \\bm{e}_{n-m}\\}, we multiply by ğ„âŠ¤\\bm{E}^\\top: ğ„âŠ¤ğ‹ğ„\\bm{E}^\\top \\bm{LE} is the matrix representation of ğ‹\\bm{L} restricted to MM."
  },
  {
    "objectID": "08_constrained.html#example-1",
    "href": "08_constrained.html#example-1",
    "title": "08_constrained",
    "section": "Example",
    "text": "Example\n\n\n\n\n\nProblem\n\n\nminimizex1+x22+x2x3+2x32subject to12(x12+x22+x32)=1.\n\\begin{align}\n\\operatorname{minimize} & x_1 + x_2^2 + x_2x_3 + 2x_3^2 \\\\\n\\text{subject to} & \\frac{1}{2}\\left(x_1^2 + x_2^2 + x_3^2 \\right) = 1.\n\\end{align}\n\n\n\n\n\n\n\nFONC\n\n\n1âˆ’Î»x1=0,2x2+x3âˆ’Î»x2=0,x2+4x3âˆ’Î»x3=0.\n\\begin{align}\n1 - \\lambda x_1 &= 0, \\\\\n2x_2 + x_3 - \\lambda x_2 &= 0, \\\\\nx_2 + 4x_3 - \\lambda x_3 &= 0.\n\\end{align}\n\nwith one solution x1=1x_1 = 1, x2=0x_2 = 0, x3=0x_3 = 0, Î»=1\\lambda = 1.\n\n\n\n\n\n\nSOC\n\n\nğ‹=[âˆ’100011013]\n\\bm{L} = \\begin{bmatrix}\n-1 & 0 & 0 \\\\ 0 & 1 & 1 \\\\ 0 & 1 & 3\n\\end{bmatrix}\n\nand the corresponding subspace MM is\nM={ğ²:y1=0}. M = \\{ \\bm{y}: y_1 = 0 \\}. \n\n\n\n\n \n\nIn this case MM is the subspace spanned by the standard bases ğ2\\bm{e}_2 and ğ3\\bm{e}_3 of â„3\\mathbb{R}^3.\nTherefore the restriction of ğ‹\\bm{L} is computed to be\n\nğ‹M=[010001][âˆ’100011013][001001]=[1113].\n\\bm{L}_M = \\begin{bmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\begin{bmatrix}\n-1 & 0 & 0 \\\\ 0 & 1 & 1 \\\\ 0 & 1 & 3\n\\end{bmatrix}\n\\begin{bmatrix} 0 & 0 \\\\ 1 & 0 \\\\ 0 & 1 \\end{bmatrix} = \\begin{bmatrix} 1 & 1 \\\\\n1 & 3 \\end{bmatrix}.\n\n\nğ‹M\\bm{L}_M is seen to be positive definite.\n\nTherefore the point in question is a relative minimum point."
  },
  {
    "objectID": "08_constrained.html#projected-hessians",
    "href": "08_constrained.html#projected-hessians",
    "title": "08_constrained",
    "section": "Projected Hessians",
    "text": "Projected Hessians\n\nAlternatively, we can construct matrices and determinants of order nn rather than nâˆ’mn-m.\nFor simplicity, let ğ€=âˆ‡ğ¡\\bm{A} = \\nabla \\bm{h}, which has full row rank.\nAny ğ±\\bm{x} satisfying ğ€ğ±=ğŸ\\bm{Ax} = \\bm{0} can be expressed as ğ±=(ğˆâˆ’ğ€âŠ¤(ğ€ğ€âŠ¤)âˆ’1ğ€)ğ³â‰œğğ€ğ³,ğ³âˆˆâ„n. \\bm{x} = (\\bm{I} - \\bm{A}^\\top(\\bm{AA}^\\top)^{-1}\\bm{A})\\bm{z} \\triangleq\n\\bm{P}_{\\bm{A}}\\bm{z}, \\qquad \\bm{z} \\in \\mathbb{R}^n. \nğğ€\\bm{P}_\\bm{A} is the so-called projection matrix onto the nullspace of ğ€\\bm{A} (i.e.Â onto MM)\n\nIf ğ±âŠ¤ğ‹ğ±â‰¥0,âˆ€ğ±âˆˆM\\bm{x}^\\top \\bm{L}\\bm{x} \\geq 0, \\;\\; \\forall \\bm{x} \\in M, then ğ³âŠ¤ğğ€ğ‹ğğ€ğ³â‰¥0,âˆ€ğ³âˆˆâ„n\\bm{z}^\\top \\bm{P}_\\bm{A}\\bm{LP}_\\bm{A}\\bm{z} \\geq 0, \\;\\; \\forall \\bm{z} \\in \\mathbb{R}^n or the matrix ğğ€ğ‹ğğ€â‰½ğŸ\\bm{P}_\\bm{A}\\bm{L}\\bm{P}_\\bm{A} \\succeq \\bm{0}.\nFurthermore, if ğğ€ğ‹ğğ€\\bm{P}_\\bm{A}\\bm{LP}_\\bm{A} has rank nâˆ’mn-m, then ğ‹M\\bm{L}_M is positive definite.\n\n\n\n\n\nProjected Hessian Test\n\n\nThe matrix ğ‹\\bm{L} is positive definite on MM iff the projected Hessian matrix to MM is positive semidefinite with rank nâˆ’mn-m.\n\n\n\nIn the previous example we had ğ€=âˆ‡ğ¡=[100]\\bm{A} = \\nabla \\bm{h} = \\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix}. Hence\n ğğ€=ğˆâˆ’[100][100]âŠ¤=[000010001]â‡’ğğ€ğ‹ğğ€=[000011013].\n\\bm{P}_\\bm{A} = \\bm{I} - \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\\n\\end{bmatrix}\\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ \\end{bmatrix}^\\top = \\begin{bmatrix}\n0 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\quad \\Rightarrow \\quad\n\\bm{P}_\\bm{A}\\bm{LP}_\\bm{A} = \\begin{bmatrix} 0 & 0 & 0 \\\\ 0 & 1 & 1 \\\\ 0 & 1 &\n3 \\end{bmatrix}."
  },
  {
    "objectID": "08_constrained.html#first-order-necessary-conditions-3",
    "href": "08_constrained.html#first-order-necessary-conditions-3",
    "title": "08_constrained",
    "section": "First-Order Necessary Conditions",
    "text": "First-Order Necessary Conditions\n\n\n\nDefinition\n\n\nLet ğ±*\\bm{x}^\\ast be a point satisfying the constraints\nğ¡(ğ±*)=ğŸ,ğ (ğ±*)â‰¥ğŸ,(9) \\bm{h}(\\bm{x}^\\ast) = \\bm{0}, \\;\\; \\bm{g}(\\bm{x}^\\ast) \\geq \\bm{0},  \\qquad(9)\nand let JJ be the set of indices jj for which gj(ğ±*)=0g_j(\\bm{x}^\\ast) = 0. Then ğ±*\\bm{x}^\\ast is said to be a regular point of the constraints EquationÂ 9 if the gradient vectors âˆ‡hi(ğ±*)\\nabla h_i(\\bm{x}^\\ast), âˆ‡gj(ğ±*)\\nabla g_j(\\bm{x}^\\ast), 1â‰¤iâ‰¤m1 \\leq i \\leq m, jâˆˆJj \\in J are linearly independent.\n\n\n\n\n\n\nKarush-Kuhn-Tucker (KKT) Conditions\n\n\nLet ğ±*\\bm{x}^\\ast be a relative minimum point for the problem\nminimizef(ğ±)subject toğ¡(ğ±)=ğŸ,ğ (ğ±)â‰¥ğŸ,(10)\n\\begin{align}\n\\operatorname{minimize} & f(\\bm{x}) \\\\\n\\text{subject to} & \\bm{h}(\\bm{x}) = \\bm{0}, \\quad \\bm{g}(\\bm{x}) \\geq \\bm{0},\n\\end{align}\n \\qquad(10)\nand suppose ğ±*\\bm{x}^\\ast is a regular point for the constraints. Then there is a vector ğ›Œâˆˆâ„m\\bm{\\lambda} \\in \\mathbb{R}^m and a vector ğ›âˆˆâ„p\\bm{\\mu} \\in \\mathbb{R}^p with ğ›â‰¥ğŸ\\bm{\\mu} \\geq \\bm{0} such that\nâˆ‡f(ğ±*)âˆ’ğ›ŒâŠ¤âˆ‡ğ¡(ğ±*)âˆ’ğ›âŠ¤âˆ‡ğ (ğ±*)=ğŸ,ğ›âŠ¤ğ (ğ±*)=0.(11)\n\\begin{align}\n\\nabla f(\\bm{x}^\\ast) - \\bm{\\lambda}^\\top \\nabla \\bm{h}(\\bm{x}^\\ast) -\n\\bm{\\mu}^\\top \\nabla \\bm{g}(\\bm{x}^\\ast) &= \\bm{0}, \\\\\n\\bm{\\mu}^\\top \\bm{g}(\\bm{x}^\\ast) = 0.\n\\end{align}\n \\qquad(11)"
  },
  {
    "objectID": "08_constrained.html#karush-kuhn-tucker-kkt-conditions-1",
    "href": "08_constrained.html#karush-kuhn-tucker-kkt-conditions-1",
    "title": "08_constrained",
    "section": "Karush-Kuhn-Tucker (KKT) Conditions",
    "text": "Karush-Kuhn-Tucker (KKT) Conditions\n\n\n\nProof\n\n\nSince ğ›â‰¥ğŸ\\bm{\\mu} \\geq \\bm{0} and ğ (ğ±*)â‰¥ğŸ\\bm{g}(\\bm{x}^\\ast) \\geq \\bm{0}, the second of EquationÂ 11 is equivalent to the statement that a component of ğ›\\bm{\\mu} may be nonzero only if the corresponding constraint is active. This is a complementary slackness condition studied in LP, which states that ğ (ğ±*)j&gt;0\\bm{g}(\\bm{x}^\\ast)_j &gt; 0 implies Î¼j=0\\mu_j = 0 and Î¼j=0\\mu_j = 0 implies ğ (ğ±*)j=0\\bm{g}(\\bm{x}^\\ast)_j = 0.\nSince ğ±*\\bm{x}^\\ast is a relative minimum point over the constraint set, it is also a relative minimum over the subset of that set defined by setting the active constraints to zero. Thus, for the resulting equality constrained problem, defined in a nbhd. of ğ±*\\bm{x}^\\ast, there are Lagrange multipliers. Therefore, we conclude that first of EquationÂ 11 holds with Î¼j=0\\mu_j = 0 if gj(ğ±*)â‰ 0g_j(\\bm{x}^\\ast) \\neq 0.\nIt remains to be shown that ğ›â‰¥ğŸ\\bm{\\mu} \\geq \\bm{0}. Suppose Î¼k&lt;0\\mu_k &lt; 0 for some kâˆˆJk \\in J. Let Sâ€²S' and Mâ€²M' be the surface and the tangent plane, resp., defined by all other active constraints at ğ±*\\bm{x}^\\ast. By the regularity assumption, there is a ğ\\bm{d} such that ğâˆˆMâ€²\\bm{d} \\in M', that is, âˆ‡ğ¡(ğ±*)ğ=ğŸ\\nabla \\bm{h}(\\bm{x}^\\ast)\\bm{d} = \\bm{0} and âˆ‡gj(ğ±*)ğ=0\\nabla g_j(\\bm{x}^\\ast) \\bm{d} = 0 for all jâˆˆJj \\in J but jâ‰ kj \\neq k, and âˆ‡gk(ğ±*)ğ&gt;0\\nabla g_k(\\bm{x}^\\ast) \\bm{d} &gt; 0. Multiplying this ğ\\bm{d} from the right to the first of EquationÂ 11, we have\nâˆ‡f(ğ±*)ğâˆ’Î¼kâˆ‡gk(ğ±*)ğ=0orâˆ‡f(ğ±*)ğ=Î¼kâˆ‡gk(ğ±*)ğ&lt;0, \\nabla f(\\bm{x}^\\ast) \\bm{d} - \\mu_k \\nabla g_k(\\bm{x}^\\ast) \\bm{d} = 0 \\quad\n\\text{or} \\quad \\nabla f(\\bm{x}^\\ast) \\bm{d} = \\mu_k \\nabla g_k(\\bm{x}^\\ast)\n\\bm{d} &lt; 0, \nwhich implies that ğ\\bm{d} is a descent direction for the objective function.\nLet ğ±(t)âˆˆSâ€²\\bm{x}(t) \\in S' with ğ±(0)=ğ±*\\bm{x}(0) = \\bm{x}^\\ast and ğ±Ì‡(0)=ğ\\dot{\\bm{x}}(0) = \\bm{d}. Then for small tâ‰¥0t \\geq 0, ğ±(t)\\bm{x}(t) is feasible â€“ it remains on the surface of Sâ€²S' and gk(ğ±(t))&gt;0g_k(\\bm{x}(t)) &gt; 0 because âˆ‡gk(ğ±*)ğ&gt;0\\nabla g_k(\\bm{x}^\\ast)\\bm{d} &gt; 0 (that is, constrant gkg_k becomes inactive). But\ndfdt(ğ±(t))|t=0=âˆ‡f(ğ±*)ğ&lt;ğŸ\n\\frac{df}{dt}(\\bm{x}(t))\\Bigg\\rvert_{t=0} = \\nabla f(\\bm{x}^\\ast)\\bm{d} &lt; \\bm{0}\n\nwhich contradicts the minimality of ğ±(0)=ğ±*\\bm{x}(0) = \\bm{x}^\\ast."
  },
  {
    "objectID": "08_constrained.html#the-lagrangian-and-first-order-conditions",
    "href": "08_constrained.html#the-lagrangian-and-first-order-conditions",
    "title": "08_constrained",
    "section": "The Lagrangian and First-Order Conditions",
    "text": "The Lagrangian and First-Order Conditions\nIntroduce the Lagrangian associated with the problem, defined as\nâ„“(ğ±,ğ›Œ,ğ›)=f(ğ±)âˆ’ğ›ŒâŠ¤ğ¡(ğ±)âˆ’ğ›âŠ¤ğ (ğ±).(12) \\ell(\\bm{x}, \\bm{\\lambda}, \\bm{\\mu}) = f(\\bm{x}) - \\bm{\\lambda}^\\top\n\\bm{h}(\\bm{x}) - \\bm{\\mu}^\\top \\bm{g}(\\bm{x}).  \\qquad(12)\n\nThe Lagrangian can again be viewed as an uncsontrained objective function combined with the original objective with two penalized terms on constraint violations.\n\nÎ»i\\lambda_i is the penalty weight on the equality hi(ğ±)=0h_i(\\bm{x}) = 0\nÎ¼j\\mu_j is the penalty weight on the inequality gj(ğ±)g_j(\\bm{x}).\n\nThere should be no penalty if gj(ğ±)&gt;0g_j(\\bm{x}) &gt; 0, so that Î¼j=0\\mu_j = 0,\nOtherwise, Î¼j\\mu_j needs to be increased to a positive value in the Lagrangian to pump up the value of gj(ğ±)g_j(\\bm{x}) when the Lagrangian is minimized.\n\n\n\n\n\n\nFirst-Order Necessary Conditions\n\n\n\n(OVC) The original variable constraints of the problem EquationÂ 9.\n(MSC) The multiplier sign constraints: ğ›Œ\\bm{\\lambda} â€œfreeâ€ and ğ›â‰¥ğŸ\\bm{\\mu} \\geq \\bm{0}. In general, the sign of the multiplier is determined by the sense of the original constraint: (i) if it is == then the sign is â€œfreeâ€, (ii) if it is â‰¤\\leq or â‰¥\\geq then the sign is â‰¤\\leq or â‰¥\\geq, resp.\n(LDC) The Lagrangian derivative condition: the first of EquationÂ 11\n(CSC) The complementarity slackness condition: the second of EquationÂ 11"
  },
  {
    "objectID": "08_constrained.html#example-2",
    "href": "08_constrained.html#example-2",
    "title": "08_constrained",
    "section": "Example",
    "text": "Example\n\n\n \n\n\n\nmaximize(x1âˆ’1)2+(x2âˆ’1)2subject to1âˆ’x12âˆ’x22â‰¥0.\n\\begin{align}\n\\operatorname{maximize} & (x_1 - 1)^2 + (x_2 - 1)^2 \\\\\n\\text{subject to} & 1 - x_1^2 - x_2^2 \\geq 0.\n\\end{align}\n\nThe Lagrangian and the (LDC) conditions are â„“(x1,x2,Î¼(â‰¥0))=(x1âˆ’1)2+(x2âˆ’1)2123âˆ’Î¼(1âˆ’x12âˆ’x22),(LDC)âˆ‡ğ±â„“(x1,x2,Î¼)=(2x1(1+Î¼)âˆ’22x2(1+Î¼)âˆ’2)=ğŸ,\n\\begin{align}\n\\ell(x_1, x_2, \\mu(\\geq 0)) &= (x_1 - 1)^2 + (x_2 - 1)^2 \\\\ \n& \\phantom{123} - \\mu(1 - x_1^2 - x_2^2), \\\\\n(\\text{LDC}) \\;\\; \\nabla_\\bm{x}\\ell(x_1, x_2, \\mu) &= \\begin{pmatrix}\n2x_1 (1+\\mu) - 2 \\\\ 2x_2(1+\\mu) - 2\n\\end{pmatrix} = \\bm{0},\n\\end{align}\n\nand the (CSC) condition is Î¼(1âˆ’x12âˆ’x22)=0\\mu(1 - x_1^2 - x_2^2) = 0.\n\n\n\n\n\nFrom the two equations of (LDC) and Î¼â‰¥0\\mu \\geq 0, we conclude x1=x2x_1 = x_2.\nWe first try Î¼=0\\mu = 0, which, from the two eqns. of (LDC) leads to x1=x2=1x_1 = x_2 = 1 and violates the inequality constraint.\nThus the constraint must be active, which gives rise to two possible solutions (x1=x2=12)and(x1=x2=âˆ’12). ( x_1 = x_2 = \\frac{1}{\\sqrt{2}} ) \\;\\; \\text{and} \\;\\; (x_1 = x_2 = \\frac{-1}{\\sqrt{2}}). \nThe former, again from (LDC), makes Î¼=2âˆ’1\\mu = \\sqrt{2} - 1; while the latter makes Î¼=âˆ’2âˆ’1\\mu = -\\sqrt{2} - 1, which violates (MSC).\nThus, the only qualified first-order solution is x1=x2=12x_1 = x_2 = \\frac{1}{\\sqrt{2}}, with the corresponding Î¼=2âˆ’1\\mu = \\sqrt{2} - 1."
  },
  {
    "objectID": "08_constrained.html#convex-problems",
    "href": "08_constrained.html#convex-problems",
    "title": "08_constrained",
    "section": "Convex Problems",
    "text": "Convex Problems\nIf ff is convex and ğ¡(ğ±)\\bm{h}(\\bm{x}) is affine ğ€ğ±âˆ’ğ›\\bm{Ax} - \\bm{b}, and $() are concave functions, then â„“(â‹…)\\ell(\\cdot) is convex in ğ±\\bm{x} for every fixed ğ›Œ\\bm{\\lambda} and ğ›(â‰¥ğŸ)\\bm{\\mu} (\\geq \\bm{0}).\nTherefore if ğ±*\\bm{x}^\\ast meets the first of EquationÂ 11, then ğ±*\\bm{x}^\\ast is the global minimizer of the unconstrained â„“(ğ±,ğ›Œ,ğ›)\\ell(\\bm{x}, \\bm{\\lambda}, \\bm{\\mu}) with the same ğ›Œ\\bm{\\lambda} and ğ›\\bm{\\mu}.\n\n\n\nTheorem\n\n\nThe FONC are sufficient if ff is convex, ğ¡\\bm{h} is affine, and gj(ğ±)g_j(\\bm{x}) is concave for all jj.\n\n\n\n\n\n\nProof\n\n\nLet ğ±\\bm{x} be any feasible solution and ğ±*\\bm{x}^\\ast, together with ğ›Œ*\\bm{\\lambda}^\\ast and ğ›*\\bm{\\mu}^\\ast satisfy the FONC. Then we have\n0â‰¤â„“(ğ±,ğ›Œ*,ğ›*)âˆ’â„“(ğ±*,ğ›Œ*,ğ›*)=f(ğ±)âˆ’f(ğ±*)âˆ’(ğ›Œ*)âŠ¤(ğ¡(ğ±)âˆ’ğ¡(ğ±*))âˆ’(ğ›*)âŠ¤(ğ (ğ±)âˆ’ğ (ğ±*))=f(ğ±)âˆ’f(ğ±*)âˆ’(ğ›*)âŠ¤(ğ (ğ±)âˆ’ğ (ğ±*))=f(ğ±)âˆ’f(ğ±*)âˆ’âˆ‘jâˆˆJÎ¼j(gj(ğ±)âˆ’gj(ğ±*))=f(ğ±)âˆ’f(ğ±*)âˆ’âˆ‘jâˆˆJÎ¼jgj(ğ±)â‰¤f(ğ±)âˆ’f(ğ±*).\n\\begin{align}\n0 &\\leq \\ell(\\bm{x}, \\bm{\\lambda}^\\ast, \\bm{\\mu}^\\ast) - \\ell(\\bm{x}^\\ast,\n\\bm{\\lambda}^\\ast, \\bm{\\mu}^\\ast) = f(\\bm{x}) - f(\\bm{x}^\\ast) -\n(\\bm{\\lambda}^\\ast)^\\top (\\bm{h}(\\bm{x}) - \\bm{h}(\\bm{x}^\\ast)) -\n(\\bm{\\mu}^\\ast)^\\top (\\bm{g}(\\bm{x}) - \\bm{g}(\\bm{x}^\\ast)) \\\\\n&= f(\\bm{x}) - f(\\bm{x}^\\ast) - (\\bm{\\mu}^\\ast)^\\top (\\bm{g}(\\bm{x}) -\n\\bm{g}(\\bm{x}^\\ast)) = f(\\bm{x}) - f(\\bm{x}^\\ast) - \\sum_{j \\in J} \\mu_j\n(g_j(\\bm{x}) - g_j(\\bm{x}^\\ast)) \\\\\n&= f(\\bm{x}) - f(\\bm{x}^\\ast) - \\sum_{j \\in J} \\mu_j g_j(\\bm{x}) \\leq f(\\bm{x})\n- f(\\bm{x}^\\ast).\n\\end{align}\n\nwhich completes the proof."
  },
  {
    "objectID": "08_constrained.html#second-order-conditions-2",
    "href": "08_constrained.html#second-order-conditions-2",
    "title": "08_constrained",
    "section": "Second-Order Conditions",
    "text": "Second-Order Conditions\n\n\n \n\n\n\nSONC\n\n\nSuppose ğ±*\\bm{x}^\\ast is a regular point of the constraints. If ğ±*\\bm{x}^\\ast is a relative minimum point for the problem EquationÂ 10, then there is a ğ›Œâˆˆâ„m\\bm{\\lambda} \\in \\mathbb{R}^m, ğ›âˆˆâ„p\\bm{\\mu} \\in \\mathbb{R}^p, ğ›â‰¥0\\bm{\\mu} \\geq 0 such that EquationÂ 11 hold and such that ğ‹(ğ±*)=ğ…(ğ±*)âˆ’ğ›ŒâŠ¤ğ‡(ğ±*)âˆ’ğ›âŠ¤ğ†(ğ±*)(13) \\bm{L}(\\bm{x}^\\ast) = \\bm{F}(\\bm{x}^\\ast) -\n\\bm{\\lambda}^\\top \\bm{H}(\\bm{x}^\\ast) - \\bm{\\mu}^\\top \\bm{G}(\\bm{x}^\\ast)  \\qquad(13) is positive semidefinite on the tangent subspace of the active constraints in ğ±*\\bm{x}^\\ast.\n\n\n\n\n\n\n\nSOSC\n\n\nSufficient conditions that a point satisfying EquationÂ 9 be a strict relative point of the problem EquationÂ 10 is that there exist ğ›Œâˆˆâ„m\\bm{\\lambda} \\in \\mathbb{R}^m, ğ›âˆˆâ„p\\bm{\\mu} \\in \\mathbb{R}^p such that\nğ›â‰¥0ğ›âŠ¤ğ (ğ±*)=0âˆ‡f(ğ±*)âˆ’ğ›ŒâŠ¤âˆ‡ğ¡(ğ±*)âˆ’ğ›âŠ¤âˆ‡ğ (ğ±*)=0,\n\\begin{align}\n\\bm{\\mu} &\\geq 0 \\\\\n\\bm{\\mu}^\\top \\bm{g}(\\bm{x}^\\ast) &= 0 \\\\\n\\nabla f(\\bm{x}^\\ast) - \\bm{\\lambda}^\\top \\nabla \\bm{h}(\\bm{x}^\\ast) -\n\\bm{\\mu}^\\top \\nabla \\bm{g}(\\bm{x}^\\ast) &= 0,\n\\end{align}\n\nand the Hessian matrix\nğ‹(ğ±*)=ğ…(ğ±*)âˆ’ğ›ŒâŠ¤ğ‡(ğ±*)âˆ’ğ›âŠ¤ğ†(ğ±*) \\bm{L}(\\bm{x}^\\ast) = \\bm{F}(\\bm{x}^\\ast) -\n\\bm{\\lambda}^\\top \\bm{H}(\\bm{x}^\\ast) - \\bm{\\mu}^\\top \\bm{G}(\\bm{x}^\\ast) \nis positive definite on the subspace\nMâ€²={ğ:âˆ‡ğ¡(ğ±*)ğ=0,âˆ‡gj(ğ±*)ğ=0âˆ€jâˆˆJ},\nM' = \\left\\{ \\bm{d}: \\nabla \\bm{h}(\\bm{x}^\\ast)\\bm{d} = 0, \\nabla\ng_j(\\bm{x}^\\ast) \\bm{d} = 0 \\;\\; \\forall j \\in J \\right\\}, \n\nwhere J={j;gj(ğ±*)=0,Î¼j&gt;0}J = \\{j; g_j(\\bm{x}^\\ast) = 0, \\; \\mu_j &gt; 0\\}."
  },
  {
    "objectID": "08_constrained.html#sensitivity-2",
    "href": "08_constrained.html#sensitivity-2",
    "title": "08_constrained",
    "section": "Sensitivity",
    "text": "Sensitivity\n\n\n\nSensitivity Theorem\n\n\nConsider the family of problems\nminimizef(ğ±)subject toğ¡(ğ±)=ğ›,ğ (ğ±)â‰¥ğœ.(14)\n\\begin{align}\n\\operatorname{minimize} & f(\\bm{x}) \\\\\n\\text{subject to} & \\bm{h}(\\bm{x}) = \\bm{b}, \\quad \\bm{g}(\\bm{x}) \\geq \\bm{c}.\n\\end{align}\n \\qquad(14)\nSuppose that for ğ›=ğŸ\\bm{b} = \\bm{0}, ğœ=ğŸ\\bm{c} = \\bm{0}, there is a local solution ğ±*\\bm{x}^\\ast that is a regular point and that together with the associated Lagrange multipliers, ğ›Œ,ğ›â‰¥ğŸ\\bm{\\lambda}, \\bm{\\mu} \\geq \\bm{0}, satisfies the SOSC for a strict local minimum. Assume further that no active inequality constraints is degenerate.\nThen for every (ğ›,ğœ)âˆˆâ„m+p(\\bm{b}, \\bm{c}) \\in \\mathbb{R}^{m+p} in a region containing (ğŸ,ğŸ)(\\bm{0}, \\bm{0}), there is a solution ğ±(ğ›,ğœ)\\bm{x}(\\bm{b}, \\bm{c}), depending continuously on (ğ›,ğœ)(\\bm{b}, \\bm{c}), such that ğ±(ğŸ,ğŸ)=ğ±*\\bm{x}(\\bm{0}, \\bm{0}) = \\bm{x}^\\ast and ğ±(ğ›,ğœ)\\bm{x}(\\bm{b}, \\bm{c}) is a relative minimum of EquationÂ 14. Furthermore\nâˆ‡ğ›f(ğ±(ğ›,ğœ))|(ğŸ,ğŸ)=ğ›ŒâŠ¤,âˆ‡ğœf(ğ±(ğ›,ğœ))|(ğŸ,ğŸ)=ğ›âŠ¤.(15)\n\\begin{align}\n\\nabla_\\bm{b} f(\\bm{x}(\\bm{b}, \\bm{c}))\\Bigg\\rvert_{(\\bm{0}, \\bm{0})} &=\n\\bm{\\lambda}^\\top, \\\\\n\\nabla_\\bm{c} f(\\bm{x}(\\bm{b}, \\bm{c}))\\Bigg\\rvert_{(\\bm{0}, \\bm{0})} &=\n\\bm{\\mu}^\\top. \\\\\n\\end{align} \n \\qquad(15)"
  },
  {
    "objectID": "08_constrained.html#example-soft-margin-minimization-in-svm",
    "href": "08_constrained.html#example-soft-margin-minimization-in-svm",
    "title": "08_constrained",
    "section": "Example â€“ Soft-Margin Minimization in SVM",
    "text": "Example â€“ Soft-Margin Minimization in SVM\n\n\n\nOptimization Theory and Practice â€¢ Aykut C. Satici"
  }
]