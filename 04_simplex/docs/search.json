[
  {
    "objectID": "04_simplex.html#optimization-theory-and-practice",
    "href": "04_simplex.html#optimization-theory-and-practice",
    "title": "04_simplex",
    "section": "Optimization Theory and Practice",
    "text": "Optimization Theory and Practice\n\n\nThe Simplex Method\n\n\n\n\nInstructor: Aykut Satici, Ph.D.   Mechanical and Biomedical Engineering  Electrical and Computer Engineering  Boise State University, Boise, ID, USA\n\n\nTopics:   Adjacent BFS (Extreme Points)  Primal Simplex Method  Dual Simplex Method"
  },
  {
    "objectID": "04_simplex.html#adjacent-solutions",
    "href": "04_simplex.html#adjacent-solutions",
    "title": "04_simplex",
    "section": "Adjacent Solutions",
    "text": "Adjacent Solutions\n\nWe know that it is only necessary to consider basic feasible solutions to the system 𝐀𝐱=𝐛,𝐱≥𝟎(1) \\bm{Ax} = \\bm{b}, \\quad \\bm{x} \\geq \\bm{0}  \\qquad(1) when solving a linear program.\nThe idea of the simplex method is to move from a basic feasible solution (extreme point) to an adjacent one with an improved objective value.\n\n\n\n\nDefinition\n\n\nTwo basic feasible solutions are said to be adjacent if and only if they differ by one basic variable.\n\n\n\n\nA new basic solution can be generated from an old one by replacing one current basic variable by a current nonbasic one.\n\nIt is impossible to arbitrarily specify a pair of variables whose roles are to be interchanged and expect to maintain the nonnegativity condition.\nHowever, it is possible to arbitrarily specify which current nonbasic (entering or incoming) variable is to become basic and then determine which current basic (leaving or outgoing) variable should become nonbasic."
  },
  {
    "objectID": "04_simplex.html#determination-of-a-vector-to-leave-the-basis",
    "href": "04_simplex.html#determination-of-a-vector-to-leave-the-basis",
    "title": "04_simplex",
    "section": "Determination of a Vector to Leave the Basis",
    "text": "Determination of a Vector to Leave the Basis\n\n\n\nLet the BFS be partitioned as 𝐱𝐁=(x1,x2,…,xm)\\bm{x}_{\\bm{B}} = (x_1, x_2, \\ldots, x_m) and 𝐱𝐃=(xm+1,xm+2,…,xn)\\bm{x}_{\\bm{D}} = (x_{m+1}, x_{m+2}, \\ldots, x_n).\n\n\n\n𝐛\\bm{b} is a linear combination of columns of 𝐁=[𝐚1𝐚2⋯𝐚m]\\bm{B} = \\begin{bmatrix} \\bm{a}_1 & \\bm{a}_2 & \\cdots & \\bm{a}_m \\end{bmatrix} with the positive multipliers (x1,x2,…,xm)(x_1, x_2, \\ldots, x_m).\n\n\n\n𝐛=𝐁𝐱𝐁=x1𝐚1+x2𝐚2+⋯+xm𝐚m,where𝐱𝐁=𝐚‾0:=𝐁−1𝐛≥𝟎.(2) \\bm{b} = \\bm{B}\\bm{x}_{\\bm{B}} = x_1\\bm{a}_1 + x_2 \\bm{a}_2 + \\cdots +\nx_m\\bm{a}_m, \\quad \\text{where} \\quad \\bm{x}_{\\bm{B}} = \\bar{\\bm{a}}_0 :=\n\\bm{B}^{-1}\\bm{b} \\geq \\bm{0}.  \\qquad(2)\n\n\n\nSuppose we decided to bring into representation the ethe^{\\text{th}} (entering) column vector of 𝐀\\bm{A}, 𝐚e\\bm{a}_e (e&gt;me &gt; m), while keeping all others nonbasic.\n\n\n\nA new representation of 𝐛\\bm{b} as a linear combination of m+1m+1 vectors (𝐚e\\bm{a}_e added to the current basis 𝐁\\bm{B}) for any nonnegative multiplier xex_e and 𝐱𝐁\\bm{x}_{\\bm{B}}:\n\n\n\n𝐛=𝐁𝐱𝐁+𝐚exe,or𝐚‾0=𝐁−1𝐛=𝐱𝐁+(𝐁−1𝐚e)xe.(3) \\bm{b} = \\bm{Bx_B} + \\bm{a}_ex_e, \\quad \\text{or} \\quad \\bar{\\bm{a}}_0 =\n\\bm{B}^{-1}\\bm{b} = \\bm{x}_{\\bm{B}} + (\\bm{B}^{-1}\\bm{a}_e)x_e.  \\qquad(3)\n\n\n\nSince xex_e is the incoming variable, its value needs to be increased from the current 00 to a positive value, say ε≥0\\varepsilon \\geq 0.\n\n\n\nAs xex_e value increases, the current basic variable 𝐱𝐁\\bm{x}_{\\bm{B}} needs to be adjusted accordingly ot keep the feasibility.\n\n\n\n𝐱𝐁=𝐚‾0−ε(𝐁−1𝐚e)=𝐚‾0−ε𝐚‾e≥𝟎,where𝐚‾e=𝐁−1𝐚e.(4)\n\\bm{x}_{\\bm{B}} = \\bar{\\bm{a}}_0 - \\varepsilon(\\bm{B}^{-1}\\bm{a}_e) =\n\\bar{\\bm{a}}_0 - \\varepsilon\\bar{\\bm{a}}_e \\geq \\bm{0}, \\quad \\text{where} \\quad\n\\bar{\\bm{a}}_e = \\bm{B}^{-1}\\bm{a}_e.\n \\qquad(4)"
  },
  {
    "objectID": "04_simplex.html#determination-of-a-vector-to-leave-the-basis-1",
    "href": "04_simplex.html#determination-of-a-vector-to-leave-the-basis-1",
    "title": "04_simplex",
    "section": "Determination of a Vector to Leave the Basis",
    "text": "Determination of a Vector to Leave the Basis\n\n\n\nFor ε=0\\varepsilon = 0, we have the old basic feasible solution 𝐱𝐁=𝐚‾0&gt;𝟎\\bm{x}_{\\bm{B}} = \\bar{\\bm{a}}_0 &gt; \\bm{0}.\nThe values of 𝐱𝐁\\bm{x}_{\\bm{B}} will either increase or remain unchanged if a‾ie≤0\\bar{a}_{ie} \\leq 0; or decrease linearly as ε\\varepsilon is increased if a‾ie&gt;0\\bar{a}_{ie} &gt; 0.\n\n\n\nFor small enough ε\\varepsilon, Equation 3 gives a feasible but nonbasic solution.\nIf any decrease, we may set ε\\varepsilon equal to the value corresponding to the first place where one (or more) of the value vanishes\n\n\n\nε=mini{a‾i0a‾ie:a‾ie&gt;0}.(5) \\varepsilon = \\operatorname{min}_i \\left\\{\\frac{\\bar{a}_{i0}}{\\bar{a}_{ie}}:\n\\bar{a}_{ie} &gt; 0 \\right\\}.  \\qquad(5)\n\n\n\nWe have a new BFS, with the vector 𝐚e\\bm{a}_e replacing (outgoing) column 𝐚o\\bm{a}_o, where index o≤mo \\leq m corresponds to the minimizing-ratio in Equation 5 o=arg mini{a‾i0a‾ie:a‾ie&gt;0}. o = \\operatorname{arg \\, min}_i \\left\\{\\frac{\\bar{a}_{i0}}{\\bar{a}_{ie}}:\n\\bar{a}_{ie} &gt; 0 \\right\\}.\n\n\n\nIf none of the a‾ie\\bar{a}_{ie}’s are positive, then all coefficients in Equation 3 increase (or remain constant) as ε\\varepsilon is increased, and no new basic feasible solution is obtained.\nIn this case the set KK of feasible solutions to Equation 1 is unbounded."
  },
  {
    "objectID": "04_simplex.html#conic-combination-interpretations",
    "href": "04_simplex.html#conic-combination-interpretations",
    "title": "04_simplex",
    "section": "Conic Combination Interpretations",
    "text": "Conic Combination Interpretations\n\n\n\nThe basis transformation can be represented in the requirements space, the space where columns of 𝐀\\bm{A} and 𝐛\\bm{b} are represented.\n\n𝐚1x1+𝐚2x2+⋯+𝐚nxn=𝐛. \\bm{a}_1x_1 + \\bm{a}_2x_2 + \\cdots + \\bm{a}_nx_n = \\bm{b}. \n\nA feasible solution defines a representation of 𝐛\\bm{b} as a conic combination of the 𝐚i\\bm{a}_i’s.\nA BFS will only use mm psoitive weights.\nSuppose we start with 𝐚1\\bm{a}_1 and 𝐚2\\bm{a}_2 as the initial basis.\n\nThen an adjacent basis is found by bringing in some other vector.\nIf 𝐚3\\bm{a}_3 is brought in, then clearly 𝐚2\\bm{a}_2 must go out (why?).\nOn the other hand, if 𝐚4\\bm{a}_4 is brought in, 𝐚1\\bm{a}_1 must go out (why?).\n\n\n\n\n\n\n\n\n\n\nA BFS can be constructed with positive weights on 𝐚1\\bm{a}_1 and 𝐚2\\bm{a}_2 because 𝐛\\bm{b} lies between them.\nA BFS cannot be constructed with positive weights on 𝐚1\\bm{a}_1 and 𝐚4\\bm{a}_4.\n\n\n\n\n\n\n\nAnother interpretation is in the activity space, the space where 𝐱\\bm{x} lives.\n\nHere, the feasible region is shown directly as a convex set, and BFS are extreme points.\nAdjacent extreme points are points that lie on a common edge."
  },
  {
    "objectID": "04_simplex.html#conic-combination-interpretations-example",
    "href": "04_simplex.html#conic-combination-interpretations-example",
    "title": "04_simplex",
    "section": "Conic Combination Interpretations – Example",
    "text": "Conic Combination Interpretations – Example\n\n\n\nExample (Basis Change Illustration)\n\n\n3x1+x2−2x3+x4=2,x1+3x2−x4=2.\n\\begin{align}\n3x_1 + x_2 - 2x_3 + x_4 &= 2, \\\\\nx_1 + 3x_2 - x_4 &= 2.\n\\end{align}\n\n\n\n\n\nSuppose we start with 𝐚1\\bm{a}_1 and 𝐚2\\bm{a}_2 as the initial basis and select 𝐚3\\bm{a}_3 as the incoming column. Then \n\n𝐁=(3113),𝐁−1=(3818−1838),𝐚‾0=𝐁−1𝐛=(1212),𝐚‾3=𝐁−1𝐚3=(−34−14).\n\\begin{equation}\n\\bm{B} = \\begin{pmatrix} 3 & 1 \\\\ 1 & 3 \\end{pmatrix}, \\quad \\bm{B}^{-1} =\n\\begin{pmatrix} \\frac{3}{8} & \\frac{1}{8} \\\\ -\\frac{1}{8} & \\frac{3}{8}\n\\end{pmatrix}, \\quad \\bar{\\bm{a}}_0 = \\bm{B}^{-1}\\bm{b} = \\begin{pmatrix}\n\\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix}, \\quad \\bar{\\bm{a}}_3 =\n\\bm{B}^{-1}\\bm{a}_3 = \\begin{pmatrix} -\\frac{3}{4} \\\\ -\\frac{1}{4}\n\\end{pmatrix}.\n\\end{equation}\n\n\nFrom Equation 5, ε=2\\varepsilon = 2 and 𝐚2\\bm{a}_2 is the outgoing column so that the new basis is formed by 𝐚1\\bm{a}_1 and 𝐚3\\bm{a}_3. \nNow, suppose we start with 𝐚1\\bm{a}_1 and 𝐚3\\bm{a}_3 as the initial basis and select 𝐚4\\bm{a}_4 as the incoming column. Then\n\n𝐁=(31−20),𝐁−1=(01−1232),𝐚‾0=𝐁−1𝐛=(22),𝐚‾4=𝐁−1𝐚4=(−1−2).\n\\begin{equation}\n\\bm{B} = \\begin{pmatrix} 3 & 1 \\\\ -2 & 0 \\end{pmatrix}, \\quad \\bm{B}^{-1} =\n\\begin{pmatrix} 0 & 1 \\\\ -\\frac{1}{2} & \\frac{3}{2}\n\\end{pmatrix}, \\quad \\bar{\\bm{a}}_0 = \\bm{B}^{-1}\\bm{b} = \\begin{pmatrix}\n2 \\\\ 2 \\end{pmatrix}, \\quad \\bar{\\bm{a}}_4 =\n\\bm{B}^{-1}\\bm{a}_4 = \\begin{pmatrix} -1 \\\\ -2\n\\end{pmatrix}.\n\\end{equation}\n\n\nSince the entries of the incoming column 𝐚‾4\\bar{\\bm{a}}_4 are all negative, ε\\varepsilon in Equation 5 can go to ∞\\infty, indicating that the feasible region is unbounded."
  },
  {
    "objectID": "04_simplex.html#determining-an-optimal-feasible-solution",
    "href": "04_simplex.html#determining-an-optimal-feasible-solution",
    "title": "04_simplex",
    "section": "Determining an Optimal Feasible Solution",
    "text": "Determining an Optimal Feasible Solution\n\n\n\nThe idea of the simplex method is to select the incoming column so that the resulting new BFS will yield a lower value to the objective function than the previous one.\n\n\n\n\n\n\nAssume that 𝐁\\bm{B} consists of the first mm columns of AA. Then partition 𝐀,𝐱\\bm{A}, \\bm{x} and 𝐜⊤\\bm{c}^\\top as\n\n𝐀=[𝐁𝐃] \\bm{A} = \\begin{bmatrix} \\bm{B} & \\bm{D} \\end{bmatrix}  𝐱=[𝐱𝐁𝐱𝐃],𝐜⊤=[𝐜𝐁⊤𝐜𝐃⊤]. \\bm{x} =\n\\begin{bmatrix}\\bm{x}_{\\bm{B}} & \\bm{x}_{\\bm{D}}\\end{bmatrix}, \\quad \\bm{c}^\\top\n= \\begin{bmatrix} \\bm{c}_{\\bm{B}}^\\top & \\bm{c}_{\\bm{D}}^\\top \\end{bmatrix}. \n\nSuppose we have a basic feasible solution 𝐱𝐁=𝐚‾0:=𝐁−1𝐛≥𝟎,and𝐱𝐃=𝟎. \\bm{x}_{\\bm{B}} = \\bar{\\bm{a}}_0 := \\bm{B}^{-1}\\bm{b} \\geq \\bm{0}, \\quad\n\\text{and} \\quad \\bm{x}_{\\bm{D}} = \\bm{0}. \nThe value of the objective function is z=c1x1+c2x2+⋯+cnxn=𝐜𝐁⊤𝐱𝐁+𝐜𝐃⊤𝐱𝐃(6) z = c_1x_1 + c_2x_2 + \\cdots + c_nx_n = \\bm{c}_{\\bm{B}}^\\top\\bm{x}_{\\bm{B}} +\n\\bm{c}_{\\bm{D}}^\\top\\bm{x}_{\\bm{D}}   \\qquad(6)\nHence for the current basic solution, the corresponding value is z0=𝐜𝐁⊤𝐁−1𝐛.(7) z_0 = \\bm{c}_{\\bm{B}}^\\top \\bm{B}^{-1}\\bm{b}.  \\qquad(7)\n\n\n\nFor any value of 𝐱𝐃\\bm{x}_{\\bm{D}} the necessary value of 𝐱𝐁\\bm{x}_{\\bm{B}} is determined from mm equality constraints of the linear program, i.e., from 𝐀𝐱=𝐛\\bm{Ax} = \\bm{b}.\n\n𝐁𝐱𝐁+𝐃𝐱𝐃=𝐛or𝐱𝐁=𝐁−1𝐛−𝐁−1𝐃𝐱𝐃(8) \\bm{Bx_{B} + Dx_D} = \\bm{b} \\quad \\text{or} \\quad \\bm{x_B} =\n\\bm{B}^{-1}\\bm{b} - \\bm{B}^{-1}\\bm{D}\\bm{x_D}  \\qquad(8)\n\nWhen this expression is substituted into Equation 6 we obtain z=𝐜𝐁⊤(𝐁−1𝐛−𝐁−1𝐃𝐱𝐃)+𝐜𝐃⊤𝐱𝐃=𝐜𝐁⊤𝐁−1𝐛+(𝐜𝐃⊤−𝐜𝐁⊤𝐁−1𝐃)𝐱𝐃=z0+(𝐜𝐃⊤−𝐲⊤𝐃)𝐱𝐃.(9)\n\\begin{align}\nz &= \\bm{c}_{\\bm{B}}^\\top(\\bm{B}^{-1}\\bm{b}-\\bm{B}^{-1}\\bm{Dx_D}) +\n\\bm{c}_{\\bm{D}}^\\top\\bm{x_D} \\\\\n&= \\bm{c}_{\\bm{B}}^\\top\\bm{B}^{-1}\\bm{b} + (\\bm{c}_{\\bm{D}}^\\top -\n\\bm{c}_{\\bm{B}}^\\top\\bm{B}^{-1}\\bm{D})\\bm{x_D} \\\\\n&= z_0 + (\\bm{c}_{\\bm{D}}^\\top - \\bm{y}^\\top\\bm{D})\\bm{x_D}.\n\\end{align}\n \\qquad(9)"
  },
  {
    "objectID": "04_simplex.html#determining-an-optimal-feasible-solution-1",
    "href": "04_simplex.html#determining-an-optimal-feasible-solution-1",
    "title": "04_simplex",
    "section": "Determining an Optimal Feasible Solution",
    "text": "Determining an Optimal Feasible Solution\n\nEquation 9 expresses the cost of any feasible solution to Equation 1 in terms of the independent variable in 𝐱𝐃\\bm{x_D}.\nHere, 𝐲⊤=𝐜𝐁⊤𝐁−1\\bm{y}^\\top = \\bm{c}_{\\bm{B}}^\\top\\bm{B}^{-1} is the simplex multipliers or the shadow prices corresponding to basis 𝐁\\bm{B}.\n\n\n\n\nLet 𝐫𝐃⊤=𝐜𝐃⊤−𝐲⊤𝐃.(10) \\bm{r}_{\\bm{D}}^\\top = \\bm{c}_{\\bm{D}}^\\top - \\bm{y}^\\top\\bm{D}.  \\qquad(10)\nThen from formula Equation 9, z=𝐜⊤𝐱=z0+∑j=m+1nrjxj(11) z = \\bm{c}^\\top \\bm{x} = z_0 + \\sum_{j=m+1}^n r_jx_j  \\qquad(11)\nThe vector 𝐫𝐃\\bm{r_D} represents the relative cost vector, also called reduced cost or reduced gradient vector for nonbasic variables in 𝐱𝐃\\bm{x_D}.\n\n\n\nFrom formula Equation 11, we can now determine if there is any advantage in changing the basic solution by introducing one of the nonbasic variables.\n\nIf rjr_j is negative for some jj, m+1≤j≤nm+1 \\leq j \\leq n, then increasing xjx_j from zero to some positive value would decrease the total cost, yielding a better solution.\nEquation 11 automatically takes into account the changes that would be required in the values of the basic variables x1,x2,…,xmx_1, x_2, \\ldots, x_m to accommodate for the change in xjx_j."
  },
  {
    "objectID": "04_simplex.html#determining-an-optimal-feasible-solution-2",
    "href": "04_simplex.html#determining-an-optimal-feasible-solution-2",
    "title": "04_simplex",
    "section": "Determining an Optimal Feasible Solution",
    "text": "Determining an Optimal Feasible Solution\n\n\n\nTheorem (Improvement of Basic Feasible Solution)\n\n\nGiven a nondegenerate BFS with corresponding objective value z0z_0, suppose that for some jj there holds rj&lt;0r_j &lt; 0. Then there is a feasible solution with objective value z&lt;z0z &lt; z_0. If the column 𝐚j\\bm{a}_j can be substituted for some vector in the original basis to yield a new basic feasible solution, this new solution will have z&lt;z0z &lt; z_0. If 𝐚j\\bm{a}_j cannot be substituted to yield a BFS then the solution set KK is unbounded and the objective function can be made arbitarily small (toward minus infinity).\n\n\n\n\nFinal question: Does rj≥0,∀jr_j \\geq 0, \\;\\; \\forall j imply optimality?\n\nThe answer is “yes” due to strong duality and the fact that\n\n\n𝐫𝐁⊤=𝐜𝐁⊤−𝐲⊤𝐁=𝐜𝐁⊤−𝐜𝐁⊤=𝟎. \\bm{r}_{\\bm{B}}^\\top = \\bm{c}_{\\bm{B}}^\\top - \\bm{y}^\\top\\bm{B} =\n\\bm{c}_{\\bm{B}}^\\top - \\bm{c}_{\\bm{B}}^\\top = \\bm{0}. \nThis means that\n0=𝐫𝐁⊤𝐱𝐁=𝐜𝐁⊤𝐱𝐁−𝐲⊤𝐁𝐱𝐁=𝐜𝐁⊤𝐱𝐁−𝐲⊤𝐁𝐁−1𝐛=𝐜⊤𝐱−𝐲⊤𝐛.\n0 = \\bm{r}_{\\bm{B}}^\\top \\bm{x_B} = \\bm{c}_{\\bm{B}}^\\top \\bm{x}_{\\bm{B}} -\n\\bm{y}^\\top \\bm{Bx_B} = \\bm{c}_{\\bm{B}}^\\top \\bm{x}_{\\bm{B}} - \\bm{y}^\\top\n\\bm{B}\\bm{B}^{-1}\\bm{b} = \\bm{c}^\\top \\bm{x} - \\bm{y}^\\top \\bm{b}.\n\nand strong duality forces that 𝐱\\bm{x} is optimal.\n\n\n\nOptimality Condition Theorem\n\n\nIf for some basic feasible solution rj≥0∀jr_j \\geq 0 \\;\\; \\forall j, then that solution is optimal."
  },
  {
    "objectID": "04_simplex.html#economic-interpretations-diet-problem",
    "href": "04_simplex.html#economic-interpretations-diet-problem",
    "title": "04_simplex",
    "section": "Economic Interpretations – Diet Problem",
    "text": "Economic Interpretations – Diet Problem\n \n\n\n\n\n\nOptimality\n\n\n\nWe consider a certain food not in the basis – say carrots – and determine if it would be advantageous to bring it into the basis.\nThis is easily determined by examining the cost of carrots as compared with the cost of synthetic carrots.\nSay carrots are food jj, whose unit cost is cjc_j. The cost of a unit of synthetic carrots is ∑i=1mci(𝐁−1𝐚j)i=𝐜𝐁⊤𝐁−1𝐚j=𝐲⊤𝐚j. \\sum_{i=1}^m c_i (\\bm{B}^{-1}\\bm{a}_j)_i = \\bm{c}_{\\bm{B}}^\\top\n\\bm{B}^{-1}\\bm{a}_j = \\bm{y}^\\top \\bm{a}_j. \nIf the reduced coefficient rj=cj−𝐲⊤𝐚j&lt;0r_j = c_j - \\bm{y}^\\top\\bm{a}_j &lt; 0, it is advantageous to use real carrots in place of synthetic carrots, and carrots should be brought into the basis.\nIn general, each 𝐲⊤𝐚j\\bm{y}^\\top \\bm{a}_j can be thought of as the price of a unit of the column 𝐚j\\bm{a}_j when constructed from the current basis.\n\nThe difference between this synthetic price and the direct price of that column determines whether that column should enter the basis.\n\n\n\n\n\n\n\n\n\nDiet Problem (Exact nutritional requirements)\n\n\nminimize𝐜⊤𝐱subject to𝐀𝐱=𝐛,𝐱≥𝟎.\n\\begin{align}\n\\operatorname{minimize} & \\bm{c}^\\top \\bm{x} \\\\\n\\text{subject to} & \\bm{Ax} = \\bm{b}, \\quad \\bm{x} \\geq \\bm{0}.\n\\end{align}\n\n\n𝐚j\\bm{a}_j gives the nutritional equivalent of a unit of a particular food.\nGiven a basis 𝐁\\bm{B}, say the first mm columns of 𝐀\\bm{A}, the corresponding 𝐁−1𝐚j\\bm{B}^{-1}\\bm{a}_j shows how the nutritinal contents of any food jj can be constructed as a combination of the foods in the basis.\nFor instance, if carrots are not in the basis we can, using the description given by the tableau, construct a synthetic carrot, which is nutritionally equivalent to a carrot, by an appropriate combination of the foods in the basis."
  },
  {
    "objectID": "04_simplex.html#the-simplex-procedure",
    "href": "04_simplex.html#the-simplex-procedure",
    "title": "04_simplex",
    "section": "The Simplex Procedure",
    "text": "The Simplex Procedure\n\n\n\nStep 0. Given the the inverse 𝐁−1\\bm{B}^{-1} of a current basis, and the current solution 𝐱𝐁=𝐚‾0=𝐁−1𝐛\\bm{x}_{\\bm{B}} = \\bar{\\bm{a}}_0 = \\bm{B}^{-1}\\bm{b}.\nStep 1. Calculate the current simplex multiplier vector 𝐲⊤=𝐜𝐁⊤𝐁−1\\bm{y}^\\top = \\bm{c}_{\\bm{B}}^\\top\\bm{B}^{-1} and then calculate the relative cost coefficients 𝐫𝐃⊤=𝐜𝐃⊤−𝐲⊤𝐃\\bm{r}_{\\bm{D}}^\\top = \\bm{c}_{\\bm{D}}^\\top - \\bm{y}^\\top\\bm{D}. If 𝐫𝐃≥𝟎\\bm{r}_{\\bm{D}} \\geq \\bm{0} stop; the current solution is optimal.\nStep 2. Determine the vector 𝐚e\\bm{a}_e that is to enter the basis by selecting its most negative cost coefficient, the ethe^{\\text{th}} (e&gt;me &gt; m) coefficient (break ties arbitrarily); and calculate 𝐚‾e=𝐁−1𝐚e\\bar{\\bm{a}}_e = \\bm{B}^{-1}\\bm{a}_e.\nStep 3. If 𝐚‾e≤𝟎\\bar{\\bm{a}}_e \\leq \\bm{0}, stop; the problem is unbounded. Otherwise, calculate the ratios a‾i0a‾ie\\frac{\\bar{a}_{i0}}{\\bar{a}_{ie}} for a‾ie&gt;0\\bar{a}_{ie} &gt; 0 to determine the current basic column, 𝐚o\\bm{a}_o where o≤m+1o \\leq m+1 corresponds to the index of the minimum ratio, to leave the basis.\nStep 4. Update 𝐁−1\\bm{B}^{-1} (or its factorization) and the new basic feasible solution 𝐚‾0=𝐁−1𝐛\\bar{\\bm{a}}_0 = \\bm{B}^{-1}\\bm{b}. Return to Step 1.\n\n\n\n\n\n\nRemark\n\n\nThe basic columns in 𝐁\\bm{B} and the nonbasic columns in 𝐃\\bm{D} can be ordered arbitrarily and the components in 𝐱𝐁,𝐱𝐃,𝐜𝐁,𝐜𝐃\\bm{x_B}, \\bm{x_D}, \\bm{c_B}, \\bm{c_D} follow the same index orders.\nMore precisely, let columns be permuted as 𝐁=[𝐚σ(1)𝐚σ(2)⋯𝐚σ(m)]\\bm{B} = \\begin{bmatrix} \\bm{a}_{\\sigma(1)} & \\bm{a}_{\\sigma(2)} & \\cdots & \\bm{a}_{\\sigma(m)} \\end{bmatrix} and 𝐃=[𝐚σ(m+1)𝐚σ(m+2)⋯𝐚σ(n)]\\bm{D} = \\begin{bmatrix} \\bm{a}_{\\sigma(m+1)} & \\bm{a}_{\\sigma(m+2)} & \\cdots & \\bm{a}_{\\sigma(n)} \\end{bmatrix}. Then when rer_e is identified as the most negative coefficient in 𝐫𝐃\\bm{r}_{\\bm{D}} in Step 2, 𝐚σ(e)\\bm{a}_{\\sigma(e)} is the entering column. Similarly, when oo is identified as the minmum ratio index in Step 3, 𝐚σ(o)\\bm{a}_{\\sigma(o)} is the outgoing column."
  },
  {
    "objectID": "04_simplex.html#example-primal-simplex-procedure-illustration",
    "href": "04_simplex.html#example-primal-simplex-procedure-illustration",
    "title": "04_simplex",
    "section": "Example – Primal Simplex Procedure Illustration ",
    "text": "Example – Primal Simplex Procedure Illustration \nSuppose we start with the initial basis 𝐁=[𝐚1𝐚3]\\bm{B} = \\begin{bmatrix} \\bm{a}_1 & \\bm{a}_3 \\end{bmatrix} and 𝐃=[𝐚2𝐚4]\\bm{D} = \\begin{bmatrix} \\bm{a}_2 & \\bm{a}_4 \\end{bmatrix}.\n\n\nStep 0. Initialization\n𝐁=[3−210],𝐁−1=[01−1232],𝐚‾0=𝐁−1𝐛=[22].\n\\begin{equation}\n\\bm{B} = \\begin{bmatrix} 3 & -2 \\\\ 1 & 0 \\end{bmatrix}, \\quad \\bm{B}^{-1} =\n\\begin{bmatrix} 0 & 1 \\\\ -\\frac{1}{2} & \\frac{3}{2} \\end{bmatrix}, \\quad\n\\bar{\\bm{a}}_0 = \\bm{B}^{-1}\\bm{b} = \\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix}.\n\\end{equation}\n\nStep 1. Calculate\n𝐲⊤=𝐜𝐁⊤𝐁−1=[182][01−1232]=[−121]. \n\\begin{equation}\n\\bm{y}^\\top = \\bm{c}_{\\bm{B}}^\\top\\bm{B}^{-1} = \\begin{bmatrix} 18 & 2\n\\end{bmatrix} \\begin{bmatrix} 0 & 1 \\\\ -\\frac{1}{2} & \\frac{3}{2} \\end{bmatrix}\n= \\begin{bmatrix} -1 & 21 \\end{bmatrix}.\n\\end{equation}\n\nand\n𝐫𝐃⊤=𝐜𝐃⊤−𝐲⊤𝐃=[126]−[−121][113−1]=[−5028].\n\\begin{equation}\n\\bm{r}_{\\bm{D}}^\\top = \\bm{c}_{\\bm{D}}^\\top - \\bm{y}^\\top\\bm{D} =\n\\begin{bmatrix} 12 & 6 \\end{bmatrix} - \\begin{bmatrix} -1 & 21 \\end{bmatrix}\n\\begin{bmatrix} 1 & 1 \\\\ 3 & -1 \\end{bmatrix} = \\begin{bmatrix} -50 & 28\n\\end{bmatrix}.\n\\end{equation}\n\nStep 2. Then see e=2e = 2, that is,𝐚2\\bm{a}_2 is the incoming column, and calculate\n𝐚‾2=𝐁−1𝐚2=[01−1232][13]=[34].\n\\bar{\\bm{a}}_2 = \\bm{B}^{-1}\\bm{a}_2 = \\begin{bmatrix} 0 & 1 \\\\ -\\frac{1}{2} &\n\\frac{3}{2} \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 3 \\end{bmatrix} = \\begin{bmatrix}\n3 \\\\ 4 \\end{bmatrix}.\n\n\n\n\n\nminimize18x1+12x2+2x3+6x4subject to3x1+x2−2x3+x4=2,x1+3x2−x4=2,x1,x2,x3,x4≥0.\n\\begin{align}\n\\operatorname{minimize} & 18x_1 + 12x_2 + 2x_3 + 6x_4 \\\\\n\\text{subject to} & 3x_1 + x_2 - 2x_3 + x_4 = 2, \\\\\n& x_1 + 3x_2 - x_4 = 2, \\\\\n& x_1, x_2, x_3, x_4 \\geq 0.\n\\end{align}\n\n\n\n\nStep 3. Since 𝐚‾2≥𝟎\\bar{\\bm{a}}_2 \\geq \\bm{0} the ratios are, via the component-wise divide operation\n𝐚‾0./𝐚‾2=[22]./[34]=[2312].\n\\bar{\\bm{a}}_0 ./ \\bar{\\bm{a}}_2 = \\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix} ./\n\\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix} = \\begin{bmatrix} \\frac{2}{3} \\\\\n\\frac{1}{2} \\end{bmatrix}.\n\nThe minimum ratio correspondes to column 𝐚3\\bm{a}_3 (o=3o=3) that would be outgoing. That is 𝐚2\\bm{a}_2 replaces 𝐚3\\bm{a}_3 in the basis, which is now 𝐁=[𝐚1𝐚2]\\bm{B} = \\begin{bmatrix} \\bm{a}_1 & \\bm{a}_2 \\end{bmatrix} and 𝐃=[𝐚2𝐚4]\\bm{D} = \\begin{bmatrix} \\bm{a}_2 & \\bm{a}_4 \\end{bmatrix}."
  },
  {
    "objectID": "04_simplex.html#example-primal-simplex-procedure-illustration-1",
    "href": "04_simplex.html#example-primal-simplex-procedure-illustration-1",
    "title": "04_simplex",
    "section": "Example – Primal Simplex Procedure Illustration ",
    "text": "Example – Primal Simplex Procedure Illustration \nStep 4. Update\n𝐁=[3113],𝐁−1=[38−18−1838],𝐚‾0=𝐁−1𝐛=[1212].\n\\begin{equation}\n\\bm{B} = \\begin{bmatrix} 3 & 1 \\\\ 1 & 3 \\end{bmatrix}, \\quad \\bm{B}^{-1} =\n\\begin{bmatrix} \\frac{3}{8} & -\\frac{1}{8} \\\\ -\\frac{1}{8} & \\frac{3}{8}\n\\end{bmatrix}, \\quad \\bar{\\bm{a}}_0 = \\bm{B}^{-1}\\bm{b} = \\begin{bmatrix}\n\\frac{1}{2} \\\\ \\frac{1}{2} \\end{bmatrix}.\n\\end{equation}\n\nReturn to Step 1.\nSecond Iteration\nStep 1. Calculate𝐲⊤=𝐜𝐁⊤𝐁−1=[182][38−18−1838]=[21494]. \n\\begin{equation}\n\\bm{y}^\\top = \\bm{c}_{\\bm{B}}^\\top\\bm{B}^{-1} = \\begin{bmatrix} 18 & 2\n\\end{bmatrix} \\begin{bmatrix} \\frac{3}{8} & -\\frac{1}{8} \\\\ -\\frac{1}{8} & \\frac{3}{8} \\end{bmatrix}\n= \\begin{bmatrix} \\frac{21}{4} & \\frac{9}{4} \\end{bmatrix}.\n\\end{equation}\n\nand\n𝐫𝐃⊤=𝐜𝐃⊤−𝐲⊤𝐃=[26]−[21494][−210−1]=[2523].\n\\begin{equation}\n\\bm{r}_{\\bm{D}}^\\top = \\bm{c}_{\\bm{D}}^\\top - \\bm{y}^\\top\\bm{D} =\n\\begin{bmatrix} 2 & 6 \\end{bmatrix} - \\begin{bmatrix} \\frac{21}{4} & \\frac{9}{4} \\end{bmatrix}\n\\begin{bmatrix} -2 & 1 \\\\ 0 & -1 \\end{bmatrix} = \\begin{bmatrix} \\frac{25}{2} & 3 \n\\end{bmatrix}.\n\\end{equation}\n\nStop! All of the reduced costs are positive so the current basic feasible solution is optimal!"
  },
  {
    "objectID": "04_simplex.html#finding-an-initial-basic-feasible-solution",
    "href": "04_simplex.html#finding-an-initial-basic-feasible-solution",
    "title": "04_simplex",
    "section": "Finding an Initial Basic Feasible Solution",
    "text": "Finding an Initial Basic Feasible Solution\n\n\n\nThe simplex procedure needs to start from a basic feasible solution.\nSuch a BFS is some times immediately available:\n\nif the constraints are of this form 𝐀𝐱≤𝐛,𝐱≥𝟎\\bm{Ax} \\leq \\bm{b}, \\quad \\bm{x} \\geq \\bm{0}, with 𝐛≥𝟎\\bm{b} \\geq \\bm{0}\na BFS to the corresponding standard form of the problem is provided by the slack variables.\n\nAn initial BFS is not always apparent for other types of LPs.\nFor those, an auxiliary LP and a corresponding application of the simplex method can be used to determined the required initial solution.\nAn LP can always be expressed in the so-called Phase I form: 𝐀𝐱=𝐛≥𝟎,𝐱≥𝟎.(12) \\bm{Ax} =\n\\bm{b} \\geq \\bm{0}, \\quad \\bm{x} \\geq \\bm{0}.  \\qquad(12)\n\n\n\nIn order to find a solution to Equation 12, we consider the artificial minimization problem (Phase One linear program)\n\nminimize∑i=1mujsubject to𝐀𝐱+𝐮=𝐛𝐱≥𝟎,𝐮≥𝟎.(13)\n\\begin{align}\n\\operatorname{minimize} & \\sum_{i=1}^m u_j \\\\\n\\text{subject to} & \\bm{Ax} + \\bm{u} = \\bm{b} \\\\\n& \\bm{x} \\geq \\bm{0}, \\quad \\bm{u} \\geq \\bm{0}.\n\\end{align}\n \\qquad(13) where 𝐮=(u1,u2,…,um)\\bm{u} = (u_1, u_2, \\ldots, u_m) is a vector of artifical variables.\n\nIf there is a feasible solution to Equation 12, then it is clear that Equation 13 has a minimum value of zero with 𝐮=𝟎\\bm{u} = \\bm{0}.\nIf Equation 12 has no feasible solution, then the minimum value of Equation 13 is greater than zero.\nEquation 13 is an LP and the a BFS for it is 𝐮=𝐛\\bm{u} = \\bm{b}. It can readily be solved using the simplex technique."
  },
  {
    "objectID": "04_simplex.html#motivations",
    "href": "04_simplex.html#motivations",
    "title": "04_simplex",
    "section": "Motivations",
    "text": "Motivations\n\n\n \n\nOften there is a basis to an LP that is not feasible for the primal problem, but its simplex multiplier vector is feasible for the dual.\n\nThat is 𝐲⊤=𝐜𝐁⊤𝐁−1\\bm{y}^\\top = \\bm{c}_{\\bm{B}}^\\top \\bm{B}^{-1} and 𝐫𝐃=𝐜𝐃⊤−𝐲⊤𝐃≥𝟎\\bm{r}_{\\bm{D}} = \\bm{c}_{\\bm{D}}^\\top - \\bm{y}^\\top\\bm{D} \\geq \\bm{0}.\n\nThen we can apply the dual simplex method moving from the current solution to a new BFS with a better objective value.\n\n\n\nAssume 𝐁\\bm{B} consists of the first mm columns of AA.\n\n\n\n\nmaximize𝐲⊤𝐛subject to𝐲⊤𝐀≤𝐜⊤\n\\begin{align}\n\\operatorname{maximize} & \\bm{y}^\\top \\bm{b} \\\\\n\\text{subject to} & \\bm{y}^\\top \\bm{A} \\leq \\bm{c}^\\top\n\\end{align}\n\n\n\n  ⇔\n\\Leftrightarrow\n\n\n\nmaximize𝐲⊤𝐛subject to𝐲⊤𝐁≤𝐜𝐁⊤,𝐲⊤𝐃≤𝐜𝐃⊤.\n\\begin{align}\n\\operatorname{maximize} & \\bm{y}^\\top \\bm{b} \\\\\n\\text{subject to} & \\bm{y}^\\top \\bm{B} \\leq \\bm{c}_{\\bm{B}}^\\top, \\\\\n& \\bm{y}^\\top \\bm{D} \\leq \\bm{c}_{\\bm{D}}^\\top.\n\\end{align}\n\n\n\n\n\nDefine a new dual variable vector 𝐲′\\bm{y}^\\prime via an affine transformation 𝐲′⊤=𝐲⊤𝐁−𝐜𝐁⊤,or𝐲⊤=(𝐲′+𝐜𝐁)⊤𝐁−1(14) {\\bm{y}^\\prime}^\\top  = \\bm{y}^\\top \\bm{B} - \\bm{c}_{\\bm{B}}^\\top, \\quad\n\\text{or} \\quad \\bm{y}^\\top = (\\bm{y}^\\prime + \\bm{c}_{\\bm{B}})^\\top\\bm{B}^{-1}  \\qquad(14)\n\nand substitute 𝐲\\bm{y} in the dual by 𝐲′\\bm{y}^\\prime\n\n\n\n\n\nmaximize𝐲′⊤𝐁−1𝐛+𝐜𝐁⊤𝐁−1𝐛subject to𝐲′⊤≤0,𝐲′⊤𝐁−1𝐃≤𝐜𝐃⊤−𝐜𝐁⊤𝐁−1𝐃.\n\\begin{align}\n\\operatorname{maximize} & {\\bm{y}^\\prime}^\\top \\bm{B}^{-1}\\bm{b} +\n\\bm{c}_{\\bm{B}}^\\top \\bm{B}^{-1}\\bm{b} \\\\\n\\text{subject to} & {\\bm{y}^\\prime}^\\top \\leq 0, \\\\\n& {\\bm{y}^\\prime}^\\top\\bm{B}^{-1}\\bm{D} \\leq \\bm{c}_{\\bm{D}}^\\top -\n\\bm{c}_{\\bm{B}}^\\top \\bm{B}^{-1}\\bm{D}.\n\\end{align}\n\n\n\n    ⇔\n\\Leftrightarrow\n\n\n\nmaximize𝐲′⊤𝐚‾0+z0subject to𝐲′⊤≤𝟎,𝐲′⊤𝐁−1𝐃≤𝐫𝐃⊤,(15)\n\\begin{align}\n\\operatorname{maximize} & {\\bm{y}^\\prime}^\\top \\bar{\\bm{a}}_0 + z_0 \\\\\n\\text{subject to} & {\\bm{y}^\\prime}^\\top \\leq \\bm{0}, \\\\\n& {\\bm{y}^\\prime}^\\top \\bm{B}^{-1}\\bm{D} \\leq \\bm{r}_{\\bm{D}}^\\top,\n\\end{align}\n \\qquad(15)"
  },
  {
    "objectID": "04_simplex.html#transformed-dual-variable-bmyprime",
    "href": "04_simplex.html#transformed-dual-variable-bmyprime",
    "title": "04_simplex",
    "section": "Transformed Dual – Variable 𝐲′\\bm{y}^\\prime",
    "text": "Transformed Dual – Variable 𝐲′\\bm{y}^\\prime\n\n\n\n𝐲′=𝟎\\bm{y}^\\prime = \\bm{0} is a BFS.\nIf 𝐚‾0≥𝟎\\bar{\\bm{a}}_0 \\geq \\bm{0}, i.e., the primal basic solution is also feasible, then 𝐲′⊤=𝟎{\\bm{y}^\\prime}^\\top = \\bm{0} is optimal.\nThis implies 𝐲⊤=𝐜𝐁⊤𝐁−1\\bm{y}^\\top = \\bm{c}_{\\bm{B}}^\\top\\bm{B}^{-1} is optimal to the original dual.\nThe vector 𝐚‾0\\bar{\\bm{a}}_0 can be viewed as the scaled gradient vector of the dual objective function at basis 𝐁\\bm{B}.\n\nIf one entry of 𝐚‾o0&lt;0\\bar{\\bm{a}}_{o0} &lt; 0, then one can decrease the variable 𝐲o′\\bm{y}_o^\\prime to some −ε-\\varepsilon while keeping others at 00’s.\nThe new 𝐲′\\bm{y}^\\prime reamins feasible, but its objective value would decrease linearly in ε\\varepsilon.\nThe second block of constraints in Equation 15 becomes ε𝐞o⊤𝐁−1𝐃≤𝐫𝐃⊤or−ε𝐚‾o≤𝐫𝐃⊤.(16) \\varepsilon \\bm{e}_o^\\top\\bm{B}^{-1}\\bm{D} \\leq \\bm{r}_{\\bm{D}}^\\top \\quad\n\\text{or} \\quad -\\varepsilon \\bar{\\bm{a}}^o \\leq \\bm{r}_{\\bm{D}}^\\top.  \\qquad(16)\n\n\n\n\nTo keep dual feasibility, we need to choose ε\\varepsilon such that this vector constraint is satisfied componentwise.\n\nIf all entries in 𝐚‾o\\bar{\\bm{a}}^o are nonnegative, then ε\\varepsilon may be chosen arbitrarily large so the dual objective is unbounded.\nIf some are negative we can increase ε\\varepsilon until one of the inequality constraints Equation 16 become equal.\nSay the ethe^{\\text{th}} becomes equal. This indicates that the current nonbasic column 𝐚e\\bm{a}_e replaces 𝐚o\\bm{a}_o in the new basis 𝐁\\bm{B}.\n\nThe determination can be done by calculating the componentwise ratios (𝐫𝐃)j(−𝐚‾o)j\\frac{(\\bm{r_D})_j}{(-\\bar{\\bm{a}}^o)_j} for (𝐚‾o)j&lt;0(\\bar{\\bm{a}}^o)_j &lt; 0 and j=m+1,…,nj = m+1, \\ldots, n (incoming col a‾e\\bar{a}_e)."
  },
  {
    "objectID": "04_simplex.html#dual-simplex-method",
    "href": "04_simplex.html#dual-simplex-method",
    "title": "04_simplex",
    "section": "Dual Simplex Method",
    "text": "Dual Simplex Method\n\nIn each cycle we find a new feasible dual solution such that one of the equalities becomes inequality and one of the inequalities becomes equality.\n\nAt the same time we increase the value of the dual objective function.\n\nThe mm equalities in the new solution then determine a new basis.\n\n\n\n\nOne difference, in contrast to the primal simplex method, is that here the outgoing column is selected first and the incoming one is chosen later.\n\n\n\n\n\n\nStep 0. Given the inverse 𝐁−1\\bm{B}^{-1} of a dual feasible basis 𝐁\\bm{B}, primal solution 𝐚‾0=𝐁−1𝐛\\bar{\\bm{a}}_0 = \\bm{B}^{-1}\\bm{b}, dual feasible solution 𝐲⊤=𝐜𝐁⊤𝐁−1\\bm{y}^\\top = \\bm{c}_{\\bm{B}}^\\top\\bm{B}^{-1}, and reduced cost vectors 𝐫𝐃⊤=𝐜𝐃⊤−𝐲⊤𝐃≥𝟎\\bm{r}_{\\bm{D}}^\\top = \\bm{c}_{\\bm{D}}^\\top - \\bm{y}^\\top\\bm{D} \\geq \\bm{0}.\nStep 1. If 𝐚‾0≥𝟎\\bar{\\bm{a}}_0 \\geq \\bm{0}, stop; the current solution pair is optimal. Otherwise, determine which column 𝐚o\\bm{a}_o is to leave the basis by selecting the most negative entry, the otho^{\\text{th}} entry (break ties arbitrarily), in 𝐚‾0\\bar{\\bm{a}}_0. Now calculate 𝐲‾⊤=𝐞o⊤𝐁−1\\bar{\\bm{y}}^\\top = \\bm{e}_o^\\top \\bm{B}^{-1} and then calculate 𝐚‾o=𝐲‾⊤𝐃\\bar{\\bm{a}}^o = \\bar{\\bm{y}}^\\top\\bm{D}.\nStep 2. If 𝐚‾o≥𝟎\\bar{\\bm{a}}^o \\geq \\bm{0}, stop; the problem is unbounded. Otherwise, calculate the ratios (𝐫D)j(−𝐚‾o)j\\frac{(\\bm{r}_D)_j}{(-\\bar{\\bm{a}}^o)_j} for (𝐚‾o)j&lt;0\\bar{\\bm{a}}^o)_j &lt; 0 to determine the current nonbasic column, 𝐚e\\bm{a}_e, ee corresponding to the minimum ratio index, to become basic.\nStep 3. Update the basis 𝐁−1\\bm{B}^{-1} (or its factorization), and update primal solution 𝐚‾0\\bar{\\bm{a}}_0, dual feasible solution 𝐲\\bm{y}, and reduced cost vector 𝐫𝐃\\bm{r}_{\\bm{D}} accordingly. Return to Step 1."
  },
  {
    "objectID": "04_simplex.html#example-dual-simplex-procedure-illustration",
    "href": "04_simplex.html#example-dual-simplex-procedure-illustration",
    "title": "04_simplex",
    "section": "Example – Dual Simplex Procedure Illustration ",
    "text": "Example – Dual Simplex Procedure Illustration \n\nWe start with the initial basis 𝐁=[𝐚2𝐚3]\\bm{B} = \\begin{bmatrix} \\bm{a}_2 & \\bm{a}_3 \\end{bmatrix} and 𝐃=[𝐚1𝐚4]\\bm{D} = \\begin{bmatrix} \\bm{a}_1 & \\bm{a}_4 \\end{bmatrix}.\n\nStep 0. Initialization\n𝐁=[1−230],𝐁−1=[013−1216],𝐚‾0=[013−1216][22]=[23−23],𝐲⊤=[122][013−1216]=[−1133],\n\\begin{equation}\n\\bm{B} = \\begin{bmatrix} 1 & -2 \\\\ 3 & 0 \\end{bmatrix}, \\quad \\bm{B}^{-1} =\n\\begin{bmatrix} 0 & \\frac{1}{3} \\\\ -\\frac{1}{2} & \\frac{1}{6} \\end{bmatrix},\n\\quad \\bar{\\bm{a}}_0 = \\begin{bmatrix} 0 & \\frac{1}{3} \\\\ -\\frac{1}{2} &\n\\frac{1}{6} \\end{bmatrix}\\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix}\n\\frac{2}{3} \\\\ -\\frac{2}{3} \\end{bmatrix}, \\quad \\bm{y}^\\top = \\begin{bmatrix}\n12& 2 \\end{bmatrix} \\begin{bmatrix} 0 & \\frac{1}{3} \\\\ -\\frac{1}{2} &\n\\frac{1}{6} \\end{bmatrix} = \\begin{bmatrix} -1 & \\frac{13}{3} \\end{bmatrix},\n\\end{equation}\n\nand\n𝐫𝐃⊤=[186]−[−1133][311−1]=[503343].\n\\bm{r}_{\\bm{D}}^\\top = \\begin{bmatrix} 18 & 6 \\end{bmatrix} - \\begin{bmatrix} -1\n& \\frac{13}{3} \\end{bmatrix}\\begin{bmatrix} 3 & 1 \\\\ 1 & -1 \\end{bmatrix} =\n\\begin{bmatrix} \\frac{50}{3} & \\frac{34}{3} \\end{bmatrix}.\n\nStep 1. We see that only the second component of 𝐚‾0\\bar{\\bm{a}}_0 is negative so that o=2o=2 (which corr. to column 𝐚3\\bm{a}_3). Now, we compute\n𝐲‾⊤=𝐞2⊤𝐁−1=[01][013−1216]=[−1216],𝐚‾2=𝐲‾⊤𝐃=[−1216][311−1]=[−43−23].\n\\bar{\\bm{y}}^\\top = \\bm{e}_2^\\top \\bm{B}^{-1} = \\begin{bmatrix} 0 & 1\n\\end{bmatrix}\\begin{bmatrix} 0 & \\frac{1}{3} \\\\ -\\frac{1}{2} & \\frac{1}{6}\n\\end{bmatrix} = \\begin{bmatrix} -\\frac{1}{2} & \\frac{1}{6} \\end{bmatrix}, \\quad \n\\bar{\\bm{a}}^2 = \\bar{\\bm{y}}^\\top\\bm{D} = \\begin{bmatrix} -\\frac{1}{2} &\n\\frac{1}{6} \\end{bmatrix} \\begin{bmatrix} 3 & 1 \\\\ 1 & -1 \\end{bmatrix} = \\begin{bmatrix}\n-\\frac{4}{3} & -\\frac{2}{3} \\end{bmatrix}."
  },
  {
    "objectID": "04_simplex.html#example-dual-simplex-procedure-illustration-1",
    "href": "04_simplex.html#example-dual-simplex-procedure-illustration-1",
    "title": "04_simplex",
    "section": "Example – Dual Simplex Procedure Illustration ",
    "text": "Example – Dual Simplex Procedure Illustration \nStep 2. Since all components in 𝐚‾o\\bar{\\bm{a}}^o are negative, the componentwise ratios are\n𝐫𝐃./(−𝐚‾2)=[503343]./[4323]=[25217]\n\\bm{r}_{\\bm{D}} ./ (-\\bar{\\bm{a}}^2) = \\begin{bmatrix} \\frac{50}{3} &\n\\frac{34}{3} \\end{bmatrix} ./ \\begin{bmatrix} \\frac{4}{3} & \\frac{2}{3}\n\\end{bmatrix} = \\begin{bmatrix} \\frac{25}{2} & 17 \\end{bmatrix}\n\nHere, we see the minimum ratio is the first component so that e=1e=1 (which corresponds to column 𝐚1\\bm{a}_1), that is 𝐚−1\\bm{a}-1 replaces 𝐚3\\bm{a}_3 in the current basis.\nStep 3. The new basis is 𝐁=[𝐚2𝐚1]\\bm{B} = \\begin{bmatrix} \\bm{a}_2 & \\bm{a}_1 \\end{bmatrix}.\n𝐁=[1331],𝐁−1=[−183838−18],𝐚‾0=[−183838−18][22]=[1212],𝐲⊤=[1218][−183838−18]=[21494],\n\\begin{equation}\n\\bm{B} = \\begin{bmatrix} 1 & 3 \\\\ 3 & 1 \\end{bmatrix}, \\quad \\bm{B}^{-1} =\n\\begin{bmatrix} -\\frac{1}{8} & \\frac{3}{8} \\\\ \\frac{3}{8} & -\\frac{1}{8} \\end{bmatrix},\n\\quad \\bar{\\bm{a}}_0 = \\begin{bmatrix} -\\frac{1}{8} & \\frac{3}{8} \\\\ \\frac{3}{8} &\n-\\frac{1}{8} \\end{bmatrix}\\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix}\n\\frac{1}{2} \\\\ \\frac{1}{2} \\end{bmatrix}, \\quad \\bm{y}^\\top = \\begin{bmatrix}\n12 & 18 \\end{bmatrix} \\begin{bmatrix} -\\frac{1}{8} & \\frac{3}{8} \\\\ \\frac{3}{8} &\n-\\frac{1}{8} \\end{bmatrix} = \\begin{bmatrix} \\frac{21}{4} & \\frac{9}{4} \\end{bmatrix},\n\\end{equation}\n\nand\n𝐫𝐃⊤=[26]−[21494][−210−1]=[2523].\n\\bm{r}_{\\bm{D}}^\\top = \\begin{bmatrix} 2 & 6 \\end{bmatrix} - \\begin{bmatrix}\n\\frac{21}{4} & \\frac{9}{4} \\end{bmatrix}\\begin{bmatrix} -2 & 1 \\\\ 0 & -1 \\end{bmatrix} =\n\\begin{bmatrix} \\frac{25}{2} & 3 \\end{bmatrix}.\n\nStop! The solution pair is optimal!"
  },
  {
    "objectID": "04_simplex.html#the-primal-dual-algorithm",
    "href": "04_simplex.html#the-primal-dual-algorithm",
    "title": "04_simplex",
    "section": "The Primal-Dual Algorithm",
    "text": "The Primal-Dual Algorithm\n\n\n\nWe can work simultaneously on the primal and dual problems to solve LP problems.\nThe procedure begins with a feasible solution to the dual that is improved at each step by optimizing an associated restricted primal problem.\n\n\n\nAs the method progresses, it can be regarded as striving to achieve the complementary slackness conditions for optimality.\n\n\n\n\n\n\n\nminimize𝐜⊤𝐱subject to𝐀𝐱=𝐛,𝐱≥𝟎\n\\begin{align}\n\\operatorname{minimize} & \\bm{c}^\\top\\bm{x} \\\\\n\\text{subject to} & \\bm{Ax} = \\bm{b}, \\quad \\bm{x} \\geq \\bm{0}\n\\end{align}\n\n\n\n  and\n\n\nminimize𝐲⊤𝐛subject to𝐲⊤𝐀=𝐜⊤.(17)\n\\begin{align}\n\\operatorname{minimize} & \\bm{y}^\\top\\bm{b} \\\\\n\\text{subject to} & \\bm{y}^\\top\\bm{A} = \\bm{c}^\\top.\n\\end{align} \n \\qquad(17)\n\n\n\n\n\n\n\n\n\nGiven a feasible solution 𝐲\\bm{y}, not necessarily basic, to the dual, define the subset 𝒫\\mathcal{P} of indices {1,2,…,n}\\{1, 2, \\ldots, n\\} by j∈𝒫j \\in \\mathcal{P} if 𝐲⊤𝐚j=cj\\bm{y}^\\top \\bm{a}_j = c_j.\n\nSince 𝐲\\bm{y} is dual feasible, we have ∀j∉𝒫,𝐲⊤𝐚j&lt;cj\\forall j \\notin \\mathcal{P}, \\;\\; \\bm{y}^\\top \\bm{a}_j &lt; c_j.\n\nCorresponding to 𝐲\\bm{y} and the index set 𝒫\\mathcal{P}, we define the associated restricted primal problem\n\nminimize𝟏⊤𝐮,𝟏⊤=[11⋯1]subject to𝐀𝐱+𝐮=𝐛𝐱≥𝟎xj=0forj∉𝒫𝐮≥𝟎(18)\n\\begin{align}\n\\operatorname{minimize} & \\bm{1}^\\top \\bm{u}, & \\bm{1}^\\top = \\begin{bmatrix} 1 &\n1 & \\cdots & 1 \\end{bmatrix} \\\\\n\\text{subject to} & \\bm{Ax} + \\bm{u} = \\bm{b}  & \\\\\n& \\bm{x} \\geq \\bm{0} & x_j = 0 \\quad \\text{for} \\quad j \\notin \\mathcal{P} \\\\\n& \\bm{u} \\geq \\bm{0} & \n\\end{align}\n \\qquad(18)"
  },
  {
    "objectID": "04_simplex.html#the-primal-dual-algorithm-1",
    "href": "04_simplex.html#the-primal-dual-algorithm-1",
    "title": "04_simplex",
    "section": "The Primal-Dual Algorithm",
    "text": "The Primal-Dual Algorithm\n\nThe dual of this associated restricted primal is called the associated restricted dual with dual variable vector 𝐲′\\bm{y}^\\prime.\n\nmaximize(𝐲′)⊤𝐛subject to(𝐲′)⊤𝐚j≤0j∈𝒫(𝐲′)≤𝟏.(19)\n\\begin{align}\n\\operatorname{maximize} & (\\bm{y}^\\prime)^\\top \\bm{b}  & \\\\\n\\text{subject to} & (\\bm{y}^\\prime)^\\top \\bm{a}_j \\leq 0 & j \\in \\mathcal{P} \\\\\n& (\\bm{y}^\\prime) \\leq \\bm{1}.\n\\end{align}\n \\qquad(19)\n\n\n\nPrimal-Dual Optimality Theorem\n\n\nSuppose that 𝐲\\bm{y} is feasible for the original dual and that 𝐱\\bm{x} and 𝐮=𝟎\\bm{u} = \\bm{0} is feasible (and of course optimal) for the associated restricted primal. Then 𝐱\\bm{x} and 𝐲\\bm{y} are optimal for the original prime and dual programs, respectively.\n\n\n\n\n\n\nProof\n\n\nClearly 𝐱\\bm{x} is feasible for the primal. Also, we have 𝐜⊤𝐱=𝐲⊤𝐀𝐱\\bm{c}^\\top\\bm{x} = \\bm{y}^\\top\\bm{Ax} because 𝐲⊤𝐀\\bm{y}^\\top\\bm{A} is identical to 𝐜⊤\\bm{c}^\\top on the components corresponding to the nonzero elements of 𝐱\\bm{x}. Thus 𝐜⊤𝐱=𝐲⊤𝐀𝐱=𝐲⊤𝐛\\bm{c}^\\top\\bm{x} = \\bm{y}^\\top\\bm{Ax} = \\bm{y}^\\top\\bm{b} and optimality follows from strong duality or complementary slackness."
  },
  {
    "objectID": "04_simplex.html#the-primal-dual-algorithm-2",
    "href": "04_simplex.html#the-primal-dual-algorithm-2",
    "title": "04_simplex",
    "section": "The Primal-Dual Algorithm",
    "text": "The Primal-Dual Algorithm\nStep 1. Given a feasible solution 𝐲0\\bm{y}^0 to the dual program Equation 17, determine the associated restricted primal according to Equation 18.\nStep 2. Optimize the associated restricted primal. If the minimal value of this problem is zero, the corresponding solution and 𝐲0\\bm{y}^0 is an optimal pair for the original LP Equation 17.\nStep 3. If the minimal value of the associated restricted primal is strictly positive, the maximal objective value of the associated restricted dual Equation 19 is also positive from the strong duality theorem, that is, its optimal solution 𝐲′⊤𝐛&gt;0{\\bm{y}^\\prime}^\\top \\bm{b} &gt; 0. If there is no jj for which 𝐲′⊤𝐚j&gt;0{\\bm{y}^\\prime}^\\top \\bm{a}_j &gt; 0 for all j∉𝒫j \\notin \\mathcal{P}, conclude the primal has no feasible solutions from Farkas’s lemma.\nStep 4. If, on the other hand, for at least one j∉𝒫j \\notin \\mathcal{P}, 𝐲′⊤𝐚j&gt;0{\\bm{y}^\\prime}^\\top \\bm{a}_j &gt; 0, define the new dual feasible vector 𝐲(ε)=𝐲0+ε𝐲′,\n\\bm{y}(\\varepsilon) = \\bm{y}^0 + \\varepsilon \\bm{y}^\\prime,  where ε\\varepsilon is referred to as the stepsize, is chosen as large as possible till one of the constraints, j∉𝒫j \\notin \\mathcal{P} becomes equal 𝐲(ε)⊤𝐚j=cj,j∉𝒫. \\bm{y}(\\varepsilon)^\\top \\bm{a}_j = c_j, \\quad j \\notin \\mathcal{P}. \nIf ε\\varepsilon can be increased to ∞\\infty, then the original dual is unbounded. Otherwise ε&gt;0\\varepsilon &gt; 0 and we go back to Step 1 using this new dual feasible solution 𝐲(ε)\\bm{y}(\\varepsilon) whose dual objective is strictly increased. 𝐲(ε)⊤𝐛=(𝐲0)⊤𝐛+ε𝐲′⊤𝐛&gt;(𝐲0)⊤𝐛. \\bm{y}(\\varepsilon)^\\top \\bm{b} = (\\bm{y}^0)^\\top \\bm{b} + \\varepsilon\n{\\bm{y}^\\prime}^\\top \\bm{b} &gt; (\\bm{y}^0)^\\top \\bm{b}. \n\n\nOptimization Theory and Practice • Aykut C. Satici"
  }
]