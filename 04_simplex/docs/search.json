[
  {
    "objectID": "04_simplex.html#optimization-theory-and-practice",
    "href": "04_simplex.html#optimization-theory-and-practice",
    "title": "04_simplex",
    "section": "Optimization Theory and Practice",
    "text": "Optimization Theory and Practice\n\n\nThe Simplex Method\n\n\n\n\nInstructor: Aykut Satici, Ph.D.Â   Mechanical and Biomedical Engineering  Electrical and Computer Engineering  Boise State University, Boise, ID, USA\n\n\nTopics:   Adjacent BFS (Extreme Points)  Primal Simplex Method  Dual Simplex Method"
  },
  {
    "objectID": "04_simplex.html#adjacent-solutions",
    "href": "04_simplex.html#adjacent-solutions",
    "title": "04_simplex",
    "section": "Adjacent Solutions",
    "text": "Adjacent Solutions\n\nWe know that it is only necessary to consider basic feasible solutions to the system ğ€ğ±=ğ›,ğ±â‰¥ğŸ(1) \\bm{Ax} = \\bm{b}, \\quad \\bm{x} \\geq \\bm{0}  \\qquad(1) when solving a linear program.\nThe idea of the simplex method is to move from a basic feasible solution (extreme point) to an adjacent one with an improved objective value.\n\n\n\n\nDefinition\n\n\nTwo basic feasible solutions are said to be adjacent if and only if they differ by one basic variable.\n\n\n\n\nA new basic solution can be generated from an old one by replacing one current basic variable by a current nonbasic one.\n\nIt is impossible to arbitrarily specify a pair of variables whose roles are to be interchanged and expect to maintain the nonnegativity condition.\nHowever, it is possible to arbitrarily specify which current nonbasic (entering or incoming) variable is to become basic and then determine which current basic (leaving or outgoing) variable should become nonbasic."
  },
  {
    "objectID": "04_simplex.html#determination-of-a-vector-to-leave-the-basis",
    "href": "04_simplex.html#determination-of-a-vector-to-leave-the-basis",
    "title": "04_simplex",
    "section": "Determination of a Vector to Leave the Basis",
    "text": "Determination of a Vector to Leave the Basis\n\n\n\nLet the BFS be partitioned as ğ±ğ=(x1,x2,â€¦,xm)\\bm{x}_{\\bm{B}} = (x_1, x_2, \\ldots, x_m) and ğ±ğƒ=(xm+1,xm+2,â€¦,xn)\\bm{x}_{\\bm{D}} = (x_{m+1}, x_{m+2}, \\ldots, x_n).\n\n\n\nğ›\\bm{b} is a linear combination of columns of ğ=[ğš1ğš2â‹¯ğšm]\\bm{B} = \\begin{bmatrix} \\bm{a}_1 & \\bm{a}_2 & \\cdots & \\bm{a}_m \\end{bmatrix} with the positive multipliers (x1,x2,â€¦,xm)(x_1, x_2, \\ldots, x_m).\n\n\n\nğ›=ğğ±ğ=x1ğš1+x2ğš2+â‹¯+xmğšm,whereğ±ğ=ğšâ€¾0:=ğâˆ’1ğ›â‰¥ğŸ.(2) \\bm{b} = \\bm{B}\\bm{x}_{\\bm{B}} = x_1\\bm{a}_1 + x_2 \\bm{a}_2 + \\cdots +\nx_m\\bm{a}_m, \\quad \\text{where} \\quad \\bm{x}_{\\bm{B}} = \\bar{\\bm{a}}_0 :=\n\\bm{B}^{-1}\\bm{b} \\geq \\bm{0}.  \\qquad(2)\n\n\n\nSuppose we decided to bring into representation the ethe^{\\text{th}} (entering) column vector of ğ€\\bm{A}, ğše\\bm{a}_e (e&gt;me &gt; m), while keeping all others nonbasic.\n\n\n\nA new representation of ğ›\\bm{b} as a linear combination of m+1m+1 vectors (ğše\\bm{a}_e added to the current basis ğ\\bm{B}) for any nonnegative multiplier xex_e and ğ±ğ\\bm{x}_{\\bm{B}}:\n\n\n\nğ›=ğğ±ğ+ğšexe,orğšâ€¾0=ğâˆ’1ğ›=ğ±ğ+(ğâˆ’1ğše)xe.(3) \\bm{b} = \\bm{Bx_B} + \\bm{a}_ex_e, \\quad \\text{or} \\quad \\bar{\\bm{a}}_0 =\n\\bm{B}^{-1}\\bm{b} = \\bm{x}_{\\bm{B}} + (\\bm{B}^{-1}\\bm{a}_e)x_e.  \\qquad(3)\n\n\n\nSince xex_e is the incoming variable, its value needs to be increased from the current 00 to a positive value, say Îµâ‰¥0\\varepsilon \\geq 0.\n\n\n\nAs xex_e value increases, the current basic variable ğ±ğ\\bm{x}_{\\bm{B}} needs to be adjusted accordingly ot keep the feasibility.\n\n\n\nğ±ğ=ğšâ€¾0âˆ’Îµ(ğâˆ’1ğše)=ğšâ€¾0âˆ’Îµğšâ€¾eâ‰¥ğŸ,whereğšâ€¾e=ğâˆ’1ğše.(4)\n\\bm{x}_{\\bm{B}} = \\bar{\\bm{a}}_0 - \\varepsilon(\\bm{B}^{-1}\\bm{a}_e) =\n\\bar{\\bm{a}}_0 - \\varepsilon\\bar{\\bm{a}}_e \\geq \\bm{0}, \\quad \\text{where} \\quad\n\\bar{\\bm{a}}_e = \\bm{B}^{-1}\\bm{a}_e.\n \\qquad(4)"
  },
  {
    "objectID": "04_simplex.html#determination-of-a-vector-to-leave-the-basis-1",
    "href": "04_simplex.html#determination-of-a-vector-to-leave-the-basis-1",
    "title": "04_simplex",
    "section": "Determination of a Vector to Leave the Basis",
    "text": "Determination of a Vector to Leave the Basis\n\n\n\nFor Îµ=0\\varepsilon = 0, we have the old basic feasible solution ğ±ğ=ğšâ€¾0&gt;ğŸ\\bm{x}_{\\bm{B}} = \\bar{\\bm{a}}_0 &gt; \\bm{0}.\nThe values of ğ±ğ\\bm{x}_{\\bm{B}} will either increase or remain unchanged if aâ€¾ieâ‰¤0\\bar{a}_{ie} \\leq 0; or decrease linearly as Îµ\\varepsilon is increased if aâ€¾ie&gt;0\\bar{a}_{ie} &gt; 0.\n\n\n\nFor small enough Îµ\\varepsilon, EquationÂ 3 gives a feasible but nonbasic solution.\nIf any decrease, we may set Îµ\\varepsilon equal to the value corresponding to the first place where one (or more) of the value vanishes\n\n\n\nÎµ=mini{aâ€¾i0aâ€¾ie:aâ€¾ie&gt;0}.(5) \\varepsilon = \\operatorname{min}_i \\left\\{\\frac{\\bar{a}_{i0}}{\\bar{a}_{ie}}:\n\\bar{a}_{ie} &gt; 0 \\right\\}.  \\qquad(5)\n\n\n\nWe have a new BFS, with the vector ğše\\bm{a}_e replacing (outgoing) column ğšo\\bm{a}_o, where index oâ‰¤mo \\leq m corresponds to the minimizing-ratio in EquationÂ 5 o=argâ€†mini{aâ€¾i0aâ€¾ie:aâ€¾ie&gt;0}. o = \\operatorname{arg \\, min}_i \\left\\{\\frac{\\bar{a}_{i0}}{\\bar{a}_{ie}}:\n\\bar{a}_{ie} &gt; 0 \\right\\}.\n\n\n\nIf none of the aâ€¾ie\\bar{a}_{ie}â€™s are positive, then all coefficients in EquationÂ 3 increase (or remain constant) as Îµ\\varepsilon is increased, and no new basic feasible solution is obtained.\nIn this case the set KK of feasible solutions to EquationÂ 1 is unbounded."
  },
  {
    "objectID": "04_simplex.html#conic-combination-interpretations",
    "href": "04_simplex.html#conic-combination-interpretations",
    "title": "04_simplex",
    "section": "Conic Combination Interpretations",
    "text": "Conic Combination Interpretations\n\n\n\nThe basis transformation can be represented in the requirements space, the space where columns of ğ€\\bm{A} and ğ›\\bm{b} are represented.\n\nğš1x1+ğš2x2+â‹¯+ğšnxn=ğ›. \\bm{a}_1x_1 + \\bm{a}_2x_2 + \\cdots + \\bm{a}_nx_n = \\bm{b}. \n\nA feasible solution defines a representation of ğ›\\bm{b} as a conic combination of the ğši\\bm{a}_iâ€™s.\nA BFS will only use mm psoitive weights.\nSuppose we start with ğš1\\bm{a}_1 and ğš2\\bm{a}_2 as the initial basis.\n\nThen an adjacent basis is found by bringing in some other vector.\nIf ğš3\\bm{a}_3 is brought in, then clearly ğš2\\bm{a}_2 must go out (why?).\nOn the other hand, if ğš4\\bm{a}_4 is brought in, ğš1\\bm{a}_1 must go out (why?).\n\n\n\n\n\n\n\n\n\n\nA BFS can be constructed with positive weights on ğš1\\bm{a}_1 and ğš2\\bm{a}_2 because ğ›\\bm{b} lies between them.\nA BFS cannot be constructed with positive weights on ğš1\\bm{a}_1 and ğš4\\bm{a}_4.\n\n\n\n\n\n\n\nAnother interpretation is in the activity space, the space where ğ±\\bm{x} lives.\n\nHere, the feasible region is shown directly as a convex set, and BFS are extreme points.\nAdjacent extreme points are points that lie on a common edge."
  },
  {
    "objectID": "04_simplex.html#conic-combination-interpretations-example",
    "href": "04_simplex.html#conic-combination-interpretations-example",
    "title": "04_simplex",
    "section": "Conic Combination Interpretations â€“ Example",
    "text": "Conic Combination Interpretations â€“ Example\n\n\n\nExample (Basis Change Illustration)\n\n\n3x1+x2âˆ’2x3+x4=2,x1+3x2âˆ’x4=2.\n\\begin{align}\n3x_1 + x_2 - 2x_3 + x_4 &= 2, \\\\\nx_1 + 3x_2 - x_4 &= 2.\n\\end{align}\n\n\n\n\n\nSuppose we start with ğš1\\bm{a}_1 and ğš2\\bm{a}_2 as the initial basis and select ğš3\\bm{a}_3 as the incoming column. Then \n\nğ=(3113),ğâˆ’1=(3818âˆ’1838),ğšâ€¾0=ğâˆ’1ğ›=(1212),ğšâ€¾3=ğâˆ’1ğš3=(âˆ’34âˆ’14).\n\\begin{equation}\n\\bm{B} = \\begin{pmatrix} 3 & 1 \\\\ 1 & 3 \\end{pmatrix}, \\quad \\bm{B}^{-1} =\n\\begin{pmatrix} \\frac{3}{8} & \\frac{1}{8} \\\\ -\\frac{1}{8} & \\frac{3}{8}\n\\end{pmatrix}, \\quad \\bar{\\bm{a}}_0 = \\bm{B}^{-1}\\bm{b} = \\begin{pmatrix}\n\\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix}, \\quad \\bar{\\bm{a}}_3 =\n\\bm{B}^{-1}\\bm{a}_3 = \\begin{pmatrix} -\\frac{3}{4} \\\\ -\\frac{1}{4}\n\\end{pmatrix}.\n\\end{equation}\n\n\nFrom EquationÂ 5, Îµ=2\\varepsilon = 2 and ğš2\\bm{a}_2 is the outgoing column so that the new basis is formed by ğš1\\bm{a}_1 and ğš3\\bm{a}_3. \nNow, suppose we start with ğš1\\bm{a}_1 and ğš3\\bm{a}_3 as the initial basis and select ğš4\\bm{a}_4 as the incoming column. Then\n\nğ=(31âˆ’20),ğâˆ’1=(01âˆ’1232),ğšâ€¾0=ğâˆ’1ğ›=(22),ğšâ€¾4=ğâˆ’1ğš4=(âˆ’1âˆ’2).\n\\begin{equation}\n\\bm{B} = \\begin{pmatrix} 3 & 1 \\\\ -2 & 0 \\end{pmatrix}, \\quad \\bm{B}^{-1} =\n\\begin{pmatrix} 0 & 1 \\\\ -\\frac{1}{2} & \\frac{3}{2}\n\\end{pmatrix}, \\quad \\bar{\\bm{a}}_0 = \\bm{B}^{-1}\\bm{b} = \\begin{pmatrix}\n2 \\\\ 2 \\end{pmatrix}, \\quad \\bar{\\bm{a}}_4 =\n\\bm{B}^{-1}\\bm{a}_4 = \\begin{pmatrix} -1 \\\\ -2\n\\end{pmatrix}.\n\\end{equation}\n\n\nSince the entries of the incoming column ğšâ€¾4\\bar{\\bm{a}}_4 are all negative, Îµ\\varepsilon in EquationÂ 5 can go to âˆ\\infty, indicating that the feasible region is unbounded."
  },
  {
    "objectID": "04_simplex.html#determining-an-optimal-feasible-solution",
    "href": "04_simplex.html#determining-an-optimal-feasible-solution",
    "title": "04_simplex",
    "section": "Determining an Optimal Feasible Solution",
    "text": "Determining an Optimal Feasible Solution\n\n\n\nThe idea of the simplex method is to select the incoming column so that the resulting new BFS will yield a lower value to the objective function than the previous one.\n\n\n\n\n\n\nAssume that ğ\\bm{B} consists of the first mm columns of AA. Then partition ğ€,ğ±\\bm{A}, \\bm{x} and ğœâŠ¤\\bm{c}^\\top as\n\nğ€=[ğğƒ] \\bm{A} = \\begin{bmatrix} \\bm{B} & \\bm{D} \\end{bmatrix}  ğ±=[ğ±ğğ±ğƒ],ğœâŠ¤=[ğœğâŠ¤ğœğƒâŠ¤]. \\bm{x} =\n\\begin{bmatrix}\\bm{x}_{\\bm{B}} & \\bm{x}_{\\bm{D}}\\end{bmatrix}, \\quad \\bm{c}^\\top\n= \\begin{bmatrix} \\bm{c}_{\\bm{B}}^\\top & \\bm{c}_{\\bm{D}}^\\top \\end{bmatrix}. \n\nSuppose we have a basic feasible solution ğ±ğ=ğšâ€¾0:=ğâˆ’1ğ›â‰¥ğŸ,andğ±ğƒ=ğŸ. \\bm{x}_{\\bm{B}} = \\bar{\\bm{a}}_0 := \\bm{B}^{-1}\\bm{b} \\geq \\bm{0}, \\quad\n\\text{and} \\quad \\bm{x}_{\\bm{D}} = \\bm{0}. \nThe value of the objective function is z=c1x1+c2x2+â‹¯+cnxn=ğœğâŠ¤ğ±ğ+ğœğƒâŠ¤ğ±ğƒ(6) z = c_1x_1 + c_2x_2 + \\cdots + c_nx_n = \\bm{c}_{\\bm{B}}^\\top\\bm{x}_{\\bm{B}} +\n\\bm{c}_{\\bm{D}}^\\top\\bm{x}_{\\bm{D}}   \\qquad(6)\nHence for the current basic solution, the corresponding value is z0=ğœğâŠ¤ğâˆ’1ğ›.(7) z_0 = \\bm{c}_{\\bm{B}}^\\top \\bm{B}^{-1}\\bm{b}.  \\qquad(7)\n\n\n\nFor any value of ğ±ğƒ\\bm{x}_{\\bm{D}} the necessary value of ğ±ğ\\bm{x}_{\\bm{B}} is determined from mm equality constraints of the linear program, i.e., from ğ€ğ±=ğ›\\bm{Ax} = \\bm{b}.\n\nğğ±ğ+ğƒğ±ğƒ=ğ›orğ±ğ=ğâˆ’1ğ›âˆ’ğâˆ’1ğƒğ±ğƒ(8) \\bm{Bx_{B} + Dx_D} = \\bm{b} \\quad \\text{or} \\quad \\bm{x_B} =\n\\bm{B}^{-1}\\bm{b} - \\bm{B}^{-1}\\bm{D}\\bm{x_D}  \\qquad(8)\n\nWhen this expression is substituted into EquationÂ 6 we obtain z=ğœğâŠ¤(ğâˆ’1ğ›âˆ’ğâˆ’1ğƒğ±ğƒ)+ğœğƒâŠ¤ğ±ğƒ=ğœğâŠ¤ğâˆ’1ğ›+(ğœğƒâŠ¤âˆ’ğœğâŠ¤ğâˆ’1ğƒ)ğ±ğƒ=z0+(ğœğƒâŠ¤âˆ’ğ²âŠ¤ğƒ)ğ±ğƒ.(9)\n\\begin{align}\nz &= \\bm{c}_{\\bm{B}}^\\top(\\bm{B}^{-1}\\bm{b}-\\bm{B}^{-1}\\bm{Dx_D}) +\n\\bm{c}_{\\bm{D}}^\\top\\bm{x_D} \\\\\n&= \\bm{c}_{\\bm{B}}^\\top\\bm{B}^{-1}\\bm{b} + (\\bm{c}_{\\bm{D}}^\\top -\n\\bm{c}_{\\bm{B}}^\\top\\bm{B}^{-1}\\bm{D})\\bm{x_D} \\\\\n&= z_0 + (\\bm{c}_{\\bm{D}}^\\top - \\bm{y}^\\top\\bm{D})\\bm{x_D}.\n\\end{align}\n \\qquad(9)"
  },
  {
    "objectID": "04_simplex.html#determining-an-optimal-feasible-solution-1",
    "href": "04_simplex.html#determining-an-optimal-feasible-solution-1",
    "title": "04_simplex",
    "section": "Determining an Optimal Feasible Solution",
    "text": "Determining an Optimal Feasible Solution\n\nEquationÂ 9 expresses the cost of any feasible solution to EquationÂ 1 in terms of the independent variable in ğ±ğƒ\\bm{x_D}.\nHere, ğ²âŠ¤=ğœğâŠ¤ğâˆ’1\\bm{y}^\\top = \\bm{c}_{\\bm{B}}^\\top\\bm{B}^{-1} is the simplex multipliers or the shadow prices corresponding to basis ğ\\bm{B}.\n\n\n\n\nLet ğ«ğƒâŠ¤=ğœğƒâŠ¤âˆ’ğ²âŠ¤ğƒ.(10) \\bm{r}_{\\bm{D}}^\\top = \\bm{c}_{\\bm{D}}^\\top - \\bm{y}^\\top\\bm{D}.  \\qquad(10)\nThen from formula EquationÂ 9, z=ğœâŠ¤ğ±=z0+âˆ‘j=m+1nrjxj(11) z = \\bm{c}^\\top \\bm{x} = z_0 + \\sum_{j=m+1}^n r_jx_j  \\qquad(11)\nThe vector ğ«ğƒ\\bm{r_D} represents the relative cost vector, also called reduced cost or reduced gradient vector for nonbasic variables in ğ±ğƒ\\bm{x_D}.\n\n\n\nFrom formula EquationÂ 11, we can now determine if there is any advantage in changing the basic solution by introducing one of the nonbasic variables.\n\nIf rjr_j is negative for some jj, m+1â‰¤jâ‰¤nm+1 \\leq j \\leq n, then increasing xjx_j from zero to some positive value would decrease the total cost, yielding a better solution.\nEquationÂ 11 automatically takes into account the changes that would be required in the values of the basic variables x1,x2,â€¦,xmx_1, x_2, \\ldots, x_m to accommodate for the change in xjx_j."
  },
  {
    "objectID": "04_simplex.html#determining-an-optimal-feasible-solution-2",
    "href": "04_simplex.html#determining-an-optimal-feasible-solution-2",
    "title": "04_simplex",
    "section": "Determining an Optimal Feasible Solution",
    "text": "Determining an Optimal Feasible Solution\n\n\n\nTheorem (Improvement of Basic Feasible Solution)\n\n\nGiven a nondegenerate BFS with corresponding objective value z0z_0, suppose that for some jj there holds rj&lt;0r_j &lt; 0. Then there is a feasible solution with objective value z&lt;z0z &lt; z_0. If the column ğšj\\bm{a}_j can be substituted for some vector in the original basis to yield a new basic feasible solution, this new solution will have z&lt;z0z &lt; z_0. If ğšj\\bm{a}_j cannot be substituted to yield a BFS then the solution set KK is unbounded and the objective function can be made arbitarily small (toward minus infinity).\n\n\n\n\nFinal question: Does rjâ‰¥0,âˆ€jr_j \\geq 0, \\;\\; \\forall j imply optimality?\n\nThe answer is â€œyesâ€ due to strong duality and the fact that\n\n\nğ«ğâŠ¤=ğœğâŠ¤âˆ’ğ²âŠ¤ğ=ğœğâŠ¤âˆ’ğœğâŠ¤=ğŸ. \\bm{r}_{\\bm{B}}^\\top = \\bm{c}_{\\bm{B}}^\\top - \\bm{y}^\\top\\bm{B} =\n\\bm{c}_{\\bm{B}}^\\top - \\bm{c}_{\\bm{B}}^\\top = \\bm{0}. \nThis means that\n0=ğ«ğâŠ¤ğ±ğ=ğœğâŠ¤ğ±ğâˆ’ğ²âŠ¤ğğ±ğ=ğœğâŠ¤ğ±ğâˆ’ğ²âŠ¤ğğâˆ’1ğ›=ğœâŠ¤ğ±âˆ’ğ²âŠ¤ğ›.\n0 = \\bm{r}_{\\bm{B}}^\\top \\bm{x_B} = \\bm{c}_{\\bm{B}}^\\top \\bm{x}_{\\bm{B}} -\n\\bm{y}^\\top \\bm{Bx_B} = \\bm{c}_{\\bm{B}}^\\top \\bm{x}_{\\bm{B}} - \\bm{y}^\\top\n\\bm{B}\\bm{B}^{-1}\\bm{b} = \\bm{c}^\\top \\bm{x} - \\bm{y}^\\top \\bm{b}.\n\nand strong duality forces that ğ±\\bm{x} is optimal.\n\n\n\nOptimality Condition Theorem\n\n\nIf for some basic feasible solution rjâ‰¥0âˆ€jr_j \\geq 0 \\;\\; \\forall j, then that solution is optimal."
  },
  {
    "objectID": "04_simplex.html#economic-interpretations-diet-problem",
    "href": "04_simplex.html#economic-interpretations-diet-problem",
    "title": "04_simplex",
    "section": "Economic Interpretations â€“ Diet Problem",
    "text": "Economic Interpretations â€“ Diet Problem\nÂ \n\n\n\n\n\nOptimality\n\n\n\nWe consider a certain food not in the basis â€“ say carrots â€“ and determine if it would be advantageous to bring it into the basis.\nThis is easily determined by examining the cost of carrots as compared with the cost of synthetic carrots.\nSay carrots are food jj, whose unit cost is cjc_j. The cost of a unit of synthetic carrots is âˆ‘i=1mci(ğâˆ’1ğšj)i=ğœğâŠ¤ğâˆ’1ğšj=ğ²âŠ¤ğšj. \\sum_{i=1}^m c_i (\\bm{B}^{-1}\\bm{a}_j)_i = \\bm{c}_{\\bm{B}}^\\top\n\\bm{B}^{-1}\\bm{a}_j = \\bm{y}^\\top \\bm{a}_j. \nIf the reduced coefficient rj=cjâˆ’ğ²âŠ¤ğšj&lt;0r_j = c_j - \\bm{y}^\\top\\bm{a}_j &lt; 0, it is advantageous to use real carrots in place of synthetic carrots, and carrots should be brought into the basis.\nIn general, each ğ²âŠ¤ğšj\\bm{y}^\\top \\bm{a}_j can be thought of as the price of a unit of the column ğšj\\bm{a}_j when constructed from the current basis.\n\nThe difference between this synthetic price and the direct price of that column determines whether that column should enter the basis.\n\n\n\n\n\n\n\n\n\nDiet Problem (Exact nutritional requirements)\n\n\nminimizeğœâŠ¤ğ±subject toğ€ğ±=ğ›,ğ±â‰¥ğŸ.\n\\begin{align}\n\\operatorname{minimize} & \\bm{c}^\\top \\bm{x} \\\\\n\\text{subject to} & \\bm{Ax} = \\bm{b}, \\quad \\bm{x} \\geq \\bm{0}.\n\\end{align}\n\n\nğšj\\bm{a}_j gives the nutritional equivalent of a unit of a particular food.\nGiven a basis ğ\\bm{B}, say the first mm columns of ğ€\\bm{A}, the corresponding ğâˆ’1ğšj\\bm{B}^{-1}\\bm{a}_j shows how the nutritinal contents of any food jj can be constructed as a combination of the foods in the basis.\nFor instance, if carrots are not in the basis we can, using the description given by the tableau, construct a synthetic carrot, which is nutritionally equivalent to a carrot, by an appropriate combination of the foods in the basis."
  },
  {
    "objectID": "04_simplex.html#the-simplex-procedure",
    "href": "04_simplex.html#the-simplex-procedure",
    "title": "04_simplex",
    "section": "The Simplex Procedure",
    "text": "The Simplex Procedure\n\n\n\nStep 0. Given the the inverse ğâˆ’1\\bm{B}^{-1} of a current basis, and the current solution ğ±ğ=ğšâ€¾0=ğâˆ’1ğ›\\bm{x}_{\\bm{B}} = \\bar{\\bm{a}}_0 = \\bm{B}^{-1}\\bm{b}.\nStep 1. Calculate the current simplex multiplier vector ğ²âŠ¤=ğœğâŠ¤ğâˆ’1\\bm{y}^\\top = \\bm{c}_{\\bm{B}}^\\top\\bm{B}^{-1} and then calculate the relative cost coefficients ğ«ğƒâŠ¤=ğœğƒâŠ¤âˆ’ğ²âŠ¤ğƒ\\bm{r}_{\\bm{D}}^\\top = \\bm{c}_{\\bm{D}}^\\top - \\bm{y}^\\top\\bm{D}. If ğ«ğƒâ‰¥ğŸ\\bm{r}_{\\bm{D}} \\geq \\bm{0} stop; the current solution is optimal.\nStep 2. Determine the vector ğše\\bm{a}_e that is to enter the basis by selecting its most negative cost coefficient, the ethe^{\\text{th}} (e&gt;me &gt; m) coefficient (break ties arbitrarily); and calculate ğšâ€¾e=ğâˆ’1ğše\\bar{\\bm{a}}_e = \\bm{B}^{-1}\\bm{a}_e.\nStep 3. If ğšâ€¾eâ‰¤ğŸ\\bar{\\bm{a}}_e \\leq \\bm{0}, stop; the problem is unbounded. Otherwise, calculate the ratios aâ€¾i0aâ€¾ie\\frac{\\bar{a}_{i0}}{\\bar{a}_{ie}} for aâ€¾ie&gt;0\\bar{a}_{ie} &gt; 0 to determine the current basic column, ğšo\\bm{a}_o where oâ‰¤m+1o \\leq m+1 corresponds to the index of the minimum ratio, to leave the basis.\nStep 4. Update ğâˆ’1\\bm{B}^{-1} (or its factorization) and the new basic feasible solution ğšâ€¾0=ğâˆ’1ğ›\\bar{\\bm{a}}_0 = \\bm{B}^{-1}\\bm{b}. Return to Step 1.\n\n\n\n\n\n\nRemark\n\n\nThe basic columns in ğ\\bm{B} and the nonbasic columns in ğƒ\\bm{D} can be ordered arbitrarily and the components in ğ±ğ,ğ±ğƒ,ğœğ,ğœğƒ\\bm{x_B}, \\bm{x_D}, \\bm{c_B}, \\bm{c_D} follow the same index orders.\nMore precisely, let columns be permuted as ğ=[ğšÏƒ(1)ğšÏƒ(2)â‹¯ğšÏƒ(m)]\\bm{B} = \\begin{bmatrix} \\bm{a}_{\\sigma(1)} & \\bm{a}_{\\sigma(2)} & \\cdots & \\bm{a}_{\\sigma(m)} \\end{bmatrix} and ğƒ=[ğšÏƒ(m+1)ğšÏƒ(m+2)â‹¯ğšÏƒ(n)]\\bm{D} = \\begin{bmatrix} \\bm{a}_{\\sigma(m+1)} & \\bm{a}_{\\sigma(m+2)} & \\cdots & \\bm{a}_{\\sigma(n)} \\end{bmatrix}. Then when rer_e is identified as the most negative coefficient in ğ«ğƒ\\bm{r}_{\\bm{D}} in Step 2, ğšÏƒ(e)\\bm{a}_{\\sigma(e)} is the entering column. Similarly, when oo is identified as the minmum ratio index in Step 3, ğšÏƒ(o)\\bm{a}_{\\sigma(o)} is the outgoing column."
  },
  {
    "objectID": "04_simplex.html#example-primal-simplex-procedure-illustration",
    "href": "04_simplex.html#example-primal-simplex-procedure-illustration",
    "title": "04_simplex",
    "section": "Example â€“ Primal Simplex Procedure Illustration ",
    "text": "Example â€“ Primal Simplex Procedure Illustration \nSuppose we start with the initial basis ğ=[ğš1ğš3]\\bm{B} = \\begin{bmatrix} \\bm{a}_1 & \\bm{a}_3 \\end{bmatrix} and ğƒ=[ğš2ğš4]\\bm{D} = \\begin{bmatrix} \\bm{a}_2 & \\bm{a}_4 \\end{bmatrix}.\n\n\nStep 0. Initialization\nğ=[3âˆ’210],ğâˆ’1=[01âˆ’1232],ğšâ€¾0=ğâˆ’1ğ›=[22].\n\\begin{equation}\n\\bm{B} = \\begin{bmatrix} 3 & -2 \\\\ 1 & 0 \\end{bmatrix}, \\quad \\bm{B}^{-1} =\n\\begin{bmatrix} 0 & 1 \\\\ -\\frac{1}{2} & \\frac{3}{2} \\end{bmatrix}, \\quad\n\\bar{\\bm{a}}_0 = \\bm{B}^{-1}\\bm{b} = \\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix}.\n\\end{equation}\n\nStep 1. Calculate\nğ²âŠ¤=ğœğâŠ¤ğâˆ’1=[182][01âˆ’1232]=[âˆ’121]. \n\\begin{equation}\n\\bm{y}^\\top = \\bm{c}_{\\bm{B}}^\\top\\bm{B}^{-1} = \\begin{bmatrix} 18 & 2\n\\end{bmatrix} \\begin{bmatrix} 0 & 1 \\\\ -\\frac{1}{2} & \\frac{3}{2} \\end{bmatrix}\n= \\begin{bmatrix} -1 & 21 \\end{bmatrix}.\n\\end{equation}\n\nand\nğ«ğƒâŠ¤=ğœğƒâŠ¤âˆ’ğ²âŠ¤ğƒ=[126]âˆ’[âˆ’121][113âˆ’1]=[âˆ’5028].\n\\begin{equation}\n\\bm{r}_{\\bm{D}}^\\top = \\bm{c}_{\\bm{D}}^\\top - \\bm{y}^\\top\\bm{D} =\n\\begin{bmatrix} 12 & 6 \\end{bmatrix} - \\begin{bmatrix} -1 & 21 \\end{bmatrix}\n\\begin{bmatrix} 1 & 1 \\\\ 3 & -1 \\end{bmatrix} = \\begin{bmatrix} -50 & 28\n\\end{bmatrix}.\n\\end{equation}\n\nStep 2. Then see e=2e = 2, that is,ğš2\\bm{a}_2 is the incoming column, and calculate\nğšâ€¾2=ğâˆ’1ğš2=[01âˆ’1232][13]=[34].\n\\bar{\\bm{a}}_2 = \\bm{B}^{-1}\\bm{a}_2 = \\begin{bmatrix} 0 & 1 \\\\ -\\frac{1}{2} &\n\\frac{3}{2} \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 3 \\end{bmatrix} = \\begin{bmatrix}\n3 \\\\ 4 \\end{bmatrix}.\n\n\n\n\n\nminimize18x1+12x2+2x3+6x4subject to3x1+x2âˆ’2x3+x4=2,x1+3x2âˆ’x4=2,x1,x2,x3,x4â‰¥0.\n\\begin{align}\n\\operatorname{minimize} & 18x_1 + 12x_2 + 2x_3 + 6x_4 \\\\\n\\text{subject to} & 3x_1 + x_2 - 2x_3 + x_4 = 2, \\\\\n& x_1 + 3x_2 - x_4 = 2, \\\\\n& x_1, x_2, x_3, x_4 \\geq 0.\n\\end{align}\n\n\n\n\nStep 3. Since ğšâ€¾2â‰¥ğŸ\\bar{\\bm{a}}_2 \\geq \\bm{0} the ratios are, via the component-wise divide operation\nğšâ€¾0./ğšâ€¾2=[22]./[34]=[2312].\n\\bar{\\bm{a}}_0 ./ \\bar{\\bm{a}}_2 = \\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix} ./\n\\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix} = \\begin{bmatrix} \\frac{2}{3} \\\\\n\\frac{1}{2} \\end{bmatrix}.\n\nThe minimum ratio correspondes to column ğš3\\bm{a}_3 (o=3o=3) that would be outgoing. That is ğš2\\bm{a}_2 replaces ğš3\\bm{a}_3 in the basis, which is now ğ=[ğš1ğš2]\\bm{B} = \\begin{bmatrix} \\bm{a}_1 & \\bm{a}_2 \\end{bmatrix} and ğƒ=[ğš2ğš4]\\bm{D} = \\begin{bmatrix} \\bm{a}_2 & \\bm{a}_4 \\end{bmatrix}."
  },
  {
    "objectID": "04_simplex.html#example-primal-simplex-procedure-illustration-1",
    "href": "04_simplex.html#example-primal-simplex-procedure-illustration-1",
    "title": "04_simplex",
    "section": "Example â€“ Primal Simplex Procedure Illustration ",
    "text": "Example â€“ Primal Simplex Procedure Illustration \nStep 4. Update\nğ=[3113],ğâˆ’1=[38âˆ’18âˆ’1838],ğšâ€¾0=ğâˆ’1ğ›=[1212].\n\\begin{equation}\n\\bm{B} = \\begin{bmatrix} 3 & 1 \\\\ 1 & 3 \\end{bmatrix}, \\quad \\bm{B}^{-1} =\n\\begin{bmatrix} \\frac{3}{8} & -\\frac{1}{8} \\\\ -\\frac{1}{8} & \\frac{3}{8}\n\\end{bmatrix}, \\quad \\bar{\\bm{a}}_0 = \\bm{B}^{-1}\\bm{b} = \\begin{bmatrix}\n\\frac{1}{2} \\\\ \\frac{1}{2} \\end{bmatrix}.\n\\end{equation}\n\nReturn to Step 1.\nSecond Iteration\nStep 1. Calculateğ²âŠ¤=ğœğâŠ¤ğâˆ’1=[182][38âˆ’18âˆ’1838]=[21494]. \n\\begin{equation}\n\\bm{y}^\\top = \\bm{c}_{\\bm{B}}^\\top\\bm{B}^{-1} = \\begin{bmatrix} 18 & 2\n\\end{bmatrix} \\begin{bmatrix} \\frac{3}{8} & -\\frac{1}{8} \\\\ -\\frac{1}{8} & \\frac{3}{8} \\end{bmatrix}\n= \\begin{bmatrix} \\frac{21}{4} & \\frac{9}{4} \\end{bmatrix}.\n\\end{equation}\n\nand\nğ«ğƒâŠ¤=ğœğƒâŠ¤âˆ’ğ²âŠ¤ğƒ=[26]âˆ’[21494][âˆ’210âˆ’1]=[2523].\n\\begin{equation}\n\\bm{r}_{\\bm{D}}^\\top = \\bm{c}_{\\bm{D}}^\\top - \\bm{y}^\\top\\bm{D} =\n\\begin{bmatrix} 2 & 6 \\end{bmatrix} - \\begin{bmatrix} \\frac{21}{4} & \\frac{9}{4} \\end{bmatrix}\n\\begin{bmatrix} -2 & 1 \\\\ 0 & -1 \\end{bmatrix} = \\begin{bmatrix} \\frac{25}{2} & 3 \n\\end{bmatrix}.\n\\end{equation}\n\nStop! All of the reduced costs are positive so the current basic feasible solution is optimal!"
  },
  {
    "objectID": "04_simplex.html#finding-an-initial-basic-feasible-solution",
    "href": "04_simplex.html#finding-an-initial-basic-feasible-solution",
    "title": "04_simplex",
    "section": "Finding an Initial Basic Feasible Solution",
    "text": "Finding an Initial Basic Feasible Solution\n\n\n\nThe simplex procedure needs to start from a basic feasible solution.\nSuch a BFS is some times immediately available:\n\nif the constraints are of this form ğ€ğ±â‰¤ğ›,ğ±â‰¥ğŸ\\bm{Ax} \\leq \\bm{b}, \\quad \\bm{x} \\geq \\bm{0}, with ğ›â‰¥ğŸ\\bm{b} \\geq \\bm{0}\na BFS to the corresponding standard form of the problem is provided by the slack variables.\n\nAn initial BFS is not always apparent for other types of LPs.\nFor those, an auxiliary LP and a corresponding application of the simplex method can be used to determined the required initial solution.\nAn LP can always be expressed in the so-called Phase I form: ğ€ğ±=ğ›â‰¥ğŸ,ğ±â‰¥ğŸ.(12) \\bm{Ax} =\n\\bm{b} \\geq \\bm{0}, \\quad \\bm{x} \\geq \\bm{0}.  \\qquad(12)\n\n\n\nIn order to find a solution to EquationÂ 12, we consider the artificial minimization problem (Phase One linear program)\n\nminimizeâˆ‘i=1mujsubject toğ€ğ±+ğ®=ğ›ğ±â‰¥ğŸ,ğ®â‰¥ğŸ.(13)\n\\begin{align}\n\\operatorname{minimize} & \\sum_{i=1}^m u_j \\\\\n\\text{subject to} & \\bm{Ax} + \\bm{u} = \\bm{b} \\\\\n& \\bm{x} \\geq \\bm{0}, \\quad \\bm{u} \\geq \\bm{0}.\n\\end{align}\n \\qquad(13) where ğ®=(u1,u2,â€¦,um)\\bm{u} = (u_1, u_2, \\ldots, u_m) is a vector of artifical variables.\n\nIf there is a feasible solution to EquationÂ 12, then it is clear that EquationÂ 13 has a minimum value of zero with ğ®=ğŸ\\bm{u} = \\bm{0}.\nIf EquationÂ 12 has no feasible solution, then the minimum value of EquationÂ 13 is greater than zero.\nEquationÂ 13 is an LP and the a BFS for it is ğ®=ğ›\\bm{u} = \\bm{b}. It can readily be solved using the simplex technique."
  },
  {
    "objectID": "04_simplex.html#motivations",
    "href": "04_simplex.html#motivations",
    "title": "04_simplex",
    "section": "Motivations",
    "text": "Motivations\n\n\nÂ \n\nOften there is a basis to an LP that is not feasible for the primal problem, but its simplex multiplier vector is feasible for the dual.\n\nThat is ğ²âŠ¤=ğœğâŠ¤ğâˆ’1\\bm{y}^\\top = \\bm{c}_{\\bm{B}}^\\top \\bm{B}^{-1} and ğ«ğƒ=ğœğƒâŠ¤âˆ’ğ²âŠ¤ğƒâ‰¥ğŸ\\bm{r}_{\\bm{D}} = \\bm{c}_{\\bm{D}}^\\top - \\bm{y}^\\top\\bm{D} \\geq \\bm{0}.\n\nThen we can apply the dual simplex method moving from the current solution to a new BFS with a better objective value.\n\n\n\nAssume ğ\\bm{B} consists of the first mm columns of AA.\n\n\n\n\nmaximizeğ²âŠ¤ğ›subject toğ²âŠ¤ğ€â‰¤ğœâŠ¤\n\\begin{align}\n\\operatorname{maximize} & \\bm{y}^\\top \\bm{b} \\\\\n\\text{subject to} & \\bm{y}^\\top \\bm{A} \\leq \\bm{c}^\\top\n\\end{align}\n\n\n\nÂ  â‡”\n\\Leftrightarrow\n\n\n\nmaximizeğ²âŠ¤ğ›subject toğ²âŠ¤ğâ‰¤ğœğâŠ¤,ğ²âŠ¤ğƒâ‰¤ğœğƒâŠ¤.\n\\begin{align}\n\\operatorname{maximize} & \\bm{y}^\\top \\bm{b} \\\\\n\\text{subject to} & \\bm{y}^\\top \\bm{B} \\leq \\bm{c}_{\\bm{B}}^\\top, \\\\\n& \\bm{y}^\\top \\bm{D} \\leq \\bm{c}_{\\bm{D}}^\\top.\n\\end{align}\n\n\n\n\n\nDefine a new dual variable vector ğ²â€²\\bm{y}^\\prime via an affine transformation ğ²â€²âŠ¤=ğ²âŠ¤ğâˆ’ğœğâŠ¤,orğ²âŠ¤=(ğ²â€²+ğœğ)âŠ¤ğâˆ’1(14) {\\bm{y}^\\prime}^\\top  = \\bm{y}^\\top \\bm{B} - \\bm{c}_{\\bm{B}}^\\top, \\quad\n\\text{or} \\quad \\bm{y}^\\top = (\\bm{y}^\\prime + \\bm{c}_{\\bm{B}})^\\top\\bm{B}^{-1}  \\qquad(14)\n\nand substitute ğ²\\bm{y} in the dual by ğ²â€²\\bm{y}^\\prime\n\n\n\n\n\nmaximizeğ²â€²âŠ¤ğâˆ’1ğ›+ğœğâŠ¤ğâˆ’1ğ›subject toğ²â€²âŠ¤â‰¤0,ğ²â€²âŠ¤ğâˆ’1ğƒâ‰¤ğœğƒâŠ¤âˆ’ğœğâŠ¤ğâˆ’1ğƒ.\n\\begin{align}\n\\operatorname{maximize} & {\\bm{y}^\\prime}^\\top \\bm{B}^{-1}\\bm{b} +\n\\bm{c}_{\\bm{B}}^\\top \\bm{B}^{-1}\\bm{b} \\\\\n\\text{subject to} & {\\bm{y}^\\prime}^\\top \\leq 0, \\\\\n& {\\bm{y}^\\prime}^\\top\\bm{B}^{-1}\\bm{D} \\leq \\bm{c}_{\\bm{D}}^\\top -\n\\bm{c}_{\\bm{B}}^\\top \\bm{B}^{-1}\\bm{D}.\n\\end{align}\n\n\n\nÂ  Â  â‡”\n\\Leftrightarrow\n\n\n\nmaximizeğ²â€²âŠ¤ğšâ€¾0+z0subject toğ²â€²âŠ¤â‰¤ğŸ,ğ²â€²âŠ¤ğâˆ’1ğƒâ‰¤ğ«ğƒâŠ¤,(15)\n\\begin{align}\n\\operatorname{maximize} & {\\bm{y}^\\prime}^\\top \\bar{\\bm{a}}_0 + z_0 \\\\\n\\text{subject to} & {\\bm{y}^\\prime}^\\top \\leq \\bm{0}, \\\\\n& {\\bm{y}^\\prime}^\\top \\bm{B}^{-1}\\bm{D} \\leq \\bm{r}_{\\bm{D}}^\\top,\n\\end{align}\n \\qquad(15)"
  },
  {
    "objectID": "04_simplex.html#transformed-dual-variable-bmyprime",
    "href": "04_simplex.html#transformed-dual-variable-bmyprime",
    "title": "04_simplex",
    "section": "Transformed Dual â€“ Variable ğ²â€²\\bm{y}^\\prime",
    "text": "Transformed Dual â€“ Variable ğ²â€²\\bm{y}^\\prime\n\n\n\nğ²â€²=ğŸ\\bm{y}^\\prime = \\bm{0} is a BFS.\nIf ğšâ€¾0â‰¥ğŸ\\bar{\\bm{a}}_0 \\geq \\bm{0}, i.e., the primal basic solution is also feasible, then ğ²â€²âŠ¤=ğŸ{\\bm{y}^\\prime}^\\top = \\bm{0} is optimal.\nThis implies ğ²âŠ¤=ğœğâŠ¤ğâˆ’1\\bm{y}^\\top = \\bm{c}_{\\bm{B}}^\\top\\bm{B}^{-1} is optimal to the original dual.\nThe vector ğšâ€¾0\\bar{\\bm{a}}_0 can be viewed as the scaled gradient vector of the dual objective function at basis ğ\\bm{B}.\n\nIf one entry of ğšâ€¾o0&lt;0\\bar{\\bm{a}}_{o0} &lt; 0, then one can decrease the variable ğ²oâ€²\\bm{y}_o^\\prime to some âˆ’Îµ-\\varepsilon while keeping others at 00â€™s.\nThe new ğ²â€²\\bm{y}^\\prime reamins feasible, but its objective value would decrease linearly in Îµ\\varepsilon.\nThe second block of constraints in EquationÂ 15 becomes ÎµğoâŠ¤ğâˆ’1ğƒâ‰¤ğ«ğƒâŠ¤orâˆ’Îµğšâ€¾oâ‰¤ğ«ğƒâŠ¤.(16) \\varepsilon \\bm{e}_o^\\top\\bm{B}^{-1}\\bm{D} \\leq \\bm{r}_{\\bm{D}}^\\top \\quad\n\\text{or} \\quad -\\varepsilon \\bar{\\bm{a}}^o \\leq \\bm{r}_{\\bm{D}}^\\top.  \\qquad(16)\n\n\n\n\nTo keep dual feasibility, we need to choose Îµ\\varepsilon such that this vector constraint is satisfied componentwise.\n\nIf all entries in ğšâ€¾o\\bar{\\bm{a}}^o are nonnegative, then Îµ\\varepsilon may be chosen arbitrarily large so the dual objective is unbounded.\nIf some are negative we can increase Îµ\\varepsilon until one of the inequality constraints EquationÂ 16 become equal.\nSay the ethe^{\\text{th}} becomes equal. This indicates that the current nonbasic column ğše\\bm{a}_e replaces ğšo\\bm{a}_o in the new basis ğ\\bm{B}.\n\nThe determination can be done by calculating the componentwise ratios (ğ«ğƒ)j(âˆ’ğšâ€¾o)j\\frac{(\\bm{r_D})_j}{(-\\bar{\\bm{a}}^o)_j} for (ğšâ€¾o)j&lt;0(\\bar{\\bm{a}}^o)_j &lt; 0 and j=m+1,â€¦,nj = m+1, \\ldots, n (incoming col aâ€¾e\\bar{a}_e)."
  },
  {
    "objectID": "04_simplex.html#dual-simplex-method",
    "href": "04_simplex.html#dual-simplex-method",
    "title": "04_simplex",
    "section": "Dual Simplex Method",
    "text": "Dual Simplex Method\n\nIn each cycle we find a new feasible dual solution such that one of the equalities becomes inequality and one of the inequalities becomes equality.\n\nAt the same time we increase the value of the dual objective function.\n\nThe mm equalities in the new solution then determine a new basis.\n\n\n\n\nOne difference, in contrast to the primal simplex method, is that here the outgoing column is selected first and the incoming one is chosen later.\n\n\n\n\n\n\nStep 0. Given the inverse ğâˆ’1\\bm{B}^{-1} of a dual feasible basis ğ\\bm{B}, primal solution ğšâ€¾0=ğâˆ’1ğ›\\bar{\\bm{a}}_0 = \\bm{B}^{-1}\\bm{b}, dual feasible solution ğ²âŠ¤=ğœğâŠ¤ğâˆ’1\\bm{y}^\\top = \\bm{c}_{\\bm{B}}^\\top\\bm{B}^{-1}, and reduced cost vectors ğ«ğƒâŠ¤=ğœğƒâŠ¤âˆ’ğ²âŠ¤ğƒâ‰¥ğŸ\\bm{r}_{\\bm{D}}^\\top = \\bm{c}_{\\bm{D}}^\\top - \\bm{y}^\\top\\bm{D} \\geq \\bm{0}.\nStep 1. If ğšâ€¾0â‰¥ğŸ\\bar{\\bm{a}}_0 \\geq \\bm{0}, stop; the current solution pair is optimal. Otherwise, determine which column ğšo\\bm{a}_o is to leave the basis by selecting the most negative entry, the otho^{\\text{th}} entry (break ties arbitrarily), in ğšâ€¾0\\bar{\\bm{a}}_0. Now calculate ğ²â€¾âŠ¤=ğoâŠ¤ğâˆ’1\\bar{\\bm{y}}^\\top = \\bm{e}_o^\\top \\bm{B}^{-1} and then calculate ğšâ€¾o=ğ²â€¾âŠ¤ğƒ\\bar{\\bm{a}}^o = \\bar{\\bm{y}}^\\top\\bm{D}.\nStep 2. If ğšâ€¾oâ‰¥ğŸ\\bar{\\bm{a}}^o \\geq \\bm{0}, stop; the problem is unbounded. Otherwise, calculate the ratios (ğ«D)j(âˆ’ğšâ€¾o)j\\frac{(\\bm{r}_D)_j}{(-\\bar{\\bm{a}}^o)_j} for (ğšâ€¾o)j&lt;0\\bar{\\bm{a}}^o)_j &lt; 0 to determine the current nonbasic column, ğše\\bm{a}_e, ee corresponding to the minimum ratio index, to become basic.\nStep 3. Update the basis ğâˆ’1\\bm{B}^{-1} (or its factorization), and update primal solution ğšâ€¾0\\bar{\\bm{a}}_0, dual feasible solution ğ²\\bm{y}, and reduced cost vector ğ«ğƒ\\bm{r}_{\\bm{D}} accordingly. Return to Step 1."
  },
  {
    "objectID": "04_simplex.html#example-dual-simplex-procedure-illustration",
    "href": "04_simplex.html#example-dual-simplex-procedure-illustration",
    "title": "04_simplex",
    "section": "Example â€“ Dual Simplex Procedure Illustration ",
    "text": "Example â€“ Dual Simplex Procedure Illustration \n\nWe start with the initial basis ğ=[ğš2ğš3]\\bm{B} = \\begin{bmatrix} \\bm{a}_2 & \\bm{a}_3 \\end{bmatrix} and ğƒ=[ğš1ğš4]\\bm{D} = \\begin{bmatrix} \\bm{a}_1 & \\bm{a}_4 \\end{bmatrix}.\n\nStep 0. Initialization\nğ=[1âˆ’230],ğâˆ’1=[013âˆ’1216],ğšâ€¾0=[013âˆ’1216][22]=[23âˆ’23],ğ²âŠ¤=[122][013âˆ’1216]=[âˆ’1133],\n\\begin{equation}\n\\bm{B} = \\begin{bmatrix} 1 & -2 \\\\ 3 & 0 \\end{bmatrix}, \\quad \\bm{B}^{-1} =\n\\begin{bmatrix} 0 & \\frac{1}{3} \\\\ -\\frac{1}{2} & \\frac{1}{6} \\end{bmatrix},\n\\quad \\bar{\\bm{a}}_0 = \\begin{bmatrix} 0 & \\frac{1}{3} \\\\ -\\frac{1}{2} &\n\\frac{1}{6} \\end{bmatrix}\\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix}\n\\frac{2}{3} \\\\ -\\frac{2}{3} \\end{bmatrix}, \\quad \\bm{y}^\\top = \\begin{bmatrix}\n12& 2 \\end{bmatrix} \\begin{bmatrix} 0 & \\frac{1}{3} \\\\ -\\frac{1}{2} &\n\\frac{1}{6} \\end{bmatrix} = \\begin{bmatrix} -1 & \\frac{13}{3} \\end{bmatrix},\n\\end{equation}\n\nand\nğ«ğƒâŠ¤=[186]âˆ’[âˆ’1133][311âˆ’1]=[503343].\n\\bm{r}_{\\bm{D}}^\\top = \\begin{bmatrix} 18 & 6 \\end{bmatrix} - \\begin{bmatrix} -1\n& \\frac{13}{3} \\end{bmatrix}\\begin{bmatrix} 3 & 1 \\\\ 1 & -1 \\end{bmatrix} =\n\\begin{bmatrix} \\frac{50}{3} & \\frac{34}{3} \\end{bmatrix}.\n\nStep 1. We see that only the second component of ğšâ€¾0\\bar{\\bm{a}}_0 is negative so that o=2o=2 (which corr. to column ğš3\\bm{a}_3). Now, we compute\nğ²â€¾âŠ¤=ğ2âŠ¤ğâˆ’1=[01][013âˆ’1216]=[âˆ’1216],ğšâ€¾2=ğ²â€¾âŠ¤ğƒ=[âˆ’1216][311âˆ’1]=[âˆ’43âˆ’23].\n\\bar{\\bm{y}}^\\top = \\bm{e}_2^\\top \\bm{B}^{-1} = \\begin{bmatrix} 0 & 1\n\\end{bmatrix}\\begin{bmatrix} 0 & \\frac{1}{3} \\\\ -\\frac{1}{2} & \\frac{1}{6}\n\\end{bmatrix} = \\begin{bmatrix} -\\frac{1}{2} & \\frac{1}{6} \\end{bmatrix}, \\quad \n\\bar{\\bm{a}}^2 = \\bar{\\bm{y}}^\\top\\bm{D} = \\begin{bmatrix} -\\frac{1}{2} &\n\\frac{1}{6} \\end{bmatrix} \\begin{bmatrix} 3 & 1 \\\\ 1 & -1 \\end{bmatrix} = \\begin{bmatrix}\n-\\frac{4}{3} & -\\frac{2}{3} \\end{bmatrix}."
  },
  {
    "objectID": "04_simplex.html#example-dual-simplex-procedure-illustration-1",
    "href": "04_simplex.html#example-dual-simplex-procedure-illustration-1",
    "title": "04_simplex",
    "section": "Example â€“ Dual Simplex Procedure Illustration ",
    "text": "Example â€“ Dual Simplex Procedure Illustration \nStep 2. Since all components in ğšâ€¾o\\bar{\\bm{a}}^o are negative, the componentwise ratios are\nğ«ğƒ./(âˆ’ğšâ€¾2)=[503343]./[4323]=[25217]\n\\bm{r}_{\\bm{D}} ./ (-\\bar{\\bm{a}}^2) = \\begin{bmatrix} \\frac{50}{3} &\n\\frac{34}{3} \\end{bmatrix} ./ \\begin{bmatrix} \\frac{4}{3} & \\frac{2}{3}\n\\end{bmatrix} = \\begin{bmatrix} \\frac{25}{2} & 17 \\end{bmatrix}\n\nHere, we see the minimum ratio is the first component so that e=1e=1 (which corresponds to column ğš1\\bm{a}_1), that is ğšâˆ’1\\bm{a}-1 replaces ğš3\\bm{a}_3 in the current basis.\nStep 3. The new basis is ğ=[ğš2ğš1]\\bm{B} = \\begin{bmatrix} \\bm{a}_2 & \\bm{a}_1 \\end{bmatrix}.\nğ=[1331],ğâˆ’1=[âˆ’183838âˆ’18],ğšâ€¾0=[âˆ’183838âˆ’18][22]=[1212],ğ²âŠ¤=[1218][âˆ’183838âˆ’18]=[21494],\n\\begin{equation}\n\\bm{B} = \\begin{bmatrix} 1 & 3 \\\\ 3 & 1 \\end{bmatrix}, \\quad \\bm{B}^{-1} =\n\\begin{bmatrix} -\\frac{1}{8} & \\frac{3}{8} \\\\ \\frac{3}{8} & -\\frac{1}{8} \\end{bmatrix},\n\\quad \\bar{\\bm{a}}_0 = \\begin{bmatrix} -\\frac{1}{8} & \\frac{3}{8} \\\\ \\frac{3}{8} &\n-\\frac{1}{8} \\end{bmatrix}\\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix}\n\\frac{1}{2} \\\\ \\frac{1}{2} \\end{bmatrix}, \\quad \\bm{y}^\\top = \\begin{bmatrix}\n12 & 18 \\end{bmatrix} \\begin{bmatrix} -\\frac{1}{8} & \\frac{3}{8} \\\\ \\frac{3}{8} &\n-\\frac{1}{8} \\end{bmatrix} = \\begin{bmatrix} \\frac{21}{4} & \\frac{9}{4} \\end{bmatrix},\n\\end{equation}\n\nand\nğ«ğƒâŠ¤=[26]âˆ’[21494][âˆ’210âˆ’1]=[2523].\n\\bm{r}_{\\bm{D}}^\\top = \\begin{bmatrix} 2 & 6 \\end{bmatrix} - \\begin{bmatrix}\n\\frac{21}{4} & \\frac{9}{4} \\end{bmatrix}\\begin{bmatrix} -2 & 1 \\\\ 0 & -1 \\end{bmatrix} =\n\\begin{bmatrix} \\frac{25}{2} & 3 \\end{bmatrix}.\n\nStop! The solution pair is optimal!"
  },
  {
    "objectID": "04_simplex.html#the-primal-dual-algorithm",
    "href": "04_simplex.html#the-primal-dual-algorithm",
    "title": "04_simplex",
    "section": "The Primal-Dual Algorithm",
    "text": "The Primal-Dual Algorithm\n\n\n\nWe can work simultaneously on the primal and dual problems to solve LP problems.\nThe procedure begins with a feasible solution to the dual that is improved at each step by optimizing an associated restricted primal problem.\n\n\n\nAs the method progresses, it can be regarded as striving to achieve the complementary slackness conditions for optimality.\n\n\n\n\n\n\n\nminimizeğœâŠ¤ğ±subject toğ€ğ±=ğ›,ğ±â‰¥ğŸ\n\\begin{align}\n\\operatorname{minimize} & \\bm{c}^\\top\\bm{x} \\\\\n\\text{subject to} & \\bm{Ax} = \\bm{b}, \\quad \\bm{x} \\geq \\bm{0}\n\\end{align}\n\n\n\nÂ  and\n\n\nminimizeğ²âŠ¤ğ›subject toğ²âŠ¤ğ€=ğœâŠ¤.(17)\n\\begin{align}\n\\operatorname{minimize} & \\bm{y}^\\top\\bm{b} \\\\\n\\text{subject to} & \\bm{y}^\\top\\bm{A} = \\bm{c}^\\top.\n\\end{align} \n \\qquad(17)\n\n\n\n\n\n\n\n\n\nGiven a feasible solution ğ²\\bm{y}, not necessarily basic, to the dual, define the subset ğ’«\\mathcal{P} of indices {1,2,â€¦,n}\\{1, 2, \\ldots, n\\} by jâˆˆğ’«j \\in \\mathcal{P} if ğ²âŠ¤ğšj=cj\\bm{y}^\\top \\bm{a}_j = c_j.\n\nSince ğ²\\bm{y} is dual feasible, we have âˆ€jâˆ‰ğ’«,ğ²âŠ¤ğšj&lt;cj\\forall j \\notin \\mathcal{P}, \\;\\; \\bm{y}^\\top \\bm{a}_j &lt; c_j.\n\nCorresponding to ğ²\\bm{y} and the index set ğ’«\\mathcal{P}, we define the associated restricted primal problem\n\nminimizeğŸâŠ¤ğ®,ğŸâŠ¤=[11â‹¯1]subject toğ€ğ±+ğ®=ğ›ğ±â‰¥ğŸxj=0forjâˆ‰ğ’«ğ®â‰¥ğŸ(18)\n\\begin{align}\n\\operatorname{minimize} & \\bm{1}^\\top \\bm{u}, & \\bm{1}^\\top = \\begin{bmatrix} 1 &\n1 & \\cdots & 1 \\end{bmatrix} \\\\\n\\text{subject to} & \\bm{Ax} + \\bm{u} = \\bm{b}  & \\\\\n& \\bm{x} \\geq \\bm{0} & x_j = 0 \\quad \\text{for} \\quad j \\notin \\mathcal{P} \\\\\n& \\bm{u} \\geq \\bm{0} & \n\\end{align}\n \\qquad(18)"
  },
  {
    "objectID": "04_simplex.html#the-primal-dual-algorithm-1",
    "href": "04_simplex.html#the-primal-dual-algorithm-1",
    "title": "04_simplex",
    "section": "The Primal-Dual Algorithm",
    "text": "The Primal-Dual Algorithm\n\nThe dual of this associated restricted primal is called the associated restricted dual with dual variable vector ğ²â€²\\bm{y}^\\prime.\n\nmaximize(ğ²â€²)âŠ¤ğ›subject to(ğ²â€²)âŠ¤ğšjâ‰¤0jâˆˆğ’«(ğ²â€²)â‰¤ğŸ.(19)\n\\begin{align}\n\\operatorname{maximize} & (\\bm{y}^\\prime)^\\top \\bm{b}  & \\\\\n\\text{subject to} & (\\bm{y}^\\prime)^\\top \\bm{a}_j \\leq 0 & j \\in \\mathcal{P} \\\\\n& (\\bm{y}^\\prime) \\leq \\bm{1}.\n\\end{align}\n \\qquad(19)\n\n\n\nPrimal-Dual Optimality Theorem\n\n\nSuppose that ğ²\\bm{y} is feasible for the original dual and that ğ±\\bm{x} and ğ®=ğŸ\\bm{u} = \\bm{0} is feasible (and of course optimal) for the associated restricted primal. Then ğ±\\bm{x} and ğ²\\bm{y} are optimal for the original prime and dual programs, respectively.\n\n\n\n\n\n\nProof\n\n\nClearly ğ±\\bm{x} is feasible for the primal. Also, we have ğœâŠ¤ğ±=ğ²âŠ¤ğ€ğ±\\bm{c}^\\top\\bm{x} = \\bm{y}^\\top\\bm{Ax} because ğ²âŠ¤ğ€\\bm{y}^\\top\\bm{A} is identical to ğœâŠ¤\\bm{c}^\\top on the components corresponding to the nonzero elements of ğ±\\bm{x}. Thus ğœâŠ¤ğ±=ğ²âŠ¤ğ€ğ±=ğ²âŠ¤ğ›\\bm{c}^\\top\\bm{x} = \\bm{y}^\\top\\bm{Ax} = \\bm{y}^\\top\\bm{b} and optimality follows from strong duality or complementary slackness."
  },
  {
    "objectID": "04_simplex.html#the-primal-dual-algorithm-2",
    "href": "04_simplex.html#the-primal-dual-algorithm-2",
    "title": "04_simplex",
    "section": "The Primal-Dual Algorithm",
    "text": "The Primal-Dual Algorithm\nStep 1. Given a feasible solution ğ²0\\bm{y}^0 to the dual program EquationÂ 17, determine the associated restricted primal according to EquationÂ 18.\nStep 2. Optimize the associated restricted primal. If the minimal value of this problem is zero, the corresponding solution and ğ²0\\bm{y}^0 is an optimal pair for the original LP EquationÂ 17.\nStep 3. If the minimal value of the associated restricted primal is strictly positive, the maximal objective value of the associated restricted dual EquationÂ 19 is also positive from the strong duality theorem, that is, its optimal solution ğ²â€²âŠ¤ğ›&gt;0{\\bm{y}^\\prime}^\\top \\bm{b} &gt; 0. If there is no jj for which ğ²â€²âŠ¤ğšj&gt;0{\\bm{y}^\\prime}^\\top \\bm{a}_j &gt; 0 for all jâˆ‰ğ’«j \\notin \\mathcal{P}, conclude the primal has no feasible solutions from Farkasâ€™s lemma.\nStep 4. If, on the other hand, for at least one jâˆ‰ğ’«j \\notin \\mathcal{P}, ğ²â€²âŠ¤ğšj&gt;0{\\bm{y}^\\prime}^\\top \\bm{a}_j &gt; 0, define the new dual feasible vector ğ²(Îµ)=ğ²0+Îµğ²â€²,\n\\bm{y}(\\varepsilon) = \\bm{y}^0 + \\varepsilon \\bm{y}^\\prime,  where Îµ\\varepsilon is referred to as the stepsize, is chosen as large as possible till one of the constraints, jâˆ‰ğ’«j \\notin \\mathcal{P} becomes equal ğ²(Îµ)âŠ¤ğšj=cj,jâˆ‰ğ’«. \\bm{y}(\\varepsilon)^\\top \\bm{a}_j = c_j, \\quad j \\notin \\mathcal{P}. \nIf Îµ\\varepsilon can be increased to âˆ\\infty, then the original dual is unbounded. Otherwise Îµ&gt;0\\varepsilon &gt; 0 and we go back to Step 1 using this new dual feasible solution ğ²(Îµ)\\bm{y}(\\varepsilon) whose dual objective is strictly increased. ğ²(Îµ)âŠ¤ğ›=(ğ²0)âŠ¤ğ›+Îµğ²â€²âŠ¤ğ›&gt;(ğ²0)âŠ¤ğ›. \\bm{y}(\\varepsilon)^\\top \\bm{b} = (\\bm{y}^0)^\\top \\bm{b} + \\varepsilon\n{\\bm{y}^\\prime}^\\top \\bm{b} &gt; (\\bm{y}^0)^\\top \\bm{b}. \n\n\nOptimization Theory and Practice â€¢ Aykut C. Satici"
  }
]