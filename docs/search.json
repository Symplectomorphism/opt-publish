[
  {
    "objectID": "07_basic_descent.html#optimization-theory-and-practice",
    "href": "07_basic_descent.html#optimization-theory-and-practice",
    "title": "07_basic_descent",
    "section": "Optimization Theory and Practice",
    "text": "Optimization Theory and Practice\n\n\nBasic Descent Methods\n\n\n\n\nInstructor: Aykut Satici, Ph.D.¬†  Mechanical and Biomedical Engineering  Electrical and Computer Engineering  Boise State University, Boise, ID, USA\n\n\nTopics:  Line Search Algorithms  The Method of Steepest Descent  Newton‚Äôs Method: Second-Order   Coordinate and Stochastic Gradient Descent"
  },
  {
    "objectID": "07_basic_descent.html#th-order-method-golden-search",
    "href": "07_basic_descent.html#th-order-method-golden-search",
    "title": "07_basic_descent",
    "section": "00th-Order Method: Golden Search",
    "text": "00th-Order Method: Golden Search\n\n\n\n\n\nIf we evaluate ff at only one intermediate point of the interval, we cannot narrow the range within which we know the minimizer is located.\n\n\n\n\n\n\n\n\n\nWe have to evaluate ff at two intermediate points.\n\nWe choose the intermediate points in such a way that the reduction in the range is symmetric, i.e., a1‚àía0=b0‚àíb1=œÅ(b0‚àía0),œÅ&lt;12. a_1 - a_0 = b_0 - b_1 = \\rho(b_0 - a_0), \\qquad \\rho &lt; \\frac{1}{2}. \nWe then evaluate ff at the intermediate points.\n\nIf f(a1)&lt;f(b1)f(a_1) &lt; f(b_1) then the minimizer must lie in the range [a0,b1][a_0, b_1].\nIf, on the other hand f(a1)‚â•f(b1)f(a_1) \\geq f(b_1), then the minimizer is located at [a1,b0][a_1, b_0].\n\n\n\n\n\n\n\n\n\n\n\n\n\nStarting with the reduced range of uncertainty, we can repeat the process to find two new points: a2a_2 and b2b_2.\nBut this is unnecessary: we know x*‚àà[a0,b1]x^\\ast \\in [a_0, b_1]\n\nSince a1‚àà[a0,b1]a_1 \\in [a_0, b_1], we can set a1=b2a_1 = b_2.\nOnly one function evaluation of ff at a2a_2 is necessary.\n\nHow do we find the value of œÅ\\rho that results only in one new evaluation of ff?"
  },
  {
    "objectID": "07_basic_descent.html#th-order-method-golden-search-1",
    "href": "07_basic_descent.html#th-order-method-golden-search-1",
    "title": "07_basic_descent",
    "section": "00th-Order Method: Golden Search",
    "text": "00th-Order Method: Golden Search\n\n\n\n\n\n\n\n\nFinding œÅ\\rho\n\n\nWe choose œÅ\\rho so that: 2345œÅ(b1‚àía0)=b1‚àíb2=1‚àí2œÅ\\phantom{2345} \\rho (b_1 - a_0) = b_1 - b_2 = 1-2\\rho.\nThis has the two solutions: 123œÅ1,2=12(3¬±5)\\phantom{123} \\rho_{1,2} = \\frac{1}{2}(3 \\pm \\sqrt{5}).\n\nSince we require that œÅ&lt;12\\rho &lt; \\frac{1}{2}, we must take œÅ=3‚àí52‚âà0.382.\\rho =\n\\frac{3-\\sqrt{5}}{2} \\approx 0.382. \nObserve that 1‚àíœÅ=5‚àí12‚âà0.618031-\\rho = \\frac{\\sqrt{5}-1}{2} \\approx 0.61803 and œÅ1‚àíœÅ=1‚àíœÅ1\\frac{\\rho}{1-\\rho} = \\frac{1-\\rho}{1}.\n\nDividing a range in the ratio of œÅ\\rho to 1‚àíœÅ1-\\rho has the effect that ratio of the shorter segment to the longer equals the ratio of the longer to the sum of the two.\nThis rule is referred to as the golden section.\n\nThe uncertainty range reduction is 1‚àíœÅ1-\\rho at each stage.\n\nNN steps of the method reduces the range by factor (1‚àíœÅ)N(1-\\rho)^N.\n\n\n\n\n\n\n\n\n\nExample: locate xx to within the range 310\\frac{3}{10}\n\n\nf(x)=x4‚àí14x3+60x2‚àí70x,x‚àà[0,2]. f(x) = x^4 - 14x^3 + 60x^2 - 70x, \\quad x \\in [0, 2]. \n\n(1‚àíœÅ)N‚â§12310‚áíN&gt;3.94(1-\\rho)^N \\leq \\frac{1}{2}\\frac{3}{10} \\; \\Rightarrow \\; N &gt; 3.94 so N=4N=4.\n\nIteration 1. Evaluate ff at two intermediate points. We have a1=a0+œÅ(b0‚àía0)=0.7639,f(a1)=‚àí24.36,b1=a0+(1‚àíœÅ)(b0‚àía0)=1.236f(b1)=‚àí18.96. \n\\begin{align}\na_1 &= a_0 + \\rho(b_0 - a_0) = 0.7639, & f(a_1) = -24.36, \\\\ \nb_1 &= a_0 + (1-\\rho)(b_0 - a_0) = 1.236 & f(b_1) = -18.96. \n\\end{align}\n Since f(a1)&lt;f(b1)f(a_1) &lt; f(b_1), the uncertainty interval is reduced to [a0,b1]=[0,1.236]. [a_0, b_1] = [0, 1.236]. \nIteration 2. We choose b2=a1b_2 = a_1 and so the new point is a2=a0+œÅ(b1‚àía0)=0.4721,f(a2)=‚àí21.10,b2=a1=0.7639,f(b2)=‚àí24.36.\n\\begin{align}\na_2 &= a_0 + \\rho(b_1 - a_0) = 0.4721, & f(a_2) = -21.10, \\\\\nb_2 &= a_1 = 0.7639, & f(b_2) = -24.36.\n\\end{align}\n Since f(a2)&gt;f(b2)f(a_2) &gt; f(b_2) the uncertainty interval is [a2,b1]=[0.4721,1.236]. [a_2, b_1] = [0.4721, 1.236]. \nIteration 3. We choose a3=b2a_3 = b_2 and continue ‚Ä¶\nIteration 4. Final iteration results in [a4,b3]=[0.6525,0.9443]. [a_4, b_3] = [0.6525, 0.9443]."
  },
  {
    "objectID": "07_basic_descent.html#st-order-method-bisection-method",
    "href": "07_basic_descent.html#st-order-method-bisection-method",
    "title": "07_basic_descent",
    "section": "11st-Order Method: Bisection Method",
    "text": "11st-Order Method: Bisection Method\n\n\n\nAssumptions: ff is unimodal and continuously differentiable.\n\n\n\n\n\n\n\n\nAlgorithm\n\n\n\nLet x0=12(a0+b0)x_0 = \\frac{1}{2}(a_0 + b_0), the midpoint of the initial uncertainty interval.\nEvaluate f‚Ä≤(x0)f'(x_0).\n\nIf f‚Ä≤(x0)&gt;0f'(x_0) &gt; 0, deduce that the minimizer lies to the left of x0x_0.\n\nReduce the uncertainty interval to [a0,x0][a_0, x_0].\n\nIf f‚Ä≤(x0)&lt;0f'(x_0) &lt; 0, deduce that the minimizer lies to the right of x0x_0.\n\nReduce the uncertainty interval to [x0,b0][x_0, b_0].\n\nIf f‚Ä≤(x0)=0f'(x_0) = 0, declare x0x_0 the minimizer and terminate the search.\n\nWith the new uncertainty interval computed, repeat the process iteratively.\n\nCompute the midpoint xkx_k and check the sign of f‚Ä≤(xk)f'(x_k) and reduce the uncertainty to the left or right of xkx_k.\nDeclare xkx_k the minimizer if f‚Ä≤(xk)=0f'(x_k) = 0.\n\n\n\n\n\n\n\n\n\nSalient features\n\n\n\nInstead of using the values of ff, the bisection method uses the values of f‚Ä≤f'.\nAt each iteration, the length of the uncertaintly interval is reduced by a factor of 12\\frac{1}{2}.\n\nAfter NN steps, the range is reduced by a factor of (12)N(\\frac{1}{2})^N.\nThis factor is smaller than in the golden search or Fibonacci methods.\n\n\n\n\n\n\n\n\nExample\n\n\nf(x)=x4‚àí14x3+60x2‚àí70x,x‚àà[0,2]. f(x) = x^4 - 14x^3 + 60x^2 - 70x, \\quad x \\in [0, 2]. \n\nIf we want a precision of 0.30.3, then we need N&gt;1‚àílog2(310)N &gt; 1 - \\operatorname{log}_2(\\frac{3}{10}) iterations, i.e., N=3N = 3."
  },
  {
    "objectID": "07_basic_descent.html#nd-order-method-newtons-method",
    "href": "07_basic_descent.html#nd-order-method-newtons-method",
    "title": "07_basic_descent",
    "section": "22nd-Order Method: Newton‚Äôs Method",
    "text": "22nd-Order Method: Newton‚Äôs Method\n\n\n\n\n\n\nConstruct a quadratic function qq which at xkx_k agrees with ff up to second derivatives, that is\n\nq(x)=f(xk)+f‚Ä≤(xk)(x‚àíxk)+12f‚Ä≥(xk)(x‚àíxk)2. q(x) = f(x_k) + f'(x_k)(x-x_k) + \\frac{1}{2}f''(x_k)(x-x_k)^2. \n\nCalculate an estimate xk+1x_{k+1} of the minimum point of ff by finding the point where the derivative of qq vanishes.\n\n0=q‚Ä≤(xk+1)=f‚Ä≤(xk)+f‚Ä≥(xk)(xk+1‚àíxk)‚áíxk+1=xk‚àíf‚Ä≤(xk)f‚Ä≥(xk).(1) \n\\begin{align}\n0 &= q'(x_{k+1}) = f'(x_k) + f''(x_k)(x_{k+1}-x_k) \\\\ \n&\\Rightarrow x_{k+1} = x_k - \\frac{f'(x_k)}{f''(x_k)}. \n\\end{align}\n \\qquad(1)\n\n\n\n\nxk+1x_{k+1} resulting from Newton‚Äôs method does not depend on the value f(xk)f(x_k).\n\n\n\n\n\n\n\n\n\nNewton‚Äôs method may be viewed as a technique for iteratively solving equations of the form\n\ng(x)=0, g(x) = 0, \nwhere, when applied to minimization, we put g(x)=f‚Ä≤(x)g(x) = f'(x).\n\n\n\n\n\n\n\n\n\nProposition\n\n\nLet x*x^\\ast satisfy g(x*)=0g(x^\\ast) = 0, g‚Ä≤(x*)‚â†0g'(x^\\ast) \\neq 0. Then, provided x0x_0 is sufficiently close to x*x^\\ast, the sequence {xk}k=0‚àû\\{x_k\\}_{k=0}^\\infty generated by Newton‚Äôs method Equation¬†1 converges to x*x^\\ast with an order of convergence at least two."
  },
  {
    "objectID": "07_basic_descent.html#example-newtons-method",
    "href": "07_basic_descent.html#example-newtons-method",
    "title": "07_basic_descent",
    "section": "Example ‚Äì Newton‚Äôs Method",
    "text": "Example ‚Äì Newton‚Äôs Method\n\n\n\nWe want to find the minimizer of\n\nf(x)=12x2‚àísinx,x0=12. f(x) = \\frac{1}{2}x^2 - \\sin{x}, \\quad x_0 = \\frac{1}{2}. \n\nWe want an accuracy of Œµ=10‚àí5\\varepsilon = 10^{-5}, i.e., stop when\n\n|xk+1‚àíxk|&lt;Œµ. |x_{k+1} - x_k | &lt; \\varepsilon. \n\nWe compute\n\nf‚Ä≤(x)=x‚àícosx,f‚Ä≥(x)=1+sinx. f'(x) = x - \\cos{x}, \\quad f''(x) = 1 + \\sin{x}. \n\n  x1=12‚àí12‚àícos121+sin12=0.7552,x2=x1‚àíf‚Ä≤(x1)f‚Ä≥(x1)=x1‚àí0.027101.685=0.7391,x3=x2‚àíf‚Ä≤(x2)f‚Ä≥(x2)=x2‚àí9.461√ó10‚àí51.673=0.7390,x4=x3‚àíf‚Ä≤(x3)f‚Ä≥(x3)=x3‚àí1.17√ó10‚àí91.673=0.7390.\n\\begin{align}\nx_1 &= \\frac{1}{2} - \\frac{\\frac{1}{2} - \\cos{\\frac{1}{2}}}{1 +\n\\sin{\\frac{1}{2}}} = 0.7552, \\\\\nx_2 &= x_1 - \\frac{f'(x_1)}{f''(x_1)} = x_1 - \\frac{0.02710}{1.685} = 0.7391, \\\\\nx_3 &= x_2 - \\frac{f'(x_2)}{f''(x_2)} = x_2 - \\frac{9.461 \\times 10^{-5}}{1.673}\n= 0.7390, \\\\\nx_4 &= x_3 - \\frac{f'(x_3)}{f''(x_3)} = x_3 - \\frac{1.17 \\times 10^{-9}}{1.673}\n= 0.7390.\n\\end{align}"
  },
  {
    "objectID": "07_basic_descent.html#inaccurate-line-search",
    "href": "07_basic_descent.html#inaccurate-line-search",
    "title": "07_basic_descent",
    "section": "Inaccurate Line Search",
    "text": "Inaccurate Line Search\n\n\n\n\nIn practice, we do not bend over backwards to find the exact minimum when performing line search.\n\nIt is often desirable to sacrifice accuracy in the line search routine in order to conserve overall computation time.\nMost functions to not attain their minimum along the line we‚Äôre searching at a particular iteration anyway!\n\nInaccuracy is introduced in a line search algorithm by simply terminating the search before it has converged.\n\n\n\n\n\n\n\n\n\nArmijo‚Äôs Rule\n\n\n\nA practical and popular criterion for terminating a line search is Armijo‚Äôs rule.\nThe idea is that the rule should first guarantee that the selected Œ±\\alpha is not too large, and next it should not be too small. œï(Œ±)=f(ùê±k+Œ±ùêùk). \\phi(\\alpha) = f(\\bm{x}_k + \\alpha \\bm{d}_k). \nConsider the function œï(0)+Œµœï‚Ä≤(0)Œ±\\phi(0) + \\varepsilon \\phi'(0)\\alpha, for fixed Œµ\\varepsilon, 0&lt;Œµ&lt;10 &lt; \\varepsilon &lt; 1.\nA value of Œ±\\alpha is consered to be not too large if the corresponding function value lies below the dashed line; that is, if œï(Œ±)‚â§œï(0)+Œµœï‚Ä≤(0)Œ±.(2) \\phi(\\alpha) \\leq \\phi(0) + \\varepsilon \\phi'(0)\\alpha.  \\qquad(2)\nTo ensure that Œ±\\alpha is not too small, a value Œ∑&gt;1\\eta &gt; 1 is selected, and Œ±\\alpha is then considered to be not too small if œï(Œ∑Œ±)&gt;œï(0)+Œµœï‚Ä≤(0)Œ∑Œ±. \\phi(\\eta \\alpha) &gt; \\phi(0) + \\varepsilon \\phi'(0)\\eta \\alpha. \nThis means that if Œ±\\alpha is increased by a factor Œ±\\alpha, it will fail to meet the test Equation¬†2.\n\n\n\n\n\n\n\n\n\n\n\nThe acceptable region defined by the Armijo rule when Œ∑=2\\eta = 2."
  },
  {
    "objectID": "07_basic_descent.html#the-method-and-convergence",
    "href": "07_basic_descent.html#the-method-and-convergence",
    "title": "07_basic_descent",
    "section": "The Method and Convergence",
    "text": "The Method and Convergence\n\n\n\n\n\n\nThe gradient ‚àáf(ùê±)\\nabla f(\\bm{x}) is defined as a nn-dim. row vector.\nWe define the nn-dim. column vector g(ùê±)=‚àáf(ùê±)‚ä§g(\\bm{x}) = \\nabla f(\\bm{x})^\\top.\n\n\n\n\n\n\n\nThe Method of Steepest Descent (SDM)\n\n\nThe iterative algorithm is\nùê±k+1=ùê±k‚àíŒ±kùê†k, \\bm{x}_{k+1} = \\bm{x}_k - \\alpha_k \\bm{g}_k, \nwhere the stepsize Œ±k\\alpha_k is a nonnegative scalar possible minimizing f(ùê±k‚àíŒ±ùê†k)f(\\bm{x}_k - \\alpha \\bm{g}_k).\n\n\n\n\n\n\nThe Algorithm\n\n\nDefine the mapping 1ùêí:‚Ñù2n‚Üí‚Ñùn\\phantom{1} \\bm{S}: \\mathbb{R}^{2n} \\rightarrow \\mathbb{R}^n by ùêí(ùê±,ùêù)={ùê≤:ùê≤=ùê±+Œ±ùêù,Œ±‚â•0,f(ùê≤)=min0‚â§Œ±&lt;‚àûf(ùê±+Œ±ùêù)}. \\bm{S}(\\bm{x}, \\bm{d}) = \\{\\bm{y}: \\bm{y} = \\bm{x} + \\alpha\n\\bm{d}, \\;\\; \\alpha \\geq 0, \\; f(\\bm{y}) =\n\\operatorname{min}_{0 \\leq \\alpha &lt; \\infty} f(\\bm{x} + \\alpha \\bm{d}) \\}. \nThis is a closed map if ùêù‚â†ùüé\\bm{d} \\neq \\bm{0}.\nThe overall algorithm is ùêÄ:‚Ñùn‚Üí‚Ñùn\\; \\bm{A}: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n which gives ùê±k+1‚ààùêÄ(ùê±k)\\bm{x}_{k+1} \\in \\bm{A}(\\bm{x}_k) can be decomposed in the form\nùêÄ=ùêíùêÜ,ùêÜ(ùê±)=(ùê±,‚àíùê†(ùê±)). \\bm{A} = \\bm{SG}, \\quad \\bm{G}(\\bm{x}) = (\\bm{x}, -\\bm{g}(\\bm{x})). \n\n\n\n\n\n\n\nGlobal Convergence\n\n\n\nDefine the solution set Œì={ùê±‚àà‚Ñùn:‚àáf(ùê±)=ùüé}\\Gamma = \\{\\bm{x} \\in \\mathbb{R}^n: \\nabla f(\\bm{x}) = \\bm{0}\\}.\nZ(ùê±)=f(ùê±)Z(\\bm{x}) = f(\\bm{x}) is a descent function for ùêÄ\\bm{A}, since for ‚àáf(ùê±)‚â†ùüé\\nabla f(\\bm{x}) \\neq \\bm{0} min0‚â§Œ±&lt;‚àûf(ùê±‚àíŒ±ùê†(ùê±))&lt;f(ùê±). \\operatorname{min}_{0 \\leq \\alpha &lt; \\infty} f(\\bm{x} - \\alpha \\bm{g}(\\bm{x}))\n&lt; f(\\bm{x}). \nThus by the Global Convergence Theorem, if the sequence {ùê±k}\\{\\bm{x}_k\\} is bounded, it will have limit points and each of these is a solution.\n\n\n\n\n\n\n\nDefinition (First-order Œ≤\\beta-Lipschitz Function)\n\n\nFor any two points ùê±\\bm{x} and ùê≤\\bm{y}, |‚àáf(ùê≤)‚àí‚àáf(ùê±)|‚â§Œ≤|ùê≤‚àíùê±||\\nabla f(\\bm{y}) - \\nabla f(\\bm{x})| \\leq \\beta |\\bm{y} - \\bm{x}|, for a positive real number Œ≤\\beta.\n\n\n\n\n\n\nConvergence Speed for fixed stepsize Œ±k=1Œ≤\\alpha_k = \\frac{1}{\\beta} is arithmetic.\n\n\nWe may not know 1Œ≤\\frac{1}{\\beta} so we employ a backtracking line search: start with a guess of Œ≤\\beta; if sufficient obj. reduction is achieved, halve Œ≤\\beta; otherwise double Œ≤\\beta. Stop when the process is reversed."
  },
  {
    "objectID": "07_basic_descent.html#steepest-descent-analysis",
    "href": "07_basic_descent.html#steepest-descent-analysis",
    "title": "07_basic_descent",
    "section": "Steepest Descent Analysis",
    "text": "Steepest Descent Analysis\n\n\n\n\n\nLemma. Let f(ùê±)f(\\bm{x}) be differentiable everywhere and satisfy the (first-order) Œ≤\\beta-Lipschitz condition. Then, for any two points ùê±\\bm{x} and ùê≤\\bm{y} f(ùê≤)‚àíf(ùê±)‚àí‚àáf(ùê±)(ùê≤‚àíùê±)‚â§Œ≤2|ùê≤‚àíùê±|2. f(\\bm{y}) - f(\\bm{x}) - \\nabla f(\\bm{x})(\\bm{y} - \\bm{x}) \\leq\n\\frac{\\beta}{2}|\\bm{y} - \\bm{x}|^2. \n\n\n\n\n\n\nSteepest Descent ‚Äî Lipschitz Convex Case.\n\n\nLet f(ùê±)f(\\bm{x}) be convex and differentiable everywhere, satisfy the (first-order) Œ≤\\beta-Lipschitz condition, and admit a minimizer ùê±*\\bm{x}^\\ast. Then, the method of steepest descent ùê±k+1=ùê±k‚àí1Œ≤ùê†k=ùê±k‚àí1Œ≤‚àáf(ùê±k)‚ä§ \\bm{x}_{k+1} = \\bm{x}_k - \\frac{1}{\\beta}\\bm{g}_k = \\bm{x}_k -\n\\frac{1}{\\beta}\\nabla f(\\bm{x}_k)^\\top  generates a sequence of solutions ùê±k\\bm{x}_k such that |‚àáf(ùê±k)|‚â§Œ≤k(k+1)|ùê±0‚àíùê±*|, |\\nabla f(\\bm{x}_k)| \\leq \\frac{\\beta}{\\sqrt{k(k+1)}}|\\bm{x}_0 -\n\\bm{x}^\\ast|,  and f(ùê±k)‚àíf*‚â§Œ≤2(k+1)|ùê±0‚àíùê±*|2. f(\\bm{x}_k) - f^\\ast \\leq \\frac{\\beta}{2(k+1)}|\\bm{x}_0 - \\bm{x}^\\ast|^2. \n\n\n\n\n\n\nProof\n\n\nConsider the function gùê±(ùê≤)=f(ùê≤)‚àí‚àáf(ùê±)ùê≤g_\\bm{x}(\\bm{y}) = f(\\bm{y}) - \\nabla f(\\bm{x})\\bm{y} for any given ùê±\\bm{x}.\n\n\n\n\n\n\n\nNote that gùê±g_\\bm{x} is convex and satisfies the Œ≤\\beta-Lipschitz condition. Moreover ùê±\\bm{x} is the minimizer of gùê±(ùê≤)g_\\bm{x}(\\bm{y}) and ‚àágùê±(ùê≤)=‚àáf(ùê≤)‚àí‚àáf(ùê±)\\nabla g_\\bm{x}(\\bm{y}) = \\nabla f(\\bm{y}) - \\nabla f(\\bm{x}).\nApplying the Lemma to gùê±g_\\bm{x} and noting the relations of gùê±g_\\bm{x} and f(ùê±)f(\\bm{x}), we have\nf(ùê±)‚àíf(ùê≤)‚àí‚àáf(ùê±)(ùê±‚àíùê≤)=gùê±(ùê±)‚àígùê±(ùê≤)123‚â§gùê±(ùê≤‚àí1Œ≤‚àágùê±(ùê≤)‚ä§)‚àígùê±(ùê≤)123‚â§‚àágùê±(ùê≤)(‚àí1Œ≤‚àágùê±(ùê≤)‚ä§)+Œ≤21Œ≤2|‚àágùê±(ùê≤)|2123=‚àí12Œ≤|‚àágùê±(ùê≤)|2=‚àí12Œ≤|‚àáf(ùê±)‚àí‚àáf(ùê≤)|2.(3)\n\\begin{align}\n&f(\\bm{x}) - f(\\bm{y}) - \\nabla f(\\bm{x})(\\bm{x} - \\bm{y}) = g_\\bm{x}(\\bm{x}) -\ng_\\bm{x}(\\bm{y}) \\\\\n&\\phantom{123} \\leq g_\\bm{x}(\\bm{y} - \\frac{1}{\\beta}\\nabla\ng_\\bm{x}(\\bm{y})^\\top) -\ng_\\bm{x}(\\bm{y}) \\\\\n&\\phantom{123}\\leq \\nabla g_{\\bm{x}}(\\bm{y})(-\\frac{1}{\\beta}\\nabla g_\\bm{x}(\\bm{y})^\\top) +\n\\frac{\\beta}{2}\\frac{1}{\\beta^2}|\\nabla g_\\bm{x}(\\bm{y})|^2 \\\\\n&\\phantom{123} = -\\frac{1}{2\\beta}|\\nabla g_{\\bm{x}}(\\bm{y})|^2 = -\\frac{1}{2\\beta}|\\nabla\nf(\\bm{x}) - \\nabla f(\\bm{y})|^2.\n\\end{align}\n \\qquad(3)\nSimilarly, we have\nf(ùê≤)‚àíf(ùê±)‚àí‚àáf(ùê≤)(ùê≤‚àíùê±)‚â§‚àí12Œ≤|‚àáf(ùê±)‚àí‚àáf(ùê≤)|2. f(\\bm{y}) - f(\\bm{x}) - \\nabla f(\\bm{y})(\\bm{y} - \\bm{x}) \\leq\n-\\frac{1}{2\\beta}|\\nabla f(\\bm{x}) - \\nabla f(\\bm{y})|^2. \nAdding the above two derived inequalities, we have for any ùê±\\bm{x} and ùê≤\\bm{y}\n(‚àáf(ùê±)‚àí‚àáf(ùê≤))(ùê±‚àíùê≤)‚â•1Œ≤|‚àáf(ùê±)‚àí‚àáf(ùê≤)|2.(4)\n(\\nabla f(\\bm{x}) - \\nabla f(\\bm{y}))(\\bm{x} - \\bm{y}) \\geq\n\\frac{1}{\\beta}|\\nabla f(\\bm{x}) - \\nabla f(\\bm{y})|^2.\n \\qquad(4)\nFor simplicity, let ùêùk=ùê±k‚àíùê±*\\bm{d}_k = \\bm{x}_k - \\bm{x}^\\ast and Œ¥k=f(ùê±k)‚àíf(ùê±*)‚â•0\\delta_k = f(\\bm{x}_k) - f(\\bm{x}^\\ast) \\geq 0."
  },
  {
    "objectID": "07_basic_descent.html#steepest-descent-analysis-1",
    "href": "07_basic_descent.html#steepest-descent-analysis-1",
    "title": "07_basic_descent",
    "section": "Steepest Descent Analysis",
    "text": "Steepest Descent Analysis\n\n\n\n\n\nProof ‚Äì Continued ‚Äì\n\n\nNow let ùê±=ùê±k+1\\bm{x} = \\bm{x}_{k+1} and ùê≤=ùê±k\\bm{y} = \\bm{x}_k in Equation¬†4. Then\n ‚àí1Œ≤ùê†k‚ä§(ùê†k+1‚àíùê†k)=(ùê±k+1‚àíùê±k)‚ä§(ùê†k+1‚àíùê†k)‚â•1Œ≤|ùê†k+1‚àíùê†k|2, -\\frac{1}{\\beta} \\bm{g}_k^\\top (\\bm{g}_{k+1} - \\bm{g}_k) = (\\bm{x}_{k+1} -\n\\bm{x}_k)^\\top (\\bm{g}_{k+1} - \\bm{g}_k) \\geq \\frac{1}{\\beta}|\\bm{g}_{k+1} -\n\\bm{g}_k|^2,  \nwhich leads to\n|ùê†k+1|2‚â§ùê†k+1‚ä§ùê†k‚â§|ùê†k+1||ùê†k|,i.e.,|ùê†k+1|‚â§|ùê†k|.(5)\n|\\bm{g}_{k+1}|^2 \\leq \\bm{g}_{k+1}^\\top \\bm{g}_k \\leq |\\bm{g}_{k+1}||\\bm{g}_k|,\n\\;\\; \\text{i.e.,} \\;\\; |\\bm{g}_{k+1}| \\leq |\\bm{g}_k|.\n \\qquad(5)\nThis inequality implies that |ùê†k|=|‚àáf(ùê±k)||\\bm{g}_k| = |\\nabla f(\\bm{x}_k)| is monotonically decreasing.\nApplying inequality Equation¬†3 for ùê±=ùê±k\\bm{x} = \\bm{x}_k and ùê≤=ùê±*\\bm{y} = \\bm{x}^\\ast and noting ùê†*=ùüé\\bm{g}^\\ast = \\bm{0} we have\nŒ¥k‚â§ùê†k‚ä§ùêùk‚àí12Œ≤|ùê†k|2=‚àíŒ≤(ùê±k+1‚àíùê±k)ùêùk‚àíŒ≤2|ùê±k+1‚àíùê±k|2=‚àíŒ≤2(|ùê±k+1‚àíùê±k|2+2(ùê±k+1‚àíùê±k)‚ä§ùêùk)=‚àíŒ≤2(|ùêùk+1‚àíùêùk|2+2(ùêùk+1‚àíùêùk)‚ä§ùêùk)=Œ≤2(|ùêùk|2‚àí|ùêùk+1|2).(6)\n\\begin{align}\n\\delta_k &\\leq \\bm{g}_k^\\top \\bm{d}_k - \\frac{1}{2\\beta}|\\bm{g}_k|^2 \\\\\n&= -\\beta(\\bm{x}_{k+1} - \\bm{x}_k)\\bm{d}_k - \\frac{\\beta}{2}|\\bm{x}_{k+1} -\n\\bm{x}_k|^2 \\\\\n&= -\\frac{\\beta}{2}(|\\bm{x}_{k+1} - \\bm{x}_k|^2 + 2(\\bm{x}_{k+1} -\n\\bm{x}_k)^\\top \\bm{d}_k) \\\\\n&= -\\frac{\\beta}{2}(|\\bm{d}_{k+1} - \\bm{d}_k|^2 + 2(\\bm{d}_{k+1} - \\bm{d}_k)^\\top\n\\bm{d}_k) \\\\\n&= \\frac{\\beta}{2}(|\\bm{d}_k|^2 - |\\bm{d}_{k+1}|^2).\n\\end{align}\n \\qquad(6)\n\n\n\n\n\n\n\nSumming up Equation¬†6 from 00 to kk, we have\n‚àël=0kŒ¥l‚â§Œ≤2(|ùêù0|2‚àí|ùêùk+1|2)‚â§Œ≤2|ùêù0|2.(7)\n\\sum_{l=0}^k \\delta_l \\leq \\frac{\\beta}{2}(|\\bm{d}_0|^2 - |\\bm{d}_{k+1}|^2) \\leq\n\\frac{\\beta}{2}|\\bm{d}_0|^2.\n \\qquad(7)\nUsing Equation¬†3 again for ùê±=ùê±k+1\\bm{x} = \\bm{x}_{k+1} and ùê≤=ùê±k\\bm{y} = \\bm{x}_k and noting the SD rule we have\nŒ¥k+1‚àíŒ¥k=f(ùê±k+1)‚àíf(ùê±k)‚â§ùê†k+1‚ä§(‚àí1Œ≤ùê†k)‚àí12Œ≤|ùê†k+1‚àíùê†k|2=‚àí12Œ≤(|ùê†k+1|2+|ùê†k|2).(8)\n\\begin{align}\n\\delta_{k+1} - \\delta_k &= f(\\bm{x}_{k+1}) - f(\\bm{x}_k) \\\\\n&\\leq \\bm{g}_{k+1}^\\top (-\\frac{1}{\\beta}\\bm{g}_k) -\n\\frac{1}{2\\beta}|\\bm{g}_{k+1} - \\bm{g}_k|^2 \\\\\n&= -\\frac{1}{2\\beta}(|\\bm{g}_{k+1}|^2 + |\\bm{g}_k|^2).\n\\end{align}\n \\qquad(8)\nNoting that Equation¬†8 holds for all kk, we have\n ‚àël=0kŒ¥l=‚àël=0kŒ¥l(l+1‚àíl)=‚àël=0kŒ¥l(l+1)‚àí‚àël=0kŒ¥ll=‚àël=1k+1Œ¥l‚àí1l‚àí‚àël=1kŒ¥ll=Œ¥k(k+1)+‚àël=1k(Œ¥l‚àí1‚àíŒ¥l)l‚â•Œ¥k(k+1)+‚àël=1kl2Œ≤(|ùê†l2|+|ùê†l‚àí1|2)‚â•Œ¥k(k+1)+k(k+1)2Œ≤|ùê†k|2,\n\\begin{align}\n\\sum_{l=0}^k \\delta_l &= \\sum_{l=0}^k \\delta_l (l + 1 - l) = \\sum_{l=0}^k\n\\delta_l(l+1) - \\sum_{l=0}^k \\delta_l l \\\\\n&= \\sum_{l=1}^{k+1} \\delta_{l-1}l - \\sum_{l=1}^k \\delta_ll = \\delta_k (k+1) +\n\\sum_{l=1}^k (\\delta_{l-1} - \\delta_l)l \\\\\n&\\geq \\delta_k(k+1) + \\sum_{l=1}^k \\frac{l}{2\\beta}(|\\bm{g}_l^2| + |\\bm{g}_{l-1}|^2) \\\\\n&\\geq \\delta_k (k+1) + \\frac{k(k+1)}{2\\beta}|\\bm{g}_k|^2,\n\\end{align}\n \nwhere the last inequality comes from the fact that |ùê†k|=|‚àáf(ùê±k)||\\bm{g}_k| = |\\nabla f(\\bm{x}_k)| is monotonically decreasing."
  },
  {
    "objectID": "07_basic_descent.html#steepest-descent-analysis-2",
    "href": "07_basic_descent.html#steepest-descent-analysis-2",
    "title": "07_basic_descent",
    "section": "Steepest Descent Analysis",
    "text": "Steepest Descent Analysis\n\n\n\nProof ‚Äì Continued ‚Äì\n\n\nUsing Equation¬†7 we finally have\n(k+1)Œ¥k+k(k+1)2Œ≤|ùê†k|2‚â§Œ≤2|ùêù0|2(9)\n(k+1)\\delta_k + \\frac{k(k+1)}{2\\beta} |\\bm{g}_k|^2 \\leq\n\\frac{\\beta}{2}|\\bm{d}_0|^2\n \\qquad(9)\nInequality Equation¬†9, from Œ¥k=f(ùê±k)‚àíf(ùê±*)‚â•0\\delta_k = f(\\bm{x}_k) - f(\\bm{x}^\\ast) \\geq 0 and ùêù0=ùê±0‚àíùê±*\\bm{d}_0 = \\bm{x}_0 - \\bm{x}^\\ast, proves the desired bounds."
  },
  {
    "objectID": "07_basic_descent.html#the-quadratic-case",
    "href": "07_basic_descent.html#the-quadratic-case",
    "title": "07_basic_descent",
    "section": "The Quadratic Case",
    "text": "The Quadratic Case\n\n\n\nWhen f(ùê±)f(\\bm{x}) is strongly convex, the convergence speed can be increased from arithmetic to geometric or linear convergence.\n\n\n\n\n\n\n\n\nWe focus on the quadratic problem\nf(ùê±)=12ùê±‚ä§ùêêùê±‚àíùê±‚ä§ùêõ,ùêê‚âªùüé.(10) f(\\bm{x}) = \\frac{1}{2}\\bm{x}^\\top \\bm{Q} \\bm{x} - \\bm{x}^\\top \\bm{b}, \\;\\;\n\\bm{Q} \\succ \\bm{0}.  \\qquad(10)\n\nThe unique minimum of ff can be found directly by setting the gradient to zero: ùêêùê±*=ùêõ. \\bm{Q}\\bm{x}^\\ast = \\bm{b}. \nLet‚Äôs introduce the function E(ùê±)=12(ùê±‚àíùê±*)ùêê(ùê±‚àíùê±*), E(\\bm{x}) = \\frac{1}{2}(\\bm{x} -\n\\bm{x}^\\ast)\\bm{Q}(\\bm{x} - \\bm{x}^\\ast),  so that we have E(ùê±)=f(ùê±)+12ùê±*ùêêùê±*E(\\bm{x}) = f(\\bm{x}) + \\frac{1}{2}\\bm{x}^\\ast \\bm{Q} \\bm{x}^\\ast. Hence minf‚áîminE\\operatorname{min} f \\; \\Leftrightarrow \\; \\operatorname{min} E.\nThe method of SD can be expressed as ùê±k+1=ùê±k‚àíŒ±kùê†k\\bm{x}_{k+1} = \\bm{x}_k - \\alpha_k \\bm{g}_k, where ùê†k=ùêêùê±k‚àíùêõ\\bm{g}_k = \\bm{Q}\\bm{x}_k - \\bm{b} and Œ±k\\alpha_k minimizes f(ùê±k‚àíŒ±ùê†k)f(\\bm{x}_k - \\alpha \\bm{g}_k).\nWe have by definition Equation¬†10 f(ùê±k‚àíŒ±ùê†k)=12(ùê±k‚àíŒ±ùê†k)‚ä§ùêê(ùê±k‚àíŒ±ùê†k)‚àí(ùê±k‚àíŒ±ùê†k)‚ä§ùêõ. f(\\bm{x}_k -\\alpha \\bm{g}_k) = \\frac{1}{2}(\\bm{x}_k - \\alpha \\bm{g}_k)^\\top\n\\bm{Q} (\\bm{x}_k - \\alpha \\bm{g}_k) - (\\bm{x}_k - \\alpha \\bm{g}_k)^\\top \\bm{b}.\n\n\nThis is minimized at Œ±k=ùê†k‚ä§ùê†kùê†k‚ä§ùêêùê†k. \\alpha_k = \\frac{\\bm{g}_k^\\top \\bm{g}_k}{\\bm{g}_k^\\top\n\\bm{Q} \\bm{g}_k}. \n\n\n\n\n\n\n\n\n\n\n\nThe function ff and the SD process is illustrated by showing the contours of constant values of ff and a typical sequence developed by the process.\nThe contours of ff are nn-dim. ellipsoids with axes in the directions of the nn-mutually orthogonal eigenvectors of ùêê\\bm{Q}.\nThe axis corresponding to the ithi^{\\text{th}} eigenvector has length proportional to 1Œªi\\frac{1}{\\lambda_i}."
  },
  {
    "objectID": "07_basic_descent.html#nonquadratic-case",
    "href": "07_basic_descent.html#nonquadratic-case",
    "title": "07_basic_descent",
    "section": "Nonquadratic Case",
    "text": "Nonquadratic Case\n\n\n\nFor nonquadratic functions, SD still does well if the condition number is modest. To establish estimates, assume that the Hessian matrix is positive definite: Œ±ùêà‚â§ùêÖ(ùê±‚Äæ)‚â§Aùêà\\alpha \\bm{I} \\leq \\bm{F}(\\bar{\\bm{x}}) \\leq A\\bm{I}.\n\n\n\n\n\n\n\n\nExact Line Search\n\n\nf(ùê±k‚àíŒ±g(ùê±k))‚â§f(ùê±k)‚àíŒ±ùê†(ùê±k)‚ä§ùê†(ùê±k)+AŒ±22ùê†(ùê±k)‚ä§ùê†(ùê±k). f(\\bm{x}_k - \\alpha g(\\bm{x}_k)) \\leq f(\\bm{x}_k) - \\alpha\n\\bm{g}(\\bm{x}_k)^\\top \\bm{g}(\\bm{x}_k) +\n\\frac{A\\alpha^2}{2}\\bm{g}(\\bm{x}_k)^\\top \\bm{g}(\\bm{x}_k). \nMinimizing both sides w.r.t. Œ±\\alpha yields f(ùê±k+1)‚â§f(ùê±k)‚àí12A|ùê†(ùê±k)|2. f(\\bm{x}_{k+1}) \\leq f(\\bm{x}_k) - \\frac{1}{2A}|\\bm{g}(\\bm{x}_k)|^2. \nSubtracting the optimal value f*=f(ùê±*)f^\\ast = f(\\bm{x}^\\ast) from both sides f(ùê±k+1)‚àíf*‚â§f(ùê±k)‚àíf*‚àí12A|ùê†(ùê±k)|2.(11) f(\\bm{x}_{k+1}) - f^\\ast \\leq f(\\bm{x}_k) - f^\\ast -\n\\frac{1}{2A}|\\bm{g}(\\bm{x}_k)|^2.  \\qquad(11)\nSimilarly, for any ùê±\\bm{x} there holds f(ùê±)‚â•f(ùê±k)+ùê†(ùê±k)‚ä§(ùê±‚àíùê±k)+a2|ùê±‚àíùê±k|2. f(\\bm{x}) \\geq f(\\bm{x}_k) + \\bm{g}(\\bm{x}_k)^\\top (\\bm{x} - \\bm{x}_k) +\n\\frac{a}{2} | \\bm{x} - \\bm{x}_k |^2. \n\n\n\n\n\n\n\nAgain, minimize both sides: the left-hand side is minimized at f*f^\\ast and the right-hand side is minimized at ùê±‚Äæ=ùê±k‚àíùê†(ùê±k)a\\bar{\\bm{x}} = \\bm{x}_k - \\frac{\\bm{g}(\\bm{x}_k)}{a}. Subsituting this ùê±‚Äæ\\bar{\\bm{x}} in the right-hand side gives f*‚â•f(ùê±k)‚àí12a|ùê†(ùê±k)|2.(12) f^\\ast \\geq f(\\bm{x}_k) - \\frac{1}{2a}|\\bm{g}(\\bm{x}_k)|^2.  \\qquad(12)\nFrom Equation¬†12, we have ‚àí|ùê†(ùê±k)|2‚â§2a[f*‚àíf(ùê±k)]. - |\\bm{g}(\\bm{x}_k)|^2 \\leq 2a [f^\\ast - f(\\bm{x}_k)]. \nSubstituting this in Equation¬†11 gives f(ùê±k+1)‚àíf*‚â§(1‚àíaA)[f(ùê±k‚àíf*)]. f(\\bm{x}_{k+1}) - f^\\ast \\leq (1-\\frac{a}{A})[f(\\bm{x}_k - f^\\ast)]. \nThis shows that SD makes progress even when it is not close to the solution.\n\n\n\n\n\n\n\n\nTheorem. Suppose that the Hessian matrix ùêÖ(ùê±*)\\bm{F}(\\bm{x}^\\ast) of ff at a relative minimum ùê±*\\bm{x}^\\ast has the smallest and largest eigenvalues a,A&gt;0a, A &gt; 0, respectively. If {ùê±k}\\{\\bm{x}_k\\} is a sequence generated by the method of steepest descent that converges to ùê±*\\bm{x}^\\ast, then the sequence of objective values {f(ùê±k)}\\{f(\\bm{x}_k)\\} converges to f(ùê±*)f(\\bm{x}^\\ast) linearly with a convergence ratio no greater than (A‚àíaA+a)2(\\frac{A-a}{A+a})^2."
  },
  {
    "objectID": "07_basic_descent.html#accelerated-steepest-descent",
    "href": "07_basic_descent.html#accelerated-steepest-descent",
    "title": "07_basic_descent",
    "section": "Accelerated Steepest Descent",
    "text": "Accelerated Steepest Descent\n\n\n\n\nThere is an accelerated steepest descent method that works as follows:\nŒª0=0,Œªk+1=12(1+1+4Œªk2),Œ±k=1‚àíŒªkŒªk+1,ùê±ÃÉk+1=ùê±k‚àí1Œ≤‚àáf(ùê±k)‚ä§,ùê±k+1=(1‚àíŒ±k)ùê±ÃÉk+1+Œ±kùê±ÃÉk.\n\\begin{align}\n&\\lambda^0 = 0, & \\lambda_{k+1} = \\frac{1}{2}(1 + \\sqrt{1+4\\lambda_k^2}), &\n\\alpha_k = \\frac{1 - \\lambda_k}{\\lambda_{k+1}}, & \\tilde{\\bm{x}}_{k+1} =\n\\bm{x}_k - \\frac{1}{\\beta}\\nabla f(\\bm{x}_k)^\\top, & \\bm{x}_{k+1} = (1 -\n\\alpha_k) \\tilde{\\bm{x}}_{k+1} + \\alpha_k \\tilde{\\bm{x}}_k.\n\\end{align}\n\nNote that Œªk2=Œªk+1(Œªk+1‚àí1)\\lambda_k^2 = \\lambda_{k+1}(\\lambda_{k+1} -1), Œªk&gt;k2\\lambda_k &gt; \\frac{k}{2}, and Œ±k‚â§0\\alpha_k \\leq 0.\n\n\n\n\n\n\nTheorem (Accelerated Steepest Descent)\n\n\nLet f(ùê±)f(\\bm{x}) be convex and differentiable everywhere, satisfies the (first-order) Œ≤\\beta-Lipschitz condition, and admits a minimizer ùê±*\\bm{x}^\\ast. Then, the method of accelerated steepest descent generates a sequence of solutions such that\nf(ùê±ÃÉk+1)‚àíf(ùê±*)‚â§2Œ≤k2|ùê±0‚àíùê±*|2,‚àÄk‚â•1.\nf(\\tilde{\\bm{x}}_{k+1}) - f(\\bm{x}^\\ast) \\leq \\frac{2\\beta}{k^2}|\\bm{x}_0 -\n\\bm{x}^\\ast|^2, \\quad \\forall k \\geq 1."
  },
  {
    "objectID": "07_basic_descent.html#order-two-convergence",
    "href": "07_basic_descent.html#order-two-convergence",
    "title": "07_basic_descent",
    "section": "Order Two Convergence",
    "text": "Order Two Convergence\n\n\n\n\nTheorem (Newton‚Äôs Method)\n\n\nLet f‚ààC3f \\in C^3 on ‚Ñùn\\mathbb{R}^n and assume that at the local minimum point ùê±*\\bm{x}^\\ast, the Hessian ùêÖ(ùê±*)\\bm{F}(\\bm{x}^\\ast) is positive definite. Then if started sufficiently close to ùê±*\\bm{x}^\\ast, the points generated by Newton‚Äôs method converge to ùê±*\\bm{x}^\\ast. The order of convergence is at least two.\n\n\n\n\n\n\nProof\n\n\nThere are œÅ,Œ≤1,Œ≤2&gt;0\\rho, \\beta_1, \\beta_2 &gt; 0 such that for all ùê±\\bm{x} with |ùê±‚àíùê±*&lt;œÅ|\\bm{x} - \\bm{x}^\\ast &lt; \\rho, there holds |ùêÖ(ùê±)‚àí1|&lt;Œ≤1|\\bm{F}(\\bm{x})^{-1}| &lt; \\beta_1 and |‚àáf(ùê±*)‚ä§‚àí‚àáf(ùê±)‚ä§‚àíùêÖ(ùê±)(ùê±*‚àíùê±)|‚â§Œ≤2|ùê±‚àíùê±*|2|\\nabla f(\\bm{x^\\ast})^\\top - \\nabla f(\\bm{x})^\\top - \\bm{F}(\\bm{x})(\\bm{x}^\\ast - \\bm{x})| \\leq \\beta_2 |\\bm{x} - \\bm{x}^\\ast|^2. now suppose ùê±k\\bm{x}_k is selected with Œ≤1Œ≤2|ùê±k‚àíùê±*|&lt;1\\beta_1\\beta_2|\\bm{x}_k - \\bm{x}^\\ast| &lt; 1 and |ùê±k‚àíùê±*|&lt;œÅ|\\bm{x}_k - \\bm{x}^\\ast| &lt; \\rho. Then\n|ùê±k+1‚àíùê±*|=|ùê±k‚àíùê±*‚àíùêÖ(ùê±k)‚àí1‚àáf(ùê±k)‚ä§|=|ùêÖ(ùê±k)‚àí1[‚àáf(ùê±*)‚ä§‚àí‚àáf(ùê±k)‚àíùêÖ(ùê±k)(ùê±*‚àíùê±k)]|‚â§|ùêü(ùê±k)‚àí1|Œ≤2|ùê±k‚àíùê±*|2‚â§Œ≤1Œ≤2|ùê±k‚àíùê±*|2&lt;|ùê±k‚àíùê±*|.\n\\begin{align}\n|\\bm{x}_{k+1} - \\bm{x}^\\ast| &= |\\bm{x}_k - \\bm{x}^\\ast -\n\\bm{F}(\\bm{x}_k)^{-1}\\nabla f(\\bm{x}_k)^\\top| = |\\bm{F}(\\bm{x}_k)^{-1}[\\nabla\nf(\\bm{x}^\\ast)^\\top - \\nabla f(\\bm{x}_k) - \\bm{F}(\\bm{x}_k)(\\bm{x}^\\ast -\n\\bm{x}_k)]| \\\\ &\\leq |\\bm{f}(\\bm{x}_k)^{-1}|\\beta_2|\\bm{x}_k - \\bm{x}^\\ast|^2\n\\leq \\beta_1\\beta_2|\\bm{x}_k - \\bm{x}^\\ast|^2 &lt; |\\bm{x}_k - \\bm{x}^\\ast|.\n\\end{align}\n\nThe final inequality shows that the new point is closer to ùê±*\\bm{x}^\\ast than the old point, and hence all conditions apply again to ùê±k+1\\bm{x}_{k+1}. The previous inequality establishes that the convergence is second order."
  },
  {
    "objectID": "07_basic_descent.html#modifications",
    "href": "07_basic_descent.html#modifications",
    "title": "07_basic_descent",
    "section": "Modifications",
    "text": "Modifications\n\n\n\nAlthough Newton‚Äôs method is very attractive in terms of its convergence properties near the solution, it requires modification before it can be used at points that are remote from the solution.\n\n\n\n\n\n\n\n\nDamping\n\n\nA search parameter Œ±\\alpha is introduced ùê±k+1=ùê±k‚àíŒ±kùêÖ(ùê±k)‚àí1‚àáf(ùê±k)‚ä§, \\bm{x}_{k+1} = \\bm{x}_k - \\alpha_k \\bm{F}(\\bm{x}_k)^{-1}\\nabla\nf(\\bm{x}_k)^\\top,  where Œ±k\\alpha_k is selected to minimize ff.\n\n\n\n\n\n\nPositive Definiteness and Scaling\n\n\nGeneral class of algorithms is given by ùê±k+1=ùê±k+Œ±ùêùk=ùê±k‚àíŒ±ùêåkùê†k,(14) \\bm{x}_{k+1} = \\bm{x}_k + \\alpha \\bm{d}_k = \\bm{x}_k - \\alpha \\bm{M}_k \\bm{g}_k,  \\qquad(14)\n\nSD: ùêåk=ùêà\\bm{M}_k = \\bm{I}, Newton: ùêåk=ùêÖ(ùê±k)‚àí1\\bm{M}_k = \\bm{F}(\\bm{x}_k)^{-1}.\n\nFor small Œ±\\alpha, it can be shown that f(ùê±k+1)=f(ùê±k)‚àíŒ±ùê†k‚ä§ùêåkùê†k+O(Œ±2). f(\\bm{x}_{k+1}) = f(\\bm{x}_k) -\n\\alpha \\bm{g}_k^\\top \\bm{M}_k \\bm{g}_k + O(\\alpha^2). \n\nAs Œ±‚Üí0\\alpha \\rightarrow 0, the second term on the rhs dominates the third.\nTo guarantee a descrese in ff, we must have ùê†k‚ä§ùêåkùê†k&gt;0\\bm{g}_k^\\top \\bm{M}_k \\bm{g}_k &gt; 0.\n\nSimplest way to ensure this is to require ùêåk‚âªùüé\\bm{M}_k \\succ \\bm{0}.\n\n\n\n\n\n\n\n\n\nGeneral Problems\n\n\n\nIn practice, Newton‚Äôs method must be modified to accommodate the possible nonpositive definiteness at regions remote from the solution.\nCommon approach: ùêåk=[Œºkùêà+ùêÖ(ùê±k)]‚àí1\\bm{M}_k = [\\mu_k\\bm{I} + \\bm{F}(\\bm{x}_k)]^{-1} for some Œºk&gt;0\\mu_k &gt; 0.\nThis can be regarded as a compromise between SD (Œºk\\mu_k very large) and Newton‚Äôs method (Œºk=0\\mu_k = 0).\n\nLevenberg-Marquardt performs Cholesky factorization for a given value of Œºk\\mu_k as follows Œºkùêà+ùêÖ(ùê±k)=ùêÜùêÜ‚ä§.\\mu_k \\bm{I} + \\bm{F}(\\bm{x}_k) = \\bm{G}\\bm{G}^\\top. \nThis checks for positive definiteness (not positive definite if factorization fails).\nIf the factorization breaks down Œºk\\mu_k is increased.\nStep direction is found by solving ùêÜùêÜ‚ä§ùêùk=‚àíùê†k\\bm{G}\\bm{G}^\\top \\bm{d}_k = -\\bm{g}_k."
  },
  {
    "objectID": "07_basic_descent.html#coordinate-descent",
    "href": "07_basic_descent.html#coordinate-descent",
    "title": "07_basic_descent",
    "section": "Coordinate Descent",
    "text": "Coordinate Descent\n\n\n\nGiven a point ùê±=(x1,x2,‚Ä¶,xn)\\bm{x} = (x_1, x_2, \\ldots, x_n), descent w.r.t. the coordinate xix_i (ii fixed) means that one solves\nminimizexif(x1,x2,‚Ä¶,xn). \\operatorname{minimize}_{x_i} \\quad f(x_1, x_2, \\ldots, x_n). \n\n\n\n\nOnly changes in the single component xix_i are allowed in seeking a new and better vector ùê±\\bm{x}.\n\nOne can also consider ùê±i\\bm{x}_i the ithi^{\\text{th}} block of variables (block coordinate method).\n\nIn our general terminology, each such descent can be regarded as a descent in the direction ùêûi\\bm{e}_i.\n\n\n\n\n\n\nCyclic methods\n\n\n\nminx1,x2,‚Ä¶,xn\\operatorname{min}\\;\\; x_1, x_2, \\ldots, x_n \\quad then minxn‚àí1,xn‚àí2,‚Ä¶,x1\\quad \\operatorname{min}\\;\\; x_{n-1}, x_{n-2}, \\ldots, x_1\nminx1,x2,‚Ä¶,xn\\operatorname{min}\\;\\; x_1, x_2, \\ldots, x_n \\quad then minx1,x2,‚Ä¶,xn\\quad \\operatorname{min}\\;\\; x_{1}, x_{2}, \\ldots, x_n\n\nThey have the advantage of not requiring any information about ‚àáf\\nabla f to determine descent directions.\n\n\n\n\n\n\n\nGauss-Southwell Method\n\n\n\nIf the gradient of ff is available, then it is possible to select the order of descent coordinates on the basis of the gradient.\nAt each stage, the coordinate corresponding to the largest component of the gradient vector is selected for descent."
  },
  {
    "objectID": "07_basic_descent.html#stochastic-gradient-descent-sgd-method",
    "href": "07_basic_descent.html#stochastic-gradient-descent-sgd-method",
    "title": "07_basic_descent",
    "section": "Stochastic Gradient Descent (SGD) Method",
    "text": "Stochastic Gradient Descent (SGD) Method\n\n\n\nImagine we are solving a stochastic optimization problem or its simple average approximation\nf(ùê±)=ùîº[œï(ùê±,ùõè)]orf(ùê±)=1M‚àëi=1Mœï(ùê±,ùõèùê¢), f(\\bm{x}) = \\mathbb{E}[\\phi(\\bm{x}, \\bm{\\xi})] \\qquad \\text{or} \\qquad\nf(\\bm{x}) = \\frac{1}{M} \\sum_{i=1}^M \\phi(\\bm{x}, \\bm{\\xi_i}), \nwhere ùõè\\bm{\\xi} is a random parameter and Œæi\\xi_i is a randomly chosen sample.\n\nIf we simply apply the SD, the evaluation of the gradient vector would be costly, involving a large sum computation.\nThe SGD would, at the current iterate ùê±k\\bm{x}_k, randomly select a sample point Œæk\\xi_k and compute its (sub)gradient vector ùê†k:=ùê†(ùê±k,Œæk)\\bm{g}_k := \\bm{g}(\\bm{x}_k, \\xi_k), which satisfies, in expectation, ùîº[ùê†k|ùê±k]‚àà‚àÇf(ùê±k)\\mathbb{E}[\\bm{g}_k | \\bm{x}_k] \\in \\partial f(\\bm{x}_k).\nThen the method would update, starting from an initial solution ùê±0\\bm{x}_0,\n\nùê±k+1=ùê±k‚àíŒ±kùê†k, \\bm{x}_{k+1} = \\bm{x}_k - \\alpha_k \\bm{g}_k, \nuntil k=K‚àí1k = K-1 and return the average solution: ùê±‚Äæ=1K‚àëk=0K‚àí1ùê±k\\bar{\\bm{x}} = \\frac{1}{K}\\sum_{k=0}^{K-1} \\bm{x}_k.\n\n\n\n\n\n\nTheorem (SGD)\n\n\nLet f(ùê±)f(\\bm{x}) be a convex function that admits a minimizer ùê±*\\bm{x}^\\ast. Assume the following two conditions hold:\n\nThe sample (sub)gradients at ùê±k\\bm{x}_k satisfy |ùê†k|‚â§Œ≤(&gt;0)|\\bm{g}_k| \\leq \\beta (&gt;0) with probability 11 for all k=0,‚Ä¶,K‚àí1k = 0, \\ldots, K-1.\nThe initial solution satisfies, for simplicity, |ùê±0‚àíùê±*|‚â§1|\\bm{x}_0 - \\bm{x}^\\ast| \\leq 1.\n\nThen, with (fixed) stepsize Œ±k=Œ±=1Œ≤K\\alpha_k = \\alpha = \\frac{1}{\\beta\\sqrt{K}}, the returned solution ùê±‚Äæ\\bar{\\bm{x}} satisfies: ùîº[f(ùê±‚Äæ)‚àíf(ùê±*)]‚â§Œ≤K\\qquad \\mathbb{E}[f(\\bar{\\bm{x}}) - f(\\bm{x}^\\ast)] \\leq \\frac{\\beta}{\\sqrt{K}}.\n\n\n\n\n\nOptimization Theory and Practice ‚Ä¢ Aykut C. Satici"
  }
]