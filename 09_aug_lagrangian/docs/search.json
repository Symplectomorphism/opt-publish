[
  {
    "objectID": "09_aug_lagrangian.html#optimization-theory-and-practice",
    "href": "09_aug_lagrangian.html#optimization-theory-and-practice",
    "title": "09_aug_lagrangian",
    "section": "Optimization Theory and Practice",
    "text": "Optimization Theory and Practice\n\n\nLocal Duality and Dual Methods\n\n\n\n\nInstructor: Aykut Satici, Ph.D.   Mechanical and Biomedical Engineering  Electrical and Computer Engineering  Boise State University, Boise, ID, USA\n\n\nTopics:  Local Duality and the Lagrangian Method  The Augmented Lagrangian (M. of Multipliers)  Separable Problems and Their Duals  The Alternating Direction M. of Multipliers"
  },
  {
    "objectID": "09_aug_lagrangian.html#local-duality",
    "href": "09_aug_lagrangian.html#local-duality",
    "title": "09_aug_lagrangian",
    "section": "Local Duality",
    "text": "Local Duality\n\n\n\n\n\nNonlinear Programming Problem\n\n\nminimizef(𝐱),f,𝐡∈C2,subject to𝐡(𝐱)=𝟎,𝐱∈ℝn,𝐡(𝐱)∈ℝm.(1)\n\\begin{align}\n\\operatorname{minimize} & f(\\bm{x}), & f, \\bm{h} \\in C^2, \\\\\n\\text{subject to} & \\bm{h}(\\bm{x}) = \\bm{0}, & \\bm{x} \\in \\mathbb{R}^n, \n\\bm{h}(\\bm{x}) \\in \\mathbb{R}^m.\n\\end{align}\n \\qquad(1)\nEverything we do can be easily extended to problems having inequality as well as equality constraints for the price of a somewhat more involved notation.\n\n\n\n\nAssume that 𝐱*\\bm{x}^\\ast is a regular point of the constraints.\n\nThere is then a Lagrange multiplier vector 𝛌*\\bm{\\lambda}^\\ast such that\n\n\n∇f(𝐱*)−(𝛌*)⊤∇𝐡(𝐱*)=𝟎,(2)\n\\nabla f(\\bm{x}^\\ast) - \\left(\\bm{\\lambda}^\\ast\\right)^\\top \\nabla \\bm{h}\n(\\bm{x}^\\ast) = \\bm{0},\n \\qquad(2)\nand the Hessian of the Lagrangian ℓ(𝐱,𝛌*)=f(𝐱)−(𝛌*)⊤𝐡(𝐱)\\ell(\\bm{x}, \\bm{\\lambda}^\\ast) = f(\\bm{x}) - \\left(\\bm{\\lambda}^\\ast\\right)^\\top \\bm{h}(\\bm{x})\n𝐋(𝐱*)=𝐅(𝐱*)−(𝛌*)⊤𝐇(𝐱*)(3)\n\\bm{L}(\\bm{x}^\\ast) = \\bm{F}(\\bm{x}^\\ast) - \\left(\\bm{\\lambda}^\\ast\\right)^\\top \\bm{H}(\\bm{x}^\\ast)\n \\qquad(3)\nmust be positive semidefinite on the tangent subspace\nM={𝐱:∇𝐡(𝐱*)=𝟎}. M = \\{\\bm{x}: \\nabla \\bm{h}(\\bm{x}^\\ast) = \\bm{0}\\}. \n\n\n\n\nLocal Convexity Assumption\n\n\nWe assume that the Hessian 𝐋(𝐱*)\\bm{L(\\bm{x}^\\ast)} is positive definite. (We mean that 𝐋(𝐱*)\\bm{L(\\bm{x}^\\ast)} on the whole space ℝn\\mathbb{R}^n, not just on the subspace MM.)\nThis assumption guarantees that the Lagrangian ℓ(𝐱,𝛌*)\\ell(\\bm{x}, \\bm{\\lambda}^\\ast) is locally convex at 𝐱*\\bm{x}^\\ast.\n\n\n\n\nWith this assumption, the point 𝐱*\\bm{x}^\\ast is not only a local solution to the constrained problem Equation 1; it is also a local solution to the unconstrained problem\n\nminimizeℓ(𝐱,𝛌*)=f(𝐱)−(𝛌*)⊤𝐡(𝐱)(4)\n\\begin{align}\n\\operatorname{minimize} & \\ell(\\bm{x}, \\bm{\\lambda}^\\ast) = f(\\bm{x}) - \n\\left( \\bm{\\lambda}^\\ast \\right)^\\top \\bm{h}(\\bm{x})\n\\end{align}\n \\qquad(4)\n\nFor any 𝛌\\bm{\\lambda} sufficiently close to 𝛌*\\bm{\\lambda}^\\ast, the function ℓ(𝐱,𝛌)\\ell(\\bm{x}, \\bm{\\lambda}) will have a local minimum point at a point 𝐱\\bm{x} near 𝐱*\\bm{x}^\\ast.\n\nThis follows by noting that by the implicit function theorem, the eqn. ∇f(𝐱)−𝛌⊤∇𝐡(𝐱)=𝟎\n\\nabla f(\\bm{x}) - \\bm{\\lambda}^\\top \\nabla \\bm{h}\n(\\bm{x}) = \\bm{0}\n\n\n\nhas a solution 𝐱\\bm{x} near 𝐱*\\bm{x}^\\ast when 𝛌\\bm{\\lambda} is near 𝛌*\\bm{\\lambda}^\\ast because 𝐋*\\bm{L}^\\ast is positive definite."
  },
  {
    "objectID": "09_aug_lagrangian.html#local-duality-1",
    "href": "09_aug_lagrangian.html#local-duality-1",
    "title": "09_aug_lagrangian",
    "section": "Local Duality",
    "text": "Local Duality\n\n\n\n\n\nThus, locally there is a unique correspondence between 𝛌\\bm{\\lambda} and 𝐱\\bm{x} through the solution of the unconstrained problem Equation 4. minimizeℓ(𝐱,𝛌)=f(𝐱)−𝛌⊤𝐡(𝐱).(5)\n\\begin{align}\n\\operatorname{minimize} & \\ell(\\bm{x}, \\bm{\\lambda}) = f(\\bm{x}) - \\bm{\\lambda}^\\top \\bm{h}(\\bm{x}).\n\\end{align}\n \\qquad(5)\n\nThis correspondence is continuously differentiable.\n\nNear 𝛌*\\bm{\\lambda}^\\ast we define the dual function ϕ\\phi by the equation ϕ(𝛌)≜min𝐱∈𝒩(𝐱*)[ℓ(𝐱,𝛌)=f(𝐱)−𝛌⊤𝐡(𝐱)](6)\n\\phi(\\bm{\\lambda}) \\triangleq \\operatorname{min}_{\\bm{x} \\in \\mathcal{N}(\\bm{x}^\\ast)} \n\\left[ \\ell(\\bm{x}, \\bm{\\lambda}) = f(\\bm{x}) - \\bm{\\lambda}^\\top \\bm{h}(\\bm{x}) \\right]\n \\qquad(6)\nWe are then able to show that locally the original constrained problem Equation 4 is equivalent to unconstrained local maximization of of the dual function ϕ\\phi with respect to 𝛌\\bm{\\lambda}.\n\nDenote by 𝐱(𝛌)\\bm{x}(\\bm{\\lambda}) the unique solution to Equation 5 in the neighborhood of 𝐱*\\bm{x}^\\ast.\n\n\n\n\n\n\n\n\nLemma 1\n\n\nThe dual function ϕ\\phi has gradient ∇ϕ(𝛌)=−𝐡(𝐱(𝛌))⊤.(7) \\nabla \\phi(\\bm{\\lambda}) = -\\bm{h}(\\bm{x}(\\bm{\\lambda}))^\\top.  \\qquad(7)\n\n\n\n\n\n\nProof\n\n\nWe have explicitly from Equation 6 ϕ(𝛌)=f(𝐱(𝛌))−𝛌⊤𝐡(𝐱(𝛌)). \\phi(\\bm{\\lambda}) = f(\\bm{x}(\\bm{\\lambda})) - \\bm{\\lambda}^\\top \\bm{h}(\\bm{x}(\\bm{\\lambda})).  Thus ∇ϕ(𝛌)=[∇f(𝐱(𝛌))−𝛌⊤∇𝐡(𝐱(𝛌))]∇𝐱(𝛌)−𝐡(𝐱(𝛌))⊤. \n\\nabla \\phi(\\bm{\\lambda}) = \\left[ \\nabla f(\\bm{x}(\\bm{\\lambda})) - \\bm{\\lambda}^\\top \\nabla \\bm{h}(\\bm{x}(\\bm{\\lambda})) \\right] \\nabla \\bm{x}(\\bm{\\lambda}) - \\bm{h}(\\bm{x}(\\bm{\\lambda}))^\\top. \n Since the first term on the right vanishes by the defition of 𝐱(𝛌)\\bm{x}(\\bm{\\lambda}) (the unique solution to Equation 5), we obtain Equation 7.\n\n\n\n\n\n\n\nLemma 2\n\n\nThe Hessian of the dual function is 𝚽(𝛌)=−∇𝐡(𝐱(𝛌))𝐋−1(𝐱(𝛌),𝛌)∇𝐡(𝐱(𝛌))⊤.(8)\n\\bm{\\Phi}(\\bm{\\lambda}) = -\\nabla \\bm{h}(\\bm{x}(\\bm{\\lambda}))\\bm{L}^{-1}(\\bm{x}(\\bm{\\lambda}), \\bm{\\lambda}) \\nabla \\bm{h}(\\bm{x}(\\bm{\\lambda}))^\\top.\n \\qquad(8)\n\n\n\n\n\n\nProof\n\n\nBy Lemma 1, 𝚽(𝛌)=−∇𝐡(𝐱(𝛌))∇𝐱(𝛌)\\bm{\\Phi}(\\bm{\\lambda}) = -\\nabla \\bm{h}(\\bm{x}(\\bm{\\lambda})) \\nabla \\bm{x}(\\bm{\\lambda}).\nDifferentiating ∇f(𝐱(𝛌))−𝛌⊤∇𝐡(𝐱(𝛌))=𝟎\\nabla f(\\bm{x}(\\bm{\\lambda})) - \\bm{\\lambda}^\\top \\nabla \\bm{h}(\\bm{x}(\\bm{\\lambda})) = \\bm{0} with respect to 𝛌\\bm{\\lambda}, we obtain\n𝐋(𝐱(𝛌),𝛌)∇𝐱(𝛌)−∇𝐡(𝐱(𝛌))⊤=𝟎. \n\\bm{L}(\\bm{x}(\\bm{\\lambda}), \\bm{\\lambda})\\nabla \\bm{x}(\\bm{\\lambda}) - \\nabla \\bm{h}(\\bm{x}(\\bm{\\lambda}))^\\top = \\bm{0}.\n\nSolving for ∇𝐱(𝛌)\\nabla \\bm{x}(\\bm{\\lambda}) and substituting back to the first eqn., we are through."
  },
  {
    "objectID": "09_aug_lagrangian.html#local-duality-theorem",
    "href": "09_aug_lagrangian.html#local-duality-theorem",
    "title": "09_aug_lagrangian",
    "section": "Local Duality Theorem",
    "text": "Local Duality Theorem\n\n\n\n\nLocal Duality Theorem\n\n\nSuppose that the problem minimizef(𝐱)subject to𝐡(𝐱)=𝟎\n\\begin{align}\n\\operatorname{minimize} & f(\\bm{x}) \\\\\n\\text{subject to} & \\bm{h}(\\bm{x}) = \\bm{0}\n\\end{align}\n has a local solution at 𝐱*\\bm{x}^\\ast with corresponding value r*r^\\ast and Lagrange multiplier 𝛌*\\bm{\\lambda}^\\ast. Suppose also that 𝐱*\\bm{x}^\\ast is a regular point of the constraints and that the corresponding Hessian of the Lagrangian 𝐋*=𝐋(𝐱*)\\bm{L}^\\ast = \\bm{L}(\\bm{x}^\\ast) is positive definite. Then the dual problem maximizeϕ(𝛌) \n\\begin{align}\n\\operatorname{maximize} & \\phi(\\bm{\\lambda})\n\\end{align}\n has a local solution at 𝛌*\\bm{\\lambda}^\\ast with corresponding value r*r^\\ast and 𝐱*\\bm{x}^\\ast as the point corresponding to 𝛌*\\bm{\\lambda}^\\ast in the definition of ϕ\\phi.\n\n\n\n\n\n\nProof\n\n\nIt is clear that 𝐱*\\bm{x}^\\ast corresponds to 𝛌*\\bm{\\lambda}^\\ast in the definition of ϕ\\phi. Now at 𝛌*\\bm{\\lambda}^\\ast we have by Lemma 1, ∇ϕ(𝛌*)=−𝐡(𝐱*)⊤=𝟎,\n\\nabla \\phi(\\bm{\\lambda}^\\ast) = -\\bm{h}(\\bm{x}^\\ast)^\\top = \\bm{0}, \n and by Lemma 2, the Hessian of ϕ\\phi is negative definite. Thus 𝛌*\\bm{\\lambda}^\\ast satisfies the SOSC for an unconstrained maximum point of ϕ\\phi. The corresponding value ϕ(𝛌*)\\phi(\\bm{\\lambda}^\\ast) is found from the definition of ϕ\\phi to be r*r^\\ast."
  },
  {
    "objectID": "09_aug_lagrangian.html#example",
    "href": "09_aug_lagrangian.html#example",
    "title": "09_aug_lagrangian",
    "section": "Example",
    "text": "Example\nminimize−xysubject to(x−3)2+y2=5.\n\\begin{align}\n\\operatorname{minimize} & -xy \\\\\n\\text{subject to} & (x-3)^2 + y^2 = 5.\n\\end{align}\n\n\n\n\n\n\nFirst-Order Necessary Conditions\n\n\n−y−(2x−6)λ=0−x−2yλ=0.\n\\begin{align}\n-y - (2x - 6)\\lambda &= 0 \\\\\n-x - 2y\\lambda &= 0.\n\\end{align}\n together with the constraint. These equations have a solution at x=4,y=2,λ=−1.\nx = 4, \\quad y = 2, \\quad \\lambda = -1.\n The Hessian of the corresponding Lagrangian is 𝐋=[2−1−12]. \\bm{L} = \\begin{bmatrix} 2 & -1 \\\\ -1 & 2 \\end{bmatrix}.  Since this is positive definite, we conclude that the solution obtained is a local minimum (it is, in fact, a global minimum).\n\n\n\n\n\n\n\nLocal Duality\n\n\nSince 𝐋\\bm{L} is positive definite, we can apply the local duality theory near this solution. ϕ(λ)=minx,y{−xy−λ[(x−3)2+y2−5]},\n\\phi(\\lambda) = \\operatorname{min}_{x,y} \\left\\{-xy - \\lambda \\left[(x-3)^2 + y^2 - 5\\right]\\right\\},\n which leads to ϕ(λ)=−4λ−4λ3+80λ5(4λ2−1)2\n\\phi(\\lambda) = \\frac{-4\\lambda - 4\\lambda^3 + 80\\lambda^5}{(4\\lambda^2 - 1)^2}\n valid for λ&lt;−12\\lambda &lt; -\\frac{1}{2}. It can be verified that ϕ\\phi has a local maximum at λ=−1\\lambda = -1. Plugging this value back in Equation 4 and maximizing (unconstrained) over xx and yy yields the same maximizers as before."
  },
  {
    "objectID": "09_aug_lagrangian.html#inequality-constraints",
    "href": "09_aug_lagrangian.html#inequality-constraints",
    "title": "09_aug_lagrangian",
    "section": "Inequality Constraints",
    "text": "Inequality Constraints\nminimizef(𝐱),f∈C2,𝐱∈ℝnsubject to𝐡(𝐱)=𝟎,𝐡∈ℂ2,𝐡(𝐱)∈ℝm,𝐠(𝐱)≥𝟎,𝐠∈C2,𝐠(𝐱)∈ℝp.(9)\n\\begin{align}\n\\operatorname{minimize} & f(\\bm{x}), & f \\in C^2, \\;\\; \\bm{x}\\in \\mathbb{R}^n \\\\ \n\\text{subject to} & \\bm{h}(\\bm{x}) = \\bm{0}, & \\bm{h} \\in \\mathbb{C}^2, \\;\\; \\bm{h}(\\bm{x}) \\in \\mathbb{R}^m, \\\\\\\n& \\bm{g}(\\bm{x}) \\geq \\bm{0}, & \\bm{g} \\in C^2, \\;\\; \\bm{g}(\\bm{x}) \\in \\mathbb{R}^p.\n\\end{align}\n \\qquad(9)\n\nSuppose 𝐱*\\bm{x}^\\ast is a local solution of Equation 9 and is a regular point of the constraints.\n\nThen, there are Lagrange multipliers 𝛌*\\bm{\\lambda}^\\ast and 𝛍*≥𝟎\\bm{\\mu}^\\ast \\geq \\bm{0} such that ∇f(𝐱*)−(𝛌*)⊤∇𝐡(𝐱*)−(𝛍*)⊤∇𝐠(𝐱*)=𝟎,(𝛍*)⊤𝐠(𝐱*)=0.\n\\begin{align}\n\\nabla f(\\bm{x}^\\ast) - \\left(\\bm{\\lambda}^\\ast \\right)^\\top \\nabla \n\\bm{h}(\\bm{x}^\\ast) - \\left(\\bm{\\mu}^\\ast\\right)^\\top \\nabla \\bm{g}(\\bm{x}^\\ast) &= \\bm{0}, \\\\\n\\left(\\bm{\\mu}^\\ast\\right)^\\top \\bm{g}(\\bm{x}^\\ast) = 0.\n\\end{align}\n\n\nLocal convexity assumption: Hessian of the Lagrangian is positive definite on the whole space. 𝐋(𝐱*)=𝐅(𝐱*)−(𝛌*)⊤𝐇(𝐱*)−(𝛍*)𝐆(𝐱*)≻𝟎. \\bm{L}(\\bm{x}^\\ast) = \\bm{F}(\\bm{x}^\\ast) - \\left(\\bm{\\lambda}^\\ast\\right)^\\top \n\\bm{H}(\\bm{x}^\\ast) - \\left(\\bm{\\mu}^\\ast\\right)\\bm{G}(\\bm{x}^\\ast) \\succ \\bm{0}.\n\nFor 𝛌\\bm{\\lambda} and 𝛍≥𝟎\\bm{\\mu} \\geq \\bm{0} near 𝛌*\\bm{\\lambda}^\\ast and 𝛍*\\bm{\\mu}^\\ast we can define the dual function ϕ(𝛌,𝛍)≜min𝐱∈𝒩(𝐱*)[ℓ(𝐱,𝛌,𝛍)=f(𝐱)−𝛌⊤𝐡(𝐱)−𝛍⊤𝐠(𝐱)],\n\\phi(\\bm{\\lambda}, \\bm{\\mu}) \\triangleq \\operatorname{min}_{\\bm{x} \\in \\mathcal{N}(\\bm{x}^\\ast)} \n\\left[ \\ell(\\bm{x}, \\bm{\\lambda}, \\bm{\\mu}) = f(\\bm{x}) - \\bm{\\lambda}^\\top \n\\bm{h}(\\bm{x}) - \\bm{\\mu}^\\top \\bm{g}(\\bm{x}) \\right],\n where the minimum is taken locally near 𝐱*\\bm{x}^\\ast.\nThen it is easy to show, paralleling the devlopment above for equality constraints, that ϕ\\phi achieves a local maximum with respect to 𝛌\\bm{\\lambda}, 𝛍≥𝟎\\bm{\\mu} \\geq \\bm{0} at 𝛌*\\bm{\\lambda}^\\ast, 𝛍*\\bm{\\mu}^\\ast."
  },
  {
    "objectID": "09_aug_lagrangian.html#partial-duality",
    "href": "09_aug_lagrangian.html#partial-duality",
    "title": "09_aug_lagrangian",
    "section": "Partial Duality",
    "text": "Partial Duality\n\n\nIt is not necessary to include the lagrange multipliers of all the cosntraints of a problem in the definition of the dual function.\nIn general, if the local convexity assumption holds, local duality can be defined with respect to any subset of function constraints.\n\nFor example, in problem Equation 9 we might define the dual with respect to only the equality constraints ϕ(𝛌)=min𝐠(𝐱)≥𝟎{f(𝐱)−𝛌⊤𝐡(𝐱)}, \\phi(\\bm{\\lambda}) = \\operatorname{min}_{\\bm{g}(\\bm{x}) \\geq \\bm{0}} \n\\left\\{f(\\bm{x}) - \\bm{\\lambda}^\\top \\bm{h}(\\bm{x}) \\right\\},  where the minimum is taken locally near the solution 𝐱*\\bm{x}^\\ast but constrained by the remaining constraints 𝐠(𝐱)≥𝟎\\bm{g}(\\bm{x}) \\geq \\bm{0}.\n\nAgain, the dual function defined in this way will achieve a local maximum at the optimal Lagrange multiplier 𝛌*\\bm{\\lambda}^\\ast.\nThe partial dual is especially useful when constraints 𝐠(𝐱)≥𝟎\\bm{g}(\\bm{x}) \\geq \\bm{0} are simple such as 𝐱≥𝟎\\bm{x} \\geq \\bm{0} or in a box where many efficient algorithms are available.\n\nSteepest descent projection, interior ellipsoidal-trust region methods, etc."
  },
  {
    "objectID": "09_aug_lagrangian.html#the-lagrangian-method-dual-steepest-ascent",
    "href": "09_aug_lagrangian.html#the-lagrangian-method-dual-steepest-ascent",
    "title": "09_aug_lagrangian",
    "section": "The Lagrangian Method: Dual Steepest Ascent",
    "text": "The Lagrangian Method: Dual Steepest Ascent\n\nAccording to Lemma 1, the gradient of ϕ\\phi is available almost without cost once ϕ\\phi is evaluated.\n\nAny of the standard algorithms discussed for unconstrained optimization can be used for solving the unconstrained Lagrangian problem to evaluate the dual gradient vector.\nThe iterative scheme is simply, starting from any initial pairs (𝐱0,𝛌0,𝛍0(≥𝟎))\\left(\\bm{x}_0, \\bm{\\lambda}_0, \\bm{\\mu}_0(\\geq \\bm{0})\\right),\n\n\n𝐱k+1:=argmin𝐱ℓ(𝐱,𝛌k,𝛍𝐤),𝛌k+1:=𝛌k−1c𝐡(𝐱k+1),𝛍k+1:=max{𝟎,𝛍k−1c𝐠(𝐱k+1)}.\n\\begin{align}\n\\bm{x}_{k+1} &:= \\operatorname{arg}\\,\\operatorname{min}_\\bm{x} \\ell(\\bm{x}, \\bm{\\lambda}_k, \\bm{\\mu_k}), \\\\\n\\bm{\\lambda}_{k+1} &:= \\bm{\\lambda}_k - \\frac{1}{c}\\bm{h}(\\bm{x}_{k+1}), \\\\\n\\bm{\\mu}_{k+1} &:= \\operatorname{max} \\left\\{\\bm{0}, \\, \\bm{\\mu}_k - \\frac{1}{c}\\bm{g}(\\bm{x}_{k+1}) \\right\\}.\n\\end{align}\n\nHere, cc is the first-order Lipschitz constant of the dual function ϕ(𝛌,𝛍)\\phi(\\bm{\\lambda}, \\bm{\\mu}).\n\nWithout some special properties, however, the method as a whole can be costly to execute.\n\nEvery evaluation of ϕ\\phi requires the solution of an unconstrained problem in the unknown 𝐱\\bm{x}.\n\nConvergence speed: identical to those discussed for solving unconstrained problems.\n\nIf the dual objective is strongly concave, the convergence rate is governed by the eigenvalue structure of the Hessian of the dual function ϕ\\phi: 𝚽=−∇𝐡(𝐱*)(𝐋*)−1∇𝐡(𝐱*)⊤\\bm{\\Phi} = -\\nabla \\bm{h}(\\bm{x}^\\ast)\\left(\\bm{L}^\\ast\\right)^{-1}\\nabla \\bm{h}(\\bm{x}^\\ast)^\\top.\nThe rate of convergence is (B−b)2(B+b)2\\frac{(B-b)^2}{(B+b)^2}, where BB and bb are the largest and smallest eigenvalues of 𝚽\\bm{\\Phi}."
  },
  {
    "objectID": "09_aug_lagrangian.html#the-augmented-lagrangian",
    "href": "09_aug_lagrangian.html#the-augmented-lagrangian",
    "title": "09_aug_lagrangian",
    "section": "The Augmented Lagrangian",
    "text": "The Augmented Lagrangian\n\nThese methods can be veiwed as a combination of penalty functions and local duality methods.\n\nThe two concepts work together to eliminate many of the disadvantages associated with either method alone.\n\nThe augmented Lagrangian for the equality constrained problem is the function ℓc(𝐱,𝛌)=f(𝐱)−𝛌⊤𝐡(𝐱)+c2|𝐡(𝐱)|2 \\ell_c(\\bm{x}, \\bm{\\lambda}) = f(\\bm{x}) - \\bm{\\lambda}^\\top \\bm{h}(\\bm{x}) + \\frac{c}{2}\\left|\\bm{h}(\\bm{x})\\right|^2  for some positive constant cc.\nFrom a penalty function viewpoint, the augmented Lagrangian, for a fixed value of the vector 𝛌\\bm{\\lambda} is simply the Lagrange penalty function for the problem minimizef(𝐱)+12c|𝐡(𝐱)|2,subject to𝐡(𝐱)=𝟎,𝐱∈Ω\n\\begin{align}\n\\operatorname{minimize} & f(\\bm{x}) + \\frac{1}{2}c\\left|\\bm{h}(\\bm{x})\\right|^2, \\\\\n\\text{subject to} & \\bm{h}(\\bm{x}) = \\bm{0}, \\quad \\bm{x} \\in \\Omega\n\\end{align}\n\nThis problem is clearly equivalent to the original equality cosntrained problem since the combinations of the constraints adjoined to f(𝐱)f(\\bm{x}) do not affect the minimum point or the minimum value.\nA typical step of an augmented Lagrangian method starts with a vector 𝛌k\\bm{\\lambda}_k. Then 𝐱(𝛌k)\\bm{x}(\\bm{\\lambda}_k) is found as the minimum point of 𝐱(𝛌k)=argminf(𝐱)−𝛌k⊤𝐡(𝐱)+12c|𝐡(𝐱)|2,subject to𝐱∈Ω.\n\\bm{x}(\\bm{\\lambda}_k) = \\operatorname{arg} \\operatorname{min} f(\\bm{x}) - \n\\bm{\\lambda}_k^\\top \\bm{h}(\\bm{x}) + \\frac{1}{2}c\\left|\\bm{h}(\\bm{x})\\right|^2, \n\\quad \\text{subject to} \\quad \\bm{x} \\in \\Omega.\n\nNext, 𝛌k\\bm{\\lambda}_k is updated to 𝛌k+1\\bm{\\lambda}_{k+1}: 𝛌k+1=𝛌k−c𝐡(𝐱(𝛌k)).\\bm{\\lambda}_{k+1} = \\bm{\\lambda}_k - c\\bm{h}(\\bm{x}(\\bm{\\lambda}_k))."
  },
  {
    "objectID": "09_aug_lagrangian.html#the-augmented-lagrangian-1",
    "href": "09_aug_lagrangian.html#the-augmented-lagrangian-1",
    "title": "09_aug_lagrangian",
    "section": "The Augmented Lagrangian",
    "text": "The Augmented Lagrangian\n\nWhereas the original Lagrangian may not be convex near the solution, and hence the standard duality method cannot be applied, the term 12c|𝐡(𝐱)|2\\frac{1}{2}c\\left|\\bm{h}(\\bm{x})\\right|^2 tends to “convexify” the Lagrangian.\n\nFor sufficiently large cc, the Lagrangian will indeed be locally convex.\nThus, the duality method can be employed, and the corresponding dual problem can be solved by an iterative process in 𝛌\\bm{\\lambda}.\nThis viewpoint leads to the development of additional multiplier adjustment processes.\n\nThe main iteration in augmented Lagrangian methods is with respect to 𝛌\\bm{\\lambda}.\n\nThe penalty parameter cc may also be adjusted during the process!\nAs in ordinary penalty function methods, the sequence of cc’s is usually preselected;\n\ncc is either held fixed,\nis increased toward a finite value,\nor tends (slowly) toward infinity.\n\nIn this method, it is not necessary for cc to go to infinity.\n\nIn fact, it may remain of relatively modest value.\nThe ill-conditioning usually associated with the penalty function approach is mediated."
  },
  {
    "objectID": "09_aug_lagrangian.html#the-penalty-viewpoint",
    "href": "09_aug_lagrangian.html#the-penalty-viewpoint",
    "title": "09_aug_lagrangian",
    "section": "The Penalty Viewpoint",
    "text": "The Penalty Viewpoint\n\n\n\nLemma\n\n\nLet 𝐀\\bm{A} and 𝐁\\bm{B} be nn-by-nn symmetric matrices. Suppose that 𝐁\\bm{B} is positive semidefinite and 𝐀\\bm{A} is positive definite on the subspace 𝐁𝐱=𝟎\\bm{Bx} = \\bm{0}. Then there is a c*c^\\ast such that for all c≥c*c \\geq c^\\ast the matrix 𝐀+c𝐁\\bm{A} + c\\bm{B} is positive definite.\n\n\n\n\n\n\nProof\n\n\nSuppose to the contrary that for every kk there were an 𝐱k\\bm{x}_k with |𝐱k|=1|\\bm{x}_k| = 1 such that 𝐱k⊤(𝐀+k𝐁)𝐱k≤0\\bm{x}_k^\\top (\\bm{A} + k\\bm{B})\\bm{x}_k \\leq 0. The sequence {𝐱k}\\left\\{\\bm{x}_k\\right\\} must have a convergent subsequence converging to a limit 𝐱‾\\bar{\\bm{x}}. Now since 𝐱k⊤𝐁𝐱k≥0\\bm{x}_k^\\top \\bm{B} \\bm{x}_k \\geq 0, it follows that 𝐱‾⊤𝐁𝐱‾=0\\bar{\\bm{x}}^\\top \\bm{B} \\bar{\\bm{x}} = 0. It also follows that 𝐱‾⊤𝐀𝐱‾≤0\\bar{\\bm{x}}^\\top \\bm{A} \\bar{\\bm{x}} \\leq 0. However, this contradicts the hypothesis of the lemma.\n\n\n\n\nThis lemma applies to the Hessian of the augmented Lagrangian, evaluated at the optimal solution pair 𝐱*\\bm{x}^\\ast, 𝛌*\\bm{\\lambda}^\\ast. 𝐋c(𝐱*,𝛌*)=𝐅(𝐱*)−(𝛌*)⊤𝐇(𝐱*)+c∇𝐡(𝐱*)⊤𝐡(𝐱*)=𝐋(𝐱*)+c∇𝐡(𝐱*)⊤∇𝐡(𝐱*).\n\\begin{align}\n\\bm{L}_c(\\bm{x}^\\ast, \\bm{\\lambda}^\\ast) = \\bm{F}(\\bm{x}^\\ast) - \n\\left(\\bm{\\lambda}^\\ast\\right)^\\top\\bm{H}(\\bm{x}^\\ast) + \nc\\nabla \\bm{h}(\\bm{x}^\\ast)^\\top \\bm{h}(\\bm{x}^\\ast) = \\bm{L}(\\bm{x}^\\ast) + \nc\\nabla \\bm{h}(\\bm{x}^\\ast)^\\top \\nabla \\bm{h}(\\bm{x}^\\ast).\n\\end{align}\n\n\nThe first term, the Hessian of the normal Lagrangian, is positive definite on the subspece ∇𝐡(𝐱*)=𝟎\\nabla \\bm{h}(\\bm{x}^\\ast) = \\bm{0}. This corresponds to the matrix 𝐀\\bm{A} in the lemma.\nThe matrix ∇𝐡(𝐱*)⊤∇𝐡(𝐱*)\\nabla \\bm{h}(\\bm{x}^\\ast)^\\top \\nabla \\bm{h}(\\bm{x}^\\ast) is positive semidefinite and corresponds to 𝐁\\bm{B} in the lemma.\n\nIt follows that there is a c*c^\\ast such that for all c&gt;c*c &gt; c^\\ast, 𝐋c(𝐱*,𝛌*)\\bm{L}_c(\\bm{x}^\\ast, \\bm{\\lambda}^\\ast) is positive definite.\n\n\nThis leads directly to the first basic result concerning augmented Lagrangian."
  },
  {
    "objectID": "09_aug_lagrangian.html#the-penalty-viewpoint-1",
    "href": "09_aug_lagrangian.html#the-penalty-viewpoint-1",
    "title": "09_aug_lagrangian",
    "section": "The Penalty Viewpoint",
    "text": "The Penalty Viewpoint\n\n\n\nProposition\n\n\nAssume that the second-order sufficiency conditions for a local minimum are satisfied at 𝐱*\\bm{x}^\\ast, 𝛌*\\bm{\\lambda}^\\ast. Then there is a c*c^\\ast such that for all c≥c*c \\geq c^\\ast, the augmented Lagrangian ℓc(𝐱,𝛌*)\\ell_c(\\bm{x}, \\bm{\\lambda}^\\ast) has a local minimum point at 𝐱*\\bm{x}^\\ast.\n\n\n\n\nBy continuity, for any 𝛌\\bm{\\lambda} near 𝛌*\\bm{\\lambda}^\\ast, the augmented Lagrangian has a unique local minimum point near 𝐱*\\bm{x}^\\ast.\nThis correspondence defines a continuous function.\n\nIf a value of 𝛌\\bm{\\lambda} can be found such that 𝐡(𝐱(𝛌))=𝟎\\bm{h}(\\bm{x}(\\bm{\\lambda})) = \\bm{0}, then that 𝛌\\bm{\\lambda} must in fact be 𝛌*\\bm{\\lambda}^\\ast.\n\nThis is because 𝐱(𝛌)\\bm{x}(\\bm{\\lambda}) satisfies the necessary conditions of the original problem.\n\n\nTherefore, the problem of determining the proper value of 𝛌\\bm{\\lambda} can be viewed as one of solving the equation 𝐡(𝐱(𝛌))=𝟎. \\bm{h}(\\bm{x}(\\bm{\\lambda})) = \\bm{0}. \nFor this purpose the iterative process 𝛌k+1=𝛌k−c𝐡(𝐱(𝛌k)), \\bm{\\lambda}_{k+1} = \\bm{\\lambda}_k - c \\bm{h}(\\bm{x}(\\bm{\\lambda}_k)),  is a method of successive approximation (such as fixed-point iteration).\n\nThis process will converge linearly in a neighborhood around 𝛌*\\bm{\\lambda}^\\ast although a rigorous proof is somewhat complex."
  },
  {
    "objectID": "09_aug_lagrangian.html#example-1",
    "href": "09_aug_lagrangian.html#example-1",
    "title": "09_aug_lagrangian",
    "section": "Example",
    "text": "Example\nminimize2x2+2xy+y2−2y,subject tox=0.\n\\begin{align}\n\\operatorname{minimize} & 2x^2 + 2xy + y^2 - 2y, \\\\\n\\text{subject to} & x = 0.\n\\end{align}\n\n\nThe augmented Lagrangian for this problem is\n\nℓc(x,y,λ)=2x2+2xy+y2−2y−λx+12cx2. \\ell_c(x, y, \\lambda) = 2x^2 + 2xy + y^2 - 2y - \\lambda x + \\frac{1}{2}cx^2. \n\nThe minimum can be found analytically to be\n\nx=−(2−λ)2+c,y=4+c−λ2+c.\nx = \\frac{-(2-\\lambda)}{2+c}, \\quad y = \\frac{4+c-\\lambda}{2+c}.\n\n\nSince h(x,y)=xh(x, y) = x in this example, it follows that the iterative process for λk\\lambda_k is\n\nλk+1=λk+c(2−λk)2+c=(22+c)λk+2c2+c.\n\\lambda_{k+1} = \\lambda_k + \\frac{c(2-\\lambda_k)}{2+c} = \\left(\\frac{2}{2+c}\\right)\\lambda_k + \\frac{2c}{2+c}.\n\n\nThis converges to λ=2\\lambda = 2 for any c&gt;0c &gt; 0.\nThe coefficient 22+c\\frac{2}{2+c} governs the rate of convergence.\n\nThe rate improves as cc is increased."
  },
  {
    "objectID": "09_aug_lagrangian.html#geometric-interpretation",
    "href": "09_aug_lagrangian.html#geometric-interpretation",
    "title": "09_aug_lagrangian",
    "section": "Geometric Interpretation",
    "text": "Geometric Interpretation\n\n\n\nThe minimum of the augmented Lagrangian at step kk can be expressed in terms of the primal function as follows:\n\nminℓc(𝐱,𝛌k)=min𝐱{f(𝐱)−𝛌k⊤𝐡(𝐱)+12c|𝐡(𝐱)|2}=min𝐱,𝐲{f(𝐱)−𝛌k⊤𝐲+12c|𝐲|2:𝐡(𝐱)=𝐲}=min𝐲{ω(𝐲)−𝛌k⊤𝐲+12c|𝐲|2},\n\\begin{align}\n\\operatorname{min} \\ell_c(\\bm{x}, \\bm{\\lambda}_k) &= \\operatorname{min}_\\bm{x} \n\\left\\{ f(\\bm{x}) - \\bm{\\lambda}_k^\\top \\bm{h}(\\bm{x}) + \\frac{1}{2}c\\left|\\bm{h}(\\bm{x})\\right|^2 \\right\\} \\\\\n&= \\operatorname{min}_{\\bm{x}, \\bm{y}} \\left\\{ f(\\bm{x}) - \\bm{\\lambda}_k^\\top \\bm{y} + \\frac{1}{2}c|\\bm{y}|^2: \\, \\bm{h}(\\bm{x}) = \\bm{y} \\right\\} \\\\\n&= \\operatorname{min}_\\bm{y} \\left\\{ \\omega(\\bm{y}) - \\bm{\\lambda}_k^\\top \\bm{y} + \\frac{1}{2}c|\\bm{y}|^2 \\right\\},\n\\end{align}\n\nwhere the minimization w.r.t. 𝐲\\bm{y} is taken to be locally near 𝐲=𝟎\\bm{y} = \\bm{0}.\n\nIn general, if 𝐱(𝛌𝐤)\\bm{x}(\\bm{\\lambda_k}) minimizes ℓc(𝐱,𝛌k)\\ell_c(\\bm{x}, \\bm{\\lambda}_k), then 𝐲k=𝐡(𝐱(𝛌𝐤))\\bm{y}_k = \\bm{h}(\\bm{x}(\\bm{\\lambda_k})) is the minimum of ω(𝐲)−𝛌k⊤𝐲+12c|𝐲|2\\omega(\\bm{y}) - \\bm{\\lambda}_k^\\top \\bm{y} + \\frac{1}{2}c|\\bm{y}|^2.\n\nAt that point we have ∇ω(𝐲k)⊤+c𝐲k=𝛌k∇ω(𝐲k)⊤=𝛌k−c𝐲k=𝛌k−c𝐡(𝐱(𝐲k)). \n\\begin{align} \n&\\nabla \\omega (\\bm{y}_k)^\\top + c\\bm{y}_k = \\bm{\\lambda}_k  \\\\\n&\\nabla \\omega(\\bm{y}_k)^\\top = \\bm{\\lambda}_k - c \\bm{y}_k = \\bm{\\lambda}_k - c \\bm{h}(\\bm{x}(\\bm{y}_k)). \n\\end{align}\n\n\nIt follows that for the next multiplier we have 𝛌k+1=𝛌k−c𝐡(𝐱(𝛌k))=∇ω(𝐲k)⊤.\n\\bm{\\lambda}_{k+1} = \\bm{\\lambda}_k - c\\bm{h}(\\bm{x}(\\bm{\\lambda}_k)) = \\nabla \\omega (\\bm{y}_k)^\\top.\n\n\n\n\n\n\n\n\n\nPrimal function\n\n\nω(𝐲)≜min{f(𝐱):𝐡(𝐱)=𝐲}, \\omega(\\bm{y}) \\triangleq \\operatorname{min}\\left\\{ f(\\bm{x}): \\bm{h}(\\bm{x}) = \\bm{y} \\right\\},  where the minimum is understood to be taken locally near 𝐱*\\bm{x}^\\ast.\n\nω(𝟎)=f(𝐱*)\\omega(\\bm{0}) = f(\\bm{x}^\\ast).\n∇ω(𝟎)⊤=𝛌*\\nabla \\omega(\\bm{0})^\\top = \\bm{\\lambda}^\\ast."
  },
  {
    "objectID": "09_aug_lagrangian.html#separable-problems",
    "href": "09_aug_lagrangian.html#separable-problems",
    "title": "09_aug_lagrangian",
    "section": "Separable Problems",
    "text": "Separable Problems\n\nA structure that arises frequently in mathematical programming applications is that of the separable problem:\n\nminimize∑i=1qfi(𝐱i),subject to∑i=1q𝐡i(𝐱i)=𝟎,∑i=1q𝐠i(𝐱i)≥𝟎.(10)\n\\begin{align}\n\\operatorname{minimize} & \\sum_{i=1}^q f_i(\\bm{x}_i), \\\\\n\\text{subject to} & \\sum_{i=1}^q \\bm{h}_i(\\bm{x}_i) = \\bm{0}, \\\\\n& \\sum_{i=1}^q \\bm{g}_i(\\bm{x}_i) \\geq \\bm{0}.\n\\end{align}\n \\qquad(10)\n\nIn this formulation, the components of the nn-vector 𝐱\\bm{x} are partitioned into qq disjoint groups, 𝐱=(𝐱1,𝐱2,…,𝐱q)\\bm{x} = \\left(\\bm{x}_1, \\bm{x}_2, \\ldots, \\bm{x}_q \\right).\n\nEach group may or may not have the same number of components.\n\n\n\n\n\nExample\n\n\nProblems involving a series of decision made at distinct times are often separable. maximizey(t),u(t)∑t=1Tf(y(t),u(t)),subject toy(t)=y(t−1)−u(t)+s(t),t=1,…,T,c≤y(t)≤d,t=1,…,T,0≤u(t),t=1,…,T.\n\\begin{align}\n\\operatorname{maximize}_{y(t), u(t)} & \\sum_{t=1}^T f(y(t), u(t)), & \\\\\n\\text{subject to} & y(t) = y(t-1) - u(t) + s(t), & t = 1, \\ldots, T, \\\\\n& c \\leq y(t) \\leq d, & t = 1, \\ldots, T, \\\\\n& 0 \\leq u(t), & t = 1, \\ldots, T.\n\\end{align}\n Here, the state variable y(t)y(t) represents the water volume behind the dam at the end of period tt, control variable u(t)u(t) represents the volume flow through the dam during period tt, and data s(t)s(t) is the volume flowing into the lake behind the dam during period tt from upper streams. The function ff gives the power generation, and cc and dd are bounds on lake volume.\nPartition into pairs: 𝐱t=(y(t),u(t))\\bm{x}_t = (y(t), u(t)), t=1,…,Tt = 1, \\ldots, T."
  },
  {
    "objectID": "09_aug_lagrangian.html#decomposition",
    "href": "09_aug_lagrangian.html#decomposition",
    "title": "09_aug_lagrangian",
    "section": "Decomposition",
    "text": "Decomposition\n\nSeparable problems are ideally suited to dual methods, because the required unconstrained minimization decomposes into small subproblems.\n\nGenerally, the most difficult aspect of a dual method is the evaluation of the dual function.\nFor a separable problem, if we associate 𝛌\\bm{\\lambda} with the equality constraints and 𝛍≥𝟎\\bm{\\mu} \\geq \\bm{0} with the inequality constraints of Equation 10, the required dual function is ϕ(𝛌,𝛍)=min∑i=1q(fi(𝐱i)−𝛌⊤𝐡i(𝐱i)−𝛍⊤𝐠i(𝐱i)).\n\\phi(\\bm{\\lambda}, \\bm{\\mu}) = \\operatorname{min} \\sum_{i=1}^q \\left(\nf_i(\\bm{x}_i) - \\bm{\\lambda}^\\top \\bm{h}_i(\\bm{x}_i) - \\bm{\\mu}^\\top \\bm{g}_i(\\bm{x}_i)\n\\right).\n\n\nThis minimization decomposes into the qq separate problems min𝐱ifi(𝐱i)−𝛌⊤𝐡i(𝐱i)−𝛍⊤𝐠i(𝐱i).\n\\operatorname{min}_{\\bm{x}_i} f_i(\\bm{x}_i) - \\bm{\\lambda}^\\top \\bm{h}_i(\\bm{x}_i) - \\bm{\\mu}^\\top \\bm{g}_i(\\bm{x}_i).\n\nThe solution of these subproblems can usually be accomplished relatively efficiently, since they are of smaller dimension than the original problem.\n\n\n\n\nExample\n\n\nusing duality with respect to the equality constraints, we denote the dual variables by λ(t)\\lambda(t), t=1,…,Tt = 1, \\ldots, T. The ttht^{\\text{th}} subproblem becomes maxc≤y(t)≤d,0≤u(t){f(y(t),u(t))+[λ(t+1)−λ(t)]y(t)−λ(t)[u(t)−s(t)]}\n\\operatorname{max}_{c \\leq y(t) \\leq d, 0 \\leq u(t)} \\left\\{ \nf(y(t), u(t)) + \\left[ \\lambda(t+1) - \\lambda(t) \\right]y(t) - \\lambda(t) \\left[u(t) - s(t) \\right]\n\\right\\}\n which is a two-dimensional optimization problem.\n\nThe selection of λ∈ℝN\\lambda \\in \\mathbb{R}^N decomposes the problem into separate problems for each time period."
  },
  {
    "objectID": "09_aug_lagrangian.html#problem-set-up",
    "href": "09_aug_lagrangian.html#problem-set-up",
    "title": "09_aug_lagrangian",
    "section": "Problem Set-Up",
    "text": "Problem Set-Up\n\nConsider the convex minimization model with linear/affine constraints and an objective function that is the sum of two seaparable functions with two blocks of variables:\n\nminimizef1(𝐱1)+f2(𝐱2),fi:ℝni→ℝ,subject to𝐀1𝐱1+𝐀2𝐱2=𝐛,𝐛∈ℝm𝐱1∈Ω1,𝐱2∈Ω2Ωi⊆ℝni(11)\n\\begin{align}\n\\operatorname{minimize} & f_1(\\bm{x}^1) + f_2(\\bm{x}^2), &  f_i: \\mathbb{R}^{n_i} \\rightarrow \\mathbb{R}, \\\\\n\\text{subject to} & \\bm{A}_1 \\bm{x}^1 + \\bm{A}_2 \\bm{x}^2 = \\bm{b}, & \\bm{b} \\in \\mathbb{R}^m \\\\\n& \\bm{x}^1 \\in \\Omega_1, \\; \\bm{x}^2 \\in \\Omega_2 & \\Omega_i \\subseteq \\mathbb{R}^{n_i}\n\\end{align} \n \\qquad(11)\n\nThen, the augmented Lagrangian function for Equation 11 would be ℓc(𝐱1,𝐱2,𝛌)=f1(𝐱1)+f2(𝐱2)−𝛌⊤(𝐀1𝐱1+𝐀2𝐱2−𝐛)+c2|𝐀1𝐱1+𝐀2𝐱2−𝐛|2.\n\\ell_c(\\bm{x}^1, \\bm{x}^2, \\bm{\\lambda}) = f_1(\\bm{x}^1) + f_2(\\bm{x}^2) - \\bm{\\lambda}^\\top\n\\left(\\bm{A}_1\\bm{x}^1 + \\bm{A}_2\\bm{x}^2 - \\bm{b} \\right) + \\frac{c}{2}\n\\left| \\bm{A}_1\\bm{x}^1 + \\bm{A}_2\\bm{x}^2 - \\bm{b} \\right|^2.\n\nIn contrast to the method of multipliers that we previously covered, the alternating direction method of multipliers (ADMM) is to (approximately) minimize ℓc(𝐱1,𝐱2,𝛌)\\ell_c(\\bm{x}^1, \\bm{x}^2, \\bm{\\lambda}) in an alternative order:\n\n𝐱k+11:=argmin𝐱1∈Ω1ℓc(𝐱1,𝐱k2,𝛌k),𝐱k+12:=argmin𝐱2∈Ω2ℓc(𝐱k+11,𝐱2,𝛌k),𝛌k+1:=𝛌k−c(𝐀1𝐱k+11+𝐀2𝐱k+12−𝐛).\n\\begin{align}\n\\bm{x}_{k+1}^1 &:= \\operatorname{arg}\\operatorname{min}_{\\bm{x}^1 \\in \\Omega_1} \n\\ell_c(\\bm{x}^1, \\bm{x}_k^2, \\bm{\\lambda}_k), \\\\\n\\bm{x}_{k+1}^2 &:= \\operatorname{arg}\\operatorname{min}_{\\bm{x}^2 \\in \\Omega_2} \n\\ell_c(\\bm{x}_{k+1}^1, \\bm{x}^2, \\bm{\\lambda}_k), \\\\\n\\bm{\\lambda}_{k+1} &:= \\bm{\\lambda}_k - c\\left( \\bm{A}_1\\bm{x}_{k+1}^1 + \\bm{A}_2\\bm{x}_{k+1}^2 - \\bm{b} \\right).\n\\end{align}\n\n\nThe idea is that each of the smaller-block minimization problems can be solved more efficiently or even in closed-forms for certain cases.\n\n\n\nOptimization Theory and Practice • Aykut C. Satici"
  }
]