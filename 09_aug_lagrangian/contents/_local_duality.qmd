# Local Duality and the Lagrangian Method

## Local Duality {.smaller}

:::: {.columns}

::: {.column width="50%"}

::: {.callout-tip  icon=false}
## Nonlinear Programming Problem 

$$
\begin{align}
\operatorname{minimize} & f(\bm{x}), & f, \bm{h} \in C^2, \\
\text{subject to} & \bm{h}(\bm{x}) = \bm{0}, & \bm{x} \in \mathbb{R}^n, 
\bm{h}(\bm{x}) \in \mathbb{R}^m.
\end{align}
$$ {#eq-nlp}

Everything we do can be easily extended to problems having inequality as well 
as equality constraints for the price of a somewhat more involved notation.
:::



* Assume that $\bm{x}^\ast$ is a regular point of the constraints.
  - There is then a Lagrange multiplier vector $\bm{\lambda}^\ast$ such that 

$$
\nabla f(\bm{x}^\ast) - \left(\bm{\lambda}^\ast\right)^\top \nabla \bm{h}
(\bm{x}^\ast) = \bm{0},
$$ {#eq-fonc}

and the Hessian of the Lagrangian $\ell(\bm{x}, \bm{\lambda}^\ast) = f(\bm{x}) - \left(\bm{\lambda}^\ast\right)^\top \bm{h}(\bm{x})$

$$
\bm{L}(\bm{x}^\ast) = \bm{F}(\bm{x}^\ast) - \left(\bm{\lambda}^\ast\right)^\top \bm{H}(\bm{x}^\ast)
$$ {#eq-hessian}

must be positive semidefinite on the tangent subspace 

$$ M = \{\bm{x}: \nabla \bm{h}(\bm{x}^\ast) = \bm{0}\}. $$

:::


::: {.column width="50%"}

::: {.callout-note icon=false}
## Local Convexity Assumption
We assume that the Hessian $\bm{L(\bm{x}^\ast)}$ is positive definite.
(We mean that $\bm{L(\bm{x}^\ast)}$ on the whole space $\mathbb{R}^n$, not just on the subspace $M$.)

This assumption guarantees that the Lagrangian $\ell(\bm{x}, \bm{\lambda}^\ast)$ 
is locally convex at $\bm{x}^\ast$.
:::

* With this assumption, the point $\bm{x}^\ast$ is not only a local solution to 
the constrained problem @eq-nlp; it is also a local solution to the unconstrained problem

$$
\begin{align}
\operatorname{minimize} & \ell(\bm{x}, \bm{\lambda}^\ast) = f(\bm{x}) - 
\left( \bm{\lambda}^\ast \right)^\top \bm{h}(\bm{x})
\end{align}
$$ {#eq-unc}

* For any $\bm{\lambda}$ sufficiently close to $\bm{\lambda}^\ast$, the function
$\ell(\bm{x}, \bm{\lambda})$ will have a local minimum point at a point $\bm{x}$ 
near $\bm{x}^\ast$.
  - This follows by noting that by the implicit function theorem, the eqn.
$$
\nabla f(\bm{x}) - \bm{\lambda}^\top \nabla \bm{h}
(\bm{x}) = \bm{0}
$$

has a solution $\bm{x}$ near $\bm{x}^\ast$ when $\bm{\lambda}$ is near 
$\bm{\lambda}^\ast$ because $\bm{L}^\ast$ is positive definite.
:::

::::


## Local Duality {.smaller}

:::: {.columns}

::: {.callout-note appearance="minimal"}
* Thus, locally there is a unique correspondence between $\bm{\lambda}$ and $\bm{x}$
through the solution of the unconstrained problem @eq-unc.
$$
\begin{align}
\operatorname{minimize} & \ell(\bm{x}, \bm{\lambda}) = f(\bm{x}) - \bm{\lambda}^\top \bm{h}(\bm{x}).
\end{align}
$$ {#eq-uncprob}
  - This correspondence is continuously differentiable.
* Near $\bm{\lambda}^\ast$ we define the _dual function_ $\phi$ by the equation
$$
\phi(\bm{\lambda}) \triangleq \operatorname{min}_{\bm{x} \in \mathcal{N}(\bm{x}^\ast)} 
\left[ \ell(\bm{x}, \bm{\lambda}) = f(\bm{x}) - \bm{\lambda}^\top \bm{h}(\bm{x}) \right]
$$ {#eq-dualfcn}

* We are then able to show that locally the original constrained problem @eq-unc 
is equivalent to unconstrained local maximization of of the dual function $\phi$
with respect to $\bm{\lambda}$.
  - Denote by $\bm{x}(\bm{\lambda})$ the unique solution to @eq-uncprob in the neighborhood of $\bm{x}^\ast$.
:::

::: {.column width="50%"}

::: {.callout-tip icon="false"}
## Lemma 1
The dual function $\phi$ has gradient $$ \nabla \phi(\bm{\lambda}) = -\bm{h}(\bm{x}(\bm{\lambda}))^\top. $$ {#eq-grad}
:::

::: {.callout-note icon=false}
## Proof
We have explicitly from @eq-dualfcn
$$ \phi(\bm{\lambda}) = f(\bm{x}(\bm{\lambda})) - \bm{\lambda}^\top \bm{h}(\bm{x}(\bm{\lambda})). $$
Thus
$$ 
\nabla \phi(\bm{\lambda}) = \left[ \nabla f(\bm{x}(\bm{\lambda})) - \bm{\lambda}^\top \nabla \bm{h}(\bm{x}(\bm{\lambda})) \right] \nabla \bm{x}(\bm{\lambda}) - \bm{h}(\bm{x}(\bm{\lambda}))^\top. 
$$
Since the first term on the right vanishes by the defition of $\bm{x}(\bm{\lambda})$ (the unique solution to @eq-uncprob), we obtain @eq-grad.
:::

:::

::: {.column width="50%"}

::: {.callout-tip icon="false"}
## Lemma 2
The Hessian of the dual function is
$$
\bm{\Phi}(\bm{\lambda}) = -\nabla \bm{h}(\bm{x}(\bm{\lambda}))\bm{L}^{-1}(\bm{x}(\bm{\lambda}), \bm{\lambda}) \nabla \bm{h}(\bm{x}(\bm{\lambda}))^\top.
$$ {#eq-dualhessian}
:::

::: {.callout-note icon="false"}
## Proof
By Lemma 1, $\bm{\Phi}(\bm{\lambda}) = -\nabla \bm{h}(\bm{x}(\bm{\lambda})) \nabla \bm{x}(\bm{\lambda})$. 

Differentiating $\nabla f(\bm{x}(\bm{\lambda})) - \bm{\lambda}^\top \nabla \bm{h}(\bm{x}(\bm{\lambda})) = \bm{0}$ with respect to $\bm{\lambda}$, we obtain

$$ 
\bm{L}(\bm{x}(\bm{\lambda}), \bm{\lambda})\nabla \bm{x}(\bm{\lambda}) - \nabla \bm{h}(\bm{x}(\bm{\lambda}))^\top = \bm{0}.
$$

Solving for $\nabla \bm{x}(\bm{\lambda})$ and substituting back to the first eqn., we are through.
:::

:::

::::


## Local Duality Theorem {.smaller}

<br>

::: {.callout-tip icon=false}
## Local Duality Theorem
Suppose that the problem
$$
\begin{align}
\operatorname{minimize} & f(\bm{x}) \\
\text{subject to} & \bm{h}(\bm{x}) = \bm{0}
\end{align}
$$
has a local solution at $\bm{x}^\ast$ with corresponding value $r^\ast$ and 
Lagrange multiplier $\bm{\lambda}^\ast$. Suppose also that $\bm{x}^\ast$ is a 
regular point of the constraints and that the corresponding Hessian of the 
Lagrangian $\bm{L}^\ast = \bm{L}(\bm{x}^\ast)$ is positive definite. Then the 
dual problem
$$ 
\begin{align}
\operatorname{maximize} & \phi(\bm{\lambda})
\end{align}
$$
has a local solution at $\bm{\lambda}^\ast$ with corresponding value $r^\ast$ 
and $\bm{x}^\ast$ as the point corresponding to $\bm{\lambda}^\ast$ in the 
definition of $\phi$.
:::

::: {.callout-note icon=false}
## Proof
It is clear that $\bm{x}^\ast$ corresponds to $\bm{\lambda}^\ast$ in the 
definition of $\phi$. Now at $\bm{\lambda}^\ast$ we have by Lemma 1,
$$
\nabla \phi(\bm{\lambda}^\ast) = -\bm{h}(\bm{x}^\ast)^\top = \bm{0}, 
$$
and by Lemma 2, the Hessian of $\phi$ is negative definite. Thus 
$\bm{\lambda}^\ast$ satisfies the SOSC for an unconstrained maximum point of 
$\phi$. The corresponding value $\phi(\bm{\lambda}^\ast)$ is found from the 
definition of $\phi$ to be $r^\ast$.
:::


## Example 

$$
\begin{align}
\operatorname{minimize} & -xy \\
\text{subject to} & (x-3)^2 + y^2 = 5.
\end{align}
$$

:::: {.columns}

::: {.column width="50%"}

::: {.callout-tip icon=false}
## First-Order Necessary Conditions
$$
\begin{align}
-y - (2x - 6)\lambda &= 0 \\
-x - 2y\lambda &= 0.
\end{align}
$$
together with the constraint. These equations have a solution at
$$
x = 4, \quad y = 2, \quad \lambda = -1.
$$
The Hessian of the corresponding Lagrangian is
$$ \bm{L} = \begin{bmatrix} 2 & -1 \\ -1 & 2 \end{bmatrix}. $$
Since this is positive definite, we conclude that the solution obtained is a 
local minimum (it is, in fact, a global minimum).
:::

:::

::: {.column width="50%"}
::: {.callout-tip icon=false}
## Local Duality
Since $\bm{L}$ is positive definite, we can apply the local duality theory near 
this solution. 
$$
\phi(\lambda) = \operatorname{min}_{x,y} \left\{-xy - \lambda \left[(x-3)^2 + y^2 - 5\right]\right\},
$$
which leads to 
$$
\phi(\lambda) = \frac{-4\lambda - 4\lambda^3 + 80\lambda^5}{(4\lambda^2 - 1)^2}
$$
valid for $\lambda < -\frac{1}{2}$. It can be verified that $\phi$ has a local 
maximum at $\lambda = -1$.
Plugging this value back in @eq-unc and maximizing (unconstrained) over $x$ and 
$y$ yields the same maximizers as before.
:::
:::

::::


## Inequality Constraints {.smaller}

$$
\begin{align}
\operatorname{minimize} & f(\bm{x}), & f \in C^2, \;\; \bm{x}\in \mathbb{R}^n \\ 
\text{subject to} & \bm{h}(\bm{x}) = \bm{0}, & \bm{h} \in \mathbb{C}^2, \;\; \bm{h}(\bm{x}) \in \mathbb{R}^m, \\\
& \bm{g}(\bm{x}) \geq \bm{0}, & \bm{g} \in C^2, \;\; \bm{g}(\bm{x}) \in \mathbb{R}^p.
\end{align}
$$ {#eq-optineq}

* Suppose $\bm{x}^\ast$ is a local solution of @eq-optineq and is a regular point of the constraints.
  - Then, there are Lagrange multipliers $\bm{\lambda}^\ast$ and $\bm{\mu}^\ast \geq \bm{0}$ such that
$$
\begin{align}
\nabla f(\bm{x}^\ast) - \left(\bm{\lambda}^\ast \right)^\top \nabla 
\bm{h}(\bm{x}^\ast) - \left(\bm{\mu}^\ast\right)^\top \nabla \bm{g}(\bm{x}^\ast) &= \bm{0}, \\
\left(\bm{\mu}^\ast\right)^\top \bm{g}(\bm{x}^\ast) = 0.
\end{align}
$$
* Local convexity assumption: Hessian of the Lagrangian is positive definite on the whole space.
$$ \bm{L}(\bm{x}^\ast) = \bm{F}(\bm{x}^\ast) - \left(\bm{\lambda}^\ast\right)^\top 
\bm{H}(\bm{x}^\ast) - \left(\bm{\mu}^\ast\right)\bm{G}(\bm{x}^\ast) \succ \bm{0}.
$$
* For $\bm{\lambda}$ and $\bm{\mu} \geq \bm{0}$ near $\bm{\lambda}^\ast$ and $\bm{\mu}^\ast$
we can define the dual function
$$
\phi(\bm{\lambda}, \bm{\mu}) \triangleq \operatorname{min}_{\bm{x} \in \mathcal{N}(\bm{x}^\ast)} 
\left[ \ell(\bm{x}, \bm{\lambda}, \bm{\mu}) = f(\bm{x}) - \bm{\lambda}^\top 
\bm{h}(\bm{x}) - \bm{\mu}^\top \bm{g}(\bm{x}) \right],
$$
where the minimum is taken locally near $\bm{x}^\ast$.
* Then it is easy to show, paralleling the devlopment above for equality 
constraints, that $\phi$ achieves a local maximum with respect to $\bm{\lambda}$, 
$\bm{\mu} \geq \bm{0}$ at $\bm{\lambda}^\ast$, $\bm{\mu}^\ast$.


## Partial Duality {.smaller}

<br>

* It is not necessary to include the lagrange multipliers of all the cosntraints 
of a problem in the definition of the dual function.
* In general, if the local convexity assumption holds, local duality can be
defined with respect to any subset of function constraints.
  - For example, in problem @eq-optineq we might define the dual with respect 
  to only the equality constraints
$$ \phi(\bm{\lambda}) = \operatorname{min}_{\bm{g}(\bm{x}) \geq \bm{0}} 
\left\{f(\bm{x}) - \bm{\lambda}^\top \bm{h}(\bm{x}) \right\}, $$
where the minimum is taken locally near the solution $\bm{x}^\ast$ but 
constrained by the remaining constraints $\bm{g}(\bm{x}) \geq \bm{0}$.

* Again, the dual function defined in this way will achieve a local maximum at
the optimal Lagrange multiplier $\bm{\lambda}^\ast$.
* The partial dual is especially useful when constraints $\bm{g}(\bm{x}) \geq \bm{0}$ 
are simple such as $\bm{x} \geq \bm{0}$ or in a box where many efficient algorithms are available.
  - Steepest descent projection, interior ellipsoidal-trust region methods, etc.


## The Lagrangian Method: Dual Steepest Ascent {.smaller}

* According to Lemma 1, the gradient of $\phi$ is available almost without cost 
once $\phi$ is evaluated.
  - Any of the standard algorithms discussed for unconstrained optimization can 
  be used for solving the unconstrained Lagrangian problem to evaluate the dual 
  gradient vector.
  - The iterative scheme is simply, starting from any initial pairs 
  $\left(\bm{x}_0, \bm{\lambda}_0, \bm{\mu}_0(\geq \bm{0})\right)$,

$$
\begin{align}
\bm{x}_{k+1} &:= \operatorname{arg}\,\operatorname{min}_\bm{x} \ell(\bm{x}, \bm{\lambda}_k, \bm{\mu_k}), \\
\bm{\lambda}_{k+1} &:= \bm{\lambda}_k - \frac{1}{c}\bm{h}(\bm{x}_{k+1}), \\
\bm{\mu}_{k+1} &:= \operatorname{max} \left\{\bm{0}, \, \bm{\mu}_k - \frac{1}{c}\bm{g}(\bm{x}_{k+1}) \right\}.
\end{align}
$$

Here, $c$ is the first-order Lipschitz constant of the dual function $\phi(\bm{\lambda}, \bm{\mu})$.

* Without some special properties, however, the method as a whole can be costly 
to execute.
  - Every evaluation of $\phi$ requires the solution of an unconstrained problem
  in the unknown $\bm{x}$.
* Convergence speed: identical to those discussed for solving unconstrained problems.
  - If the dual objective is strongly concave, the convergence rate is governed by
  the eigenvalue structure of the Hessian of the dual function $\phi$: 
  $\bm{\Phi} = -\nabla \bm{h}(\bm{x}^\ast)\left(\bm{L}^\ast\right)^{-1}\nabla \bm{h}(\bm{x}^\ast)^\top$.
  - The rate of convergence is $\frac{(B-b)^2}{(B+b)^2}$, where $B$ and $b$ are 
  the largest and smallest eigenvalues of $\bm{\Phi}$.