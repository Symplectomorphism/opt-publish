# Introduction

## Standard Form

::: {.callout-note}
## Linear Program (LP)
An LP is an optimization problem in which the objective
function is linear in the unknowns and the constraints consist of linear
(in)equalities.
:::

::: {.callout-tip}
## Standard form
$$
\begin{align}
\operatorname{minimize} & \bm{c}^\top \bm{x} = c_1x_1 + c_2x_2 + \cdots + c_nx_n
\\
\text{subject to} & \bm{A}\bm{x} = \bm{b} \quad \text{and} \quad \bm{x} \geq
\bm{0}.
\end{align}
$$

* $\bm{c}, \bm{x} \in \mathbb{R}^n$ are column vectors, $\bm{A} \in
\mathbb{R}^{m \times n}$ a fat matrix ($m < n$), $\bm{b} \in \mathbb{R}^m$ a column vector.
* $b_i$'s, $c_i$'s and $a_{ij}$'s are fixed real constants, and the $x_i$'s are
real numbers to be determined.
* We assume that each equation has been multiplied by minus unity, if necessary,
so that each $b_i \geq 0$.

:::

## Slack Variables

:::: {.columns}

::: {.column width="68%"}

::: {.callout-tip appearance="minimal"}
$$
\begin{align}
\operatorname{maximize} & c_1x_2 + c_2x_2 + \cdots + c_nx_n \\
\text{subject to} & a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n &\leq b_1, \\
& a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n &\leq b_2, \\
& \vdots & \vdots \\
& a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n &\leq b_m, \\
& x_1, x_2, \ldots, x_n \geq 0.
\end{align}
$$
:::

This problem may be alternatively expressed as

::: {.callout-tip appearance="minimal"}
$$
\begin{align}
\operatorname{minimize} & -c_1x_2 - c_2x_2 - \cdots - c_nx_n \\
\text{subject to} & a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n + x_{n+1} &= b_1, \\
& a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n \phantom{12} + x_{n+2} &= b_2, \\
& \vdots & \vdots \\
& a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n \phantom{12345} + x_{n+m} &= b_m, \\
& x_1, x_2, \ldots, x_{n+1}, \ldots, x_{n+m} \geq 0.
\end{align}
$$
:::

:::

::: {.column width="32%"}
* The new nonnegative variables $x_{n+i}$, $i=1, \ldots, m$ convert inequalities
to equalities are called _slack variables_.

&nbsp;

* The constrant matrix now is transformed to $\bm{A} \rightarrow \begin{bmatrix}
\bm{A} & \bm{I} \end{bmatrix}$.
:::

::::


## Surplus Variables

* If the linear equalities are reversed so that a typical inequality is 

$$ a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in} x_n \geq b_i, $$

it is clear that this is equivalent to 

$$ a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in} x_n - y_i = b_i, $$

with $y_i \geq 0$.

* Variables, such as $y_i$, adjoined in this fashion to convert a "greater than
or equal to" inequality to equality are called _surplus variables_.

* By suitably multiplying by minus unity, and adjoining slack and surplus
variables, any set of linear inequalities can be converted to standard form.



## Free variables &#8211; first method

::: {.callout-important appearance="minimal"}
Suppose one or more of the unknown variables is not required to be nonnegative,
say, $x_1 \geq 0$ is not present so that $x_1$ is free to take on either
positive or negative values.
:::

* We then write $x_1 = u_1 - v_1$, and require that $u_1, v_1 \geq 0$.
* We substitute $u_1 - v_1$ for $x_1$ everwhere.
* The problem is then expressed in terms of the $n+1$ variables $u_1, v_1, x_2,
x_3, \ldots, x_n$.
* There is a certaind egree of redundancy introduced in this technique since a
constant added to $u_1$ and $v_1$ does not change $x_1$.
* Nevertheless, the simplex method can still be used to find the solution.


## Free variables &#8211; second method {.smaller}

* Take the same free variable situation, i.e, $x_1$ is free to take on positive
or negative values.
* One can take any one of the $m$ equality constraints which has a nonzero
coefficient for $x_1$, say, for example,

$$ a_{i1}x_1 + a_{i2}x_2 + \cdots + a_{in}x_n = b_i, $$ 

where $a_{i1} \neq 0$.

* Then $x_1$ can be expressed as a linear combination of the other variables,
plus a constant.
* This expression can be substituted everywhere for $x_1$ and we are led to a
new problem of exacly the same form but expressed in terms of the variables
$x_2, x_3, \ldots, x_n$ only.
* Furthermore, the $i^{\text{th}}$ equation, used to determine $x_1$ is now
identically zero and it too can be eliminated.
* We obtain a linear program having $n_1$ variables and $m-1$ constraint
equations.

## Example &#8211; specific case {.smaller}

:::: {.columns}

::: {.column width="50%"}

::: {.callout-note appearance="minimal"}
$$
\begin{align}
\operatorname{minimize} & x_1 + 3x_2 + 4x_3 \\
\text{subject to} & x_1 + 2x_2 + 3x_3 = 5, \\
& 2x_1 + 3x_2 + x_3 = 6, \\
& x_2, x_3 \geq 0.
\end{align}
$$
:::

:::

::: {.column width="50%"}

$x_1$ is free, so we can solve for it from the first constraint, obtaining

$$ x_1 = 5 - 2x_2 - x_3.$$ {#eq-a}

:::

::::

Substituting this into the objective and the second constraint, we obtain the
equivalent problem 

$$
\begin{align}
\operatorname{minimize} & x_2 + 3x_3 \\
\text{subject to}& x_2 + x_3 = 4, \\
& x_2, x_3 \geq 0.
\end{align}
$$

which is a problem in standard form.

After the smaller problem is solved (what is the answer?) the value for $x_1 =
-3$ can be found from @eq-a.
